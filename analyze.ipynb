{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All Dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_1\n",
      "Dataset_10\n",
      "Dataset_11\n",
      "Dataset_12\n",
      "Dataset_13\n",
      "Dataset_14\n",
      "Dataset_15\n",
      "Dataset_16\n",
      "Dataset_17\n",
      "Dataset_18\n",
      "Dataset_19\n",
      "Dataset_2\n",
      "Dataset_20\n",
      "Dataset_21\n",
      "Dataset_22\n",
      "Dataset_23\n",
      "Dataset_24\n",
      "Dataset_25\n",
      "Dataset_26\n",
      "Dataset_27\n",
      "Dataset_28\n",
      "Dataset_29\n",
      "Dataset_3\n",
      "Dataset_30\n",
      "Dataset_31\n",
      "Dataset_32\n",
      "Dataset_33\n",
      "Dataset_34\n",
      "Dataset_35\n",
      "Dataset_36\n",
      "Dataset_37\n",
      "Dataset_38\n",
      "Dataset_39\n",
      "Dataset_4\n",
      "Dataset_40\n",
      "Dataset_41\n",
      "Dataset_42\n",
      "Dataset_43\n",
      "Dataset_44\n",
      "Dataset_45\n",
      "Dataset_46\n",
      "Dataset_47\n",
      "Dataset_48\n",
      "Dataset_49\n",
      "Dataset_5\n",
      "Dataset_6\n",
      "Dataset_7\n",
      "Dataset_8\n",
      "Dataset_9\n"
     ]
    }
   ],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "\n",
    "path = \"C:/Users/User/Desktop/SeniorYearFirstSem/DataScience/Competition1_code/Competition_data\"\n",
    "for folder_name in os.listdir(path):\n",
    "    print(folder_name)\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"{path}/{folder_name}/X_train.csv\", header=0))\n",
    "    y_trains.append(pd.read_csv(f\"{path}/{folder_name}/y_train.csv\", header=0))\n",
    "    X_tests.append(pd.read_csv(f\"{path}/{folder_name}/X_test.csv\", header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split & build Model\n",
    "You can select an appropriate model and perform corresponding hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train & Test & Split & Build Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_set = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.9887\n",
      "  Validation Accuracy = 0.8090\n",
      "  Validation AUC = 0.7670\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.9964\n",
      "  Validation Accuracy = 0.6684\n",
      "  Validation AUC = 0.6566\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9516\n",
      "  Validation AUC = 0.9435\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9907\n",
      "  Validation Accuracy = 0.7945\n",
      "  Validation AUC = 0.7373\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7432\n",
      "  Validation AUC = 0.6749\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9857\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9101\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9416\n",
      "  Validation AUC = 0.9256\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9857\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8462\n",
      "  Validation AUC = 0.8006\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.9945\n",
      "  Validation Accuracy = 0.8607\n",
      "  Validation AUC = 0.8575\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8462\n",
      "  Validation AUC = 0.8368\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8662\n",
      "  Validation AUC = 0.8584\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7125\n",
      "  Validation AUC = 0.5749\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9815\n",
      "  Validation AUC = 0.9750\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7778\n",
      "  Validation AUC = 0.7127\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 0.9868\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.6897\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8862\n",
      "  Validation AUC = 0.8808\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7857\n",
      "  Validation AUC = 0.7857\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7342\n",
      "  Validation AUC = 0.7001\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7273\n",
      "  Validation AUC = 0.6075\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.9324\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5503\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9896\n",
      "  Validation AUC = 0.9865\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.9817\n",
      "  Validation Accuracy = 0.7727\n",
      "  Validation AUC = 0.7530\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.6897\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9906\n",
      "  Validation Accuracy = 0.7465\n",
      "  Validation AUC = 0.7513\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7214\n",
      "  Validation AUC = 0.6024\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9972\n",
      "  Validation Accuracy = 0.9708\n",
      "  Validation AUC = 0.9703\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9773\n",
      "  Validation Accuracy = 0.9515\n",
      "  Validation AUC = 0.4949\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.6897\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9479\n",
      "  Validation AUC = 0.7721\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9828\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.9324\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5503\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9688\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8310\n",
      "  Validation AUC = 0.8271\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8000\n",
      "  Validation AUC = 0.8000\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9971\n",
      "  Validation Accuracy = 0.9261\n",
      "  Validation AUC = 0.9222\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9948\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9680\n",
      "  Validation AUC = 0.9765\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9595\n",
      "  Validation AUC = 0.9259\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7917\n",
      "  Validation AUC = 0.7572\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8276\n",
      "  Validation AUC = 0.8292\n",
      "Average AUC = 0.8092416125176792\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = RandomForestClassifier(\n",
    "            n_estimators=400,       \n",
    "            max_depth=15,           \n",
    "            min_samples_split=4,   \n",
    "            min_samples_leaf=1,\n",
    "            random_state=42,\n",
    "            max_features=0.5\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for dataset Dataset_1: {'max_depth': 15, 'max_features': 0.5, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 400}\n",
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.9173\n",
      "  Validation Accuracy = 0.7697\n",
      "  Validation AUC = 0.6955\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m\n\u001b[0;32m     17\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     18\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mRandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m     19\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m     20\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Evaluate using AUC score\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m               \u001b[38;5;66;03m# 10-fold cross-validation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV on the training data\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Get the best model and parameters\u001b[39;00m\n\u001b[0;32m     28\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for RandomForestClassifier\n",
    "param_grid = {\n",
    "    'n_estimators': [400],\n",
    "    'max_depth': [15],\n",
    "    'min_samples_split': [4],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.5]\n",
    "}\n",
    "\n",
    "average_auc = 0\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=0),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',  # Evaluate using AUC score\n",
    "        cv=5               # 10-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for dataset {dataset_names[i]}: {best_params}\")\n",
    "    \n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "# Calculate and print the average AUC score\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> K NEIGHBORS CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7360\n",
      "  Validation AUC = 0.6596\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6578\n",
      "  Validation AUC = 0.6457\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8226\n",
      "  Validation AUC = 0.8095\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7397\n",
      "  Validation AUC = 0.6776\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8082\n",
      "  Validation AUC = 0.7565\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6757\n",
      "  Validation AUC = 0.6056\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9677\n",
      "  Validation AUC = 0.9600\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8542\n",
      "  Validation AUC = 0.8439\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9853\n",
      "  Validation AUC = 0.7500\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9270\n",
      "  Validation AUC = 0.9259\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9677\n",
      "  Validation AUC = 0.9600\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6923\n",
      "  Validation AUC = 0.6124\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7951\n",
      "  Validation AUC = 0.7918\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8077\n",
      "  Validation AUC = 0.8264\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7664\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6625\n",
      "  Validation AUC = 0.5522\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7593\n",
      "  Validation AUC = 0.7162\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7639\n",
      "  Validation AUC = 0.7409\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7283\n",
      "  Validation AUC = 0.6962\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8455\n",
      "  Validation AUC = 0.8429\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6786\n",
      "  Validation AUC = 0.6786\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6937\n",
      "  Validation AUC = 0.6570\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7879\n",
      "  Validation AUC = 0.5625\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.9437\n",
      "  Validation Accuracy = 0.8109\n",
      "  Validation AUC = 0.5574\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9645\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.9817\n",
      "  Validation Accuracy = 0.7273\n",
      "  Validation AUC = 0.7214\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7065\n",
      "  Validation AUC = 0.6881\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7353\n",
      "  Validation AUC = 0.7197\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7746\n",
      "  Validation AUC = 0.7735\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7000\n",
      "  Validation AUC = 0.6290\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9500\n",
      "  Validation AUC = 0.9552\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9320\n",
      "  Validation AUC = 0.4848\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7065\n",
      "  Validation AUC = 0.6881\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9219\n",
      "  Validation AUC = 0.7576\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9310\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.9437\n",
      "  Validation Accuracy = 0.8109\n",
      "  Validation AUC = 0.5574\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8333\n",
      "  Validation AUC = 0.7812\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9062\n",
      "  Validation AUC = 0.8333\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7854\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.5429\n",
      "  Validation AUC = 0.4700\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8947\n",
      "  Validation AUC = 0.8720\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9043\n",
      "  Validation AUC = 0.9183\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9462\n",
      "  Validation AUC = 0.6209\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9947\n",
      "  Validation Accuracy = 0.9600\n",
      "  Validation AUC = 0.9706\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9459\n",
      "  Validation AUC = 0.7903\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6944\n",
      "  Validation AUC = 0.6743\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7759\n",
      "  Validation AUC = 0.7832\n",
      "Average AUC = 0.7441867678247674\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = KNeighborsClassifier(\n",
    "            n_neighbors=4,           # [1, 3, 5, 10, 20]\n",
    "            weights='distance',     # uniform/distance      \n",
    "            metric='cosine'              # minkowski, euclidean, manhattan, cosine\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.7594\n",
      "  Validation Accuracy = 0.7191\n",
      "  Validation AUC = 0.5847\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.7179\n",
      "  Validation Accuracy = 0.6845\n",
      "  Validation AUC = 0.6737\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.9706\n",
      "  Validation Accuracy = 0.6250\n",
      "  Validation AUC = 0.4412\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.6848\n",
      "  Validation Accuracy = 0.7903\n",
      "  Validation AUC = 0.5863\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9815\n",
      "  Validation Accuracy = 0.7808\n",
      "  Validation AUC = 0.7353\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8904\n",
      "  Validation AUC = 0.8633\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.8000\n",
      "  Validation Accuracy = 0.7162\n",
      "  Validation AUC = 0.6580\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9713\n",
      "  Validation Accuracy = 0.9516\n",
      "  Validation AUC = 0.9499\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9444\n",
      "  Validation Accuracy = 0.8542\n",
      "  Validation AUC = 0.8545\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9902\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9951\n",
      "  Validation Accuracy = 0.9489\n",
      "  Validation AUC = 0.9433\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9713\n",
      "  Validation Accuracy = 0.9516\n",
      "  Validation AUC = 0.9499\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9351\n",
      "  Validation Accuracy = 0.7692\n",
      "  Validation AUC = 0.7065\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.9061\n",
      "  Validation Accuracy = 0.8525\n",
      "  Validation AUC = 0.8489\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.7500\n",
      "  Validation Accuracy = 0.6346\n",
      "  Validation AUC = 0.6319\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8821\n",
      "  Validation Accuracy = 0.8310\n",
      "  Validation AUC = 0.8262\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7389\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5505\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.6914\n",
      "  Validation Accuracy = 0.6111\n",
      "  Validation AUC = 0.4956\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.8879\n",
      "  Validation Accuracy = 0.7639\n",
      "  Validation AUC = 0.7409\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8225\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7135\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.8361\n",
      "  Validation Accuracy = 0.8699\n",
      "  Validation AUC = 0.8668\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.7805\n",
      "  Validation Accuracy = 0.6786\n",
      "  Validation AUC = 0.6786\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.8006\n",
      "  Validation Accuracy = 0.6712\n",
      "  Validation AUC = 0.6438\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.8958\n",
      "  Validation Accuracy = 0.5758\n",
      "  Validation AUC = 0.5500\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9792\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9746\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.7988\n",
      "  Validation Accuracy = 0.8091\n",
      "  Validation AUC = 0.8063\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8261\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.6945\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8529\n",
      "  Validation AUC = 0.8674\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8962\n",
      "  Validation Accuracy = 0.7746\n",
      "  Validation AUC = 0.7735\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7177\n",
      "  Validation Accuracy = 0.7286\n",
      "  Validation AUC = 0.6321\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9750\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9581\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9416\n",
      "  Validation Accuracy = 0.9466\n",
      "  Validation AUC = 0.4924\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8261\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.6945\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9583\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.7663\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 0.9861\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9483\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9574\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.6167\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9238\n",
      "  Validation Accuracy = 0.7324\n",
      "  Validation AUC = 0.7242\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 0.9804\n",
      "  Validation Accuracy = 0.6000\n",
      "  Validation AUC = 0.5700\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9684\n",
      "  Validation AUC = 0.9599\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9333\n",
      "  Validation Accuracy = 0.9217\n",
      "  Validation AUC = 0.9096\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9639\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.6168\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9412\n",
      "  Validation Accuracy = 0.9120\n",
      "  Validation AUC = 0.9221\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9548\n",
      "  Validation Accuracy = 0.9662\n",
      "  Validation AUC = 0.8785\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.8318\n",
      "  Validation Accuracy = 0.7778\n",
      "  Validation AUC = 0.7140\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.8953\n",
      "  Validation Accuracy = 0.7759\n",
      "  Validation AUC = 0.7760\n",
      "Average AUC = 0.7507947885909418\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = LogisticRegression(\n",
    "                max_iter=200\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.9398\n",
      "  Validation Accuracy = 0.6910\n",
      "  Validation AUC = 0.6133\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.9714\n",
      "  Validation Accuracy = 0.6096\n",
      "  Validation AUC = 0.6042\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.9706\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5840\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.9783\n",
      "  Validation Accuracy = 0.8871\n",
      "  Validation AUC = 0.8712\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9630\n",
      "  Validation Accuracy = 0.7808\n",
      "  Validation AUC = 0.7527\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.9136\n",
      "  Validation Accuracy = 0.6622\n",
      "  Validation AUC = 0.6134\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9964\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9885\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9583\n",
      "  Validation Accuracy = 0.8333\n",
      "  Validation AUC = 0.8427\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9951\n",
      "  Validation Accuracy = 0.8978\n",
      "  Validation AUC = 0.8937\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9964\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9885\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9610\n",
      "  Validation Accuracy = 0.7692\n",
      "  Validation AUC = 0.7177\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.9779\n",
      "  Validation Accuracy = 0.8770\n",
      "  Validation AUC = 0.8840\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.9737\n",
      "  Validation Accuracy = 0.6923\n",
      "  Validation AUC = 0.6910\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.9623\n",
      "  Validation Accuracy = 0.8380\n",
      "  Validation AUC = 0.8364\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.9250\n",
      "  Validation Accuracy = 0.6458\n",
      "  Validation AUC = 0.5441\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9444\n",
      "  Validation AUC = 0.9583\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.9439\n",
      "  Validation Accuracy = 0.7361\n",
      "  Validation AUC = 0.6668\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9837\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 0.9848\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.9601\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.7156\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.9672\n",
      "  Validation Accuracy = 0.8293\n",
      "  Validation AUC = 0.8179\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.9512\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7500\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.9396\n",
      "  Validation Accuracy = 0.7117\n",
      "  Validation AUC = 0.6600\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.9375\n",
      "  Validation Accuracy = 0.7273\n",
      "  Validation AUC = 0.5694\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.9014\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5447\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9931\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9459\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.9573\n",
      "  Validation Accuracy = 0.7455\n",
      "  Validation AUC = 0.7395\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.9601\n",
      "  Validation Accuracy = 0.6957\n",
      "  Validation AUC = 0.6793\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 0.9900\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9528\n",
      "  Validation Accuracy = 0.6479\n",
      "  Validation AUC = 0.6512\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.9569\n",
      "  Validation Accuracy = 0.6429\n",
      "  Validation AUC = 0.5417\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9861\n",
      "  Validation Accuracy = 0.9250\n",
      "  Validation AUC = 0.9297\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9643\n",
      "  Validation Accuracy = 0.9466\n",
      "  Validation AUC = 0.5429\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.9601\n",
      "  Validation Accuracy = 0.6957\n",
      "  Validation AUC = 0.6793\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9826\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 0.8594\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9800\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.9014\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5447\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 0.7857\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9429\n",
      "  Validation Accuracy = 0.8310\n",
      "  Validation AUC = 0.8098\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6857\n",
      "  Validation AUC = 0.6413\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9884\n",
      "  Validation Accuracy = 0.9087\n",
      "  Validation AUC = 0.9093\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9897\n",
      "  Validation Accuracy = 0.8615\n",
      "  Validation AUC = 0.4706\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9733\n",
      "  Validation Accuracy = 0.8800\n",
      "  Validation AUC = 0.8809\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9910\n",
      "  Validation Accuracy = 0.9257\n",
      "  Validation AUC = 0.8485\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.9252\n",
      "  Validation Accuracy = 0.7361\n",
      "  Validation AUC = 0.6979\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.9884\n",
      "  Validation Accuracy = 0.7241\n",
      "  Validation AUC = 0.7284\n",
      "Average AUC = 0.7746742743162263\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=42)\n",
    "    model = DecisionTreeClassifier(\n",
    "            criterion='entropy',\n",
    "            max_depth=15,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=123,\n",
    "            max_leaf_nodes=None,\n",
    "            max_features=0.5\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for dataset Dataset_10: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 50, 'min_samples_leaf': 2, 'min_samples_split': 5, 'random_state': 0}\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.7786\n",
      "  Validation Accuracy = 0.6631\n",
      "  Validation AUC = 0.6286\n",
      "Best parameters for dataset Dataset_14: {'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 0}\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Best parameters for dataset Dataset_19: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123}\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9559\n",
      "  Validation Accuracy = 0.9124\n",
      "  Validation AUC = 0.8824\n",
      "Best parameters for dataset Dataset_23: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'random_state': 42}\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.9434\n",
      "  Validation Accuracy = 0.8732\n",
      "  Validation AUC = 0.8611\n",
      "Best parameters for dataset Dataset_28: {'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': 10, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 0}\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8551\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.6914\n",
      "Best parameters for dataset Dataset_32: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123}\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5000\n",
      "Best parameters for dataset Dataset_37: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'min_samples_leaf': 10, 'min_samples_split': 2, 'random_state': 42}\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8679\n",
      "  Validation Accuracy = 0.6479\n",
      "  Validation AUC = 0.6573\n",
      "Best parameters for dataset Dataset_41: {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'random_state': 42}\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9826\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.8442\n",
      "Best parameters for dataset Dataset_46: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'max_leaf_nodes': 10, 'min_samples_leaf': 5, 'min_samples_split': 2, 'random_state': 123}\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8762\n",
      "  Validation Accuracy = 0.7746\n",
      "  Validation AUC = 0.7671\n",
      "Best parameters for dataset Dataset_6: {'criterion': 'gini', 'max_depth': 5, 'max_features': 'sqrt', 'max_leaf_nodes': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 1}\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9198\n",
      "  Validation Accuracy = 0.9040\n",
      "  Validation AUC = 0.9228\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 50],\n",
    "    'random_state': [0, 1, 42, 123]\n",
    "}\n",
    "\n",
    "average_auc = 0\n",
    "test_indices = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# Iterate only through the selected indices\n",
    "for i in test_indices:\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=DecisionTreeClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',  # Evaluate using AUC score\n",
    "        cv=5               # 5-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for dataset {dataset_names[i]}: {best_params}\")\n",
    "    \n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.7707\n",
      "  Validation Accuracy = 0.7303\n",
      "  Validation AUC = 0.7254\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.7179\n",
      "  Validation Accuracy = 0.6631\n",
      "  Validation AUC = 0.6708\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.5833\n",
      "  Validation AUC = 0.4118\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.5978\n",
      "  Validation Accuracy = 0.7258\n",
      "  Validation AUC = 0.7723\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7397\n",
      "  Validation AUC = 0.6862\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8904\n",
      "  Validation AUC = 0.8547\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7455\n",
      "  Validation Accuracy = 0.6622\n",
      "  Validation AUC = 0.6201\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9892\n",
      "  Validation Accuracy = 0.9839\n",
      "  Validation AUC = 0.9871\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9583\n",
      "  Validation Accuracy = 0.8125\n",
      "  Validation AUC = 0.8016\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9124\n",
      "  Validation AUC = 0.9103\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9892\n",
      "  Validation Accuracy = 0.9839\n",
      "  Validation AUC = 0.9871\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9740\n",
      "  Validation Accuracy = 0.7115\n",
      "  Validation AUC = 0.6722\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.9171\n",
      "  Validation Accuracy = 0.8361\n",
      "  Validation AUC = 0.8332\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.7895\n",
      "  Validation Accuracy = 0.4808\n",
      "  Validation AUC = 0.5035\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8396\n",
      "  Validation Accuracy = 0.8239\n",
      "  Validation AUC = 0.8360\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.6083\n",
      "  Validation Accuracy = 0.5708\n",
      "  Validation AUC = 0.6150\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.6296\n",
      "  Validation Accuracy = 0.4444\n",
      "  Validation AUC = 0.3941\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.9065\n",
      "  Validation Accuracy = 0.7222\n",
      "  Validation AUC = 0.6982\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 0.9889\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.7971\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.7292\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.8251\n",
      "  Validation Accuracy = 0.8618\n",
      "  Validation AUC = 0.8616\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.8049\n",
      "  Validation Accuracy = 0.6786\n",
      "  Validation AUC = 0.6786\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.7825\n",
      "  Validation Accuracy = 0.6441\n",
      "  Validation AUC = 0.6361\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.9375\n",
      "  Validation Accuracy = 0.6364\n",
      "  Validation AUC = 0.5900\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.5718\n",
      "  Validation Accuracy = 0.5882\n",
      "  Validation AUC = 0.6740\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9391\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.8110\n",
      "  Validation Accuracy = 0.7727\n",
      "  Validation AUC = 0.7800\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.7681\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.7383\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8824\n",
      "  Validation AUC = 0.8902\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9057\n",
      "  Validation Accuracy = 0.7606\n",
      "  Validation AUC = 0.7624\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7129\n",
      "  Validation Accuracy = 0.6571\n",
      "  Validation AUC = 0.7152\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9750\n",
      "  Validation Accuracy = 0.9542\n",
      "  Validation AUC = 0.9547\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.7955\n",
      "  Validation Accuracy = 0.7379\n",
      "  Validation AUC = 0.5038\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.7681\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.7383\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9062\n",
      "  Validation Accuracy = 0.8750\n",
      "  Validation AUC = 0.8640\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9655\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.5718\n",
      "  Validation Accuracy = 0.5882\n",
      "  Validation AUC = 0.6740\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9688\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9833\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9048\n",
      "  Validation Accuracy = 0.8028\n",
      "  Validation AUC = 0.7977\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.5143\n",
      "  Validation AUC = 0.5100\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9789\n",
      "  Validation AUC = 0.9677\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9681\n",
      "  Validation Accuracy = 0.9043\n",
      "  Validation AUC = 0.9027\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9588\n",
      "  Validation Accuracy = 0.8923\n",
      "  Validation AUC = 0.6506\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9358\n",
      "  Validation Accuracy = 0.9360\n",
      "  Validation AUC = 0.9529\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.8959\n",
      "  Validation Accuracy = 0.8986\n",
      "  Validation AUC = 0.8916\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.8411\n",
      "  Validation Accuracy = 0.7222\n",
      "  Validation AUC = 0.6931\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.9535\n",
      "  Validation Accuracy = 0.8103\n",
      "  Validation AUC = 0.8082\n",
      "Average AUC = 0.7712243778417804\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'C': [0.1, 1, 10, 100],\n",
    "'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10],\n",
    "'degree': [2, 3, 4],  # Only for 'poly' kernel\n",
    "'class_weight': [None, 'balanced'],\n",
    "'random_state': [0, 1, 42, 123]\n",
    "\"\"\"\n",
    "    \n",
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = SVC(\n",
    "            C=10,       \n",
    "            kernel='linear',           \n",
    "            gamma='scale',   \n",
    "            degree=3,\n",
    "            class_weight='balanced',    ### *****\n",
    "            random_state=123\n",
    "            )    \n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10],\n",
    "    'degree': [2, 3, 4],  # Only for 'poly' kernel\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'random_state': [0, 1, 42, 123]\n",
    "}\n",
    "\n",
    "average_auc = 0\n",
    "test_indices = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# Iterate only through the selected indices\n",
    "for i in test_indices:\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=SVC(),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',  # Evaluate using AUC score\n",
    "        cv=5               # 10-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for dataset {dataset_names[i]}: {best_params}\")\n",
    "    \n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> GAUSSIAN NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.7406\n",
      "  Validation Accuracy = 0.7303\n",
      "  Validation AUC = 0.6558\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.6679\n",
      "  Validation Accuracy = 0.6096\n",
      "  Validation AUC = 0.6047\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.8824\n",
      "  Validation Accuracy = 0.5833\n",
      "  Validation AUC = 0.4118\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.8696\n",
      "  Validation Accuracy = 0.9032\n",
      "  Validation AUC = 0.8363\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.8426\n",
      "  Validation Accuracy = 0.7397\n",
      "  Validation AUC = 0.7205\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9178\n",
      "  Validation AUC = 0.8846\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7636\n",
      "  Validation Accuracy = 0.7162\n",
      "  Validation AUC = 0.6622\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9749\n",
      "  Validation Accuracy = 0.9301\n",
      "  Validation AUC = 0.9100\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9028\n",
      "  Validation Accuracy = 0.8750\n",
      "  Validation AUC = 0.8783\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9902\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9559\n",
      "  Validation Accuracy = 0.9416\n",
      "  Validation AUC = 0.9375\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9749\n",
      "  Validation Accuracy = 0.9301\n",
      "  Validation AUC = 0.9100\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.8831\n",
      "  Validation Accuracy = 0.8654\n",
      "  Validation AUC = 0.8381\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.8177\n",
      "  Validation Accuracy = 0.8115\n",
      "  Validation AUC = 0.8090\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.6711\n",
      "  Validation Accuracy = 0.4808\n",
      "  Validation AUC = 0.5382\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8774\n",
      "  Validation Accuracy = 0.8662\n",
      "  Validation AUC = 0.8459\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7222\n",
      "  Validation Accuracy = 0.6750\n",
      "  Validation AUC = 0.5390\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.9012\n",
      "  Validation Accuracy = 0.7963\n",
      "  Validation AUC = 0.7559\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.7757\n",
      "  Validation Accuracy = 0.7361\n",
      "  Validation AUC = 0.7464\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9187\n",
      "  Validation Accuracy = 0.9398\n",
      "  Validation AUC = 0.9444\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7283\n",
      "  Validation AUC = 0.7115\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.7760\n",
      "  Validation Accuracy = 0.7967\n",
      "  Validation AUC = 0.7974\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.7317\n",
      "  Validation Accuracy = 0.5714\n",
      "  Validation AUC = 0.5714\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.7432\n",
      "  Validation Accuracy = 0.6982\n",
      "  Validation AUC = 0.6775\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.8333\n",
      "  Validation Accuracy = 0.7273\n",
      "  Validation AUC = 0.6500\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8676\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5503\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9653\n",
      "  Validation Accuracy = 0.9479\n",
      "  Validation AUC = 0.9526\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.7561\n",
      "  Validation Accuracy = 0.7364\n",
      "  Validation AUC = 0.7455\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7287\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 0.7700\n",
      "  Validation Accuracy = 0.6765\n",
      "  Validation AUC = 0.7027\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8962\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7927\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7081\n",
      "  Validation Accuracy = 0.6929\n",
      "  Validation AUC = 0.7397\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9389\n",
      "  Validation Accuracy = 0.9417\n",
      "  Validation AUC = 0.9465\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9058\n",
      "  Validation Accuracy = 0.9175\n",
      "  Validation AUC = 0.6572\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7287\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.8993\n",
      "  Validation Accuracy = 0.9219\n",
      "  Validation AUC = 0.8680\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 0.9861\n",
      "  Validation Accuracy = 0.8750\n",
      "  Validation AUC = 0.8875\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8676\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5503\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9062\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9681\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 0.7417\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8762\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7854\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 0.8824\n",
      "  Validation Accuracy = 0.6571\n",
      "  Validation AUC = 0.6700\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 0.9085\n",
      "  Validation Accuracy = 0.8421\n",
      "  Validation AUC = 0.8246\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.8957\n",
      "  Validation Accuracy = 0.9043\n",
      "  Validation AUC = 0.9151\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9433\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9037\n",
      "  Validation Accuracy = 0.9200\n",
      "  Validation AUC = 0.9081\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9548\n",
      "  Validation Accuracy = 0.9527\n",
      "  Validation AUC = 0.8709\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.8505\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.6614\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.8023\n",
      "  Validation Accuracy = 0.8793\n",
      "  Validation AUC = 0.8799\n",
      "Average AUC = 0.7622466588825504\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = GaussianNB(\n",
    "                var_smoothing=1e-2\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for dataset Dataset_1: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.3797\n",
      "  Validation Accuracy = 0.3539\n",
      "  Validation AUC = 0.5479\n",
      "Best parameters for dataset Dataset_10: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.6607\n",
      "  Validation Accuracy = 0.6150\n",
      "  Validation AUC = 0.6094\n",
      "Best parameters for dataset Dataset_11: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.8824\n",
      "  Validation Accuracy = 0.6667\n",
      "  Validation AUC = 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:982: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 971, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 376, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 640, in roc_auc_score\n",
      "    return _average_binary_score(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_base.py\", line 76, in _average_binary_score\n",
      "    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py\", line 382, in _binary_roc_auc_score\n",
      "    raise ValueError(\n",
      "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for dataset Dataset_12: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.8696\n",
      "  Validation Accuracy = 0.8871\n",
      "  Validation AUC = 0.8259\n",
      "Best parameters for dataset Dataset_13: {'var_smoothing': 1e-06}\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.6667\n",
      "  Validation Accuracy = 0.6301\n",
      "  Validation AUC = 0.6526\n",
      "Best parameters for dataset Dataset_14: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9041\n",
      "  Validation AUC = 0.8654\n",
      "Best parameters for dataset Dataset_15: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7636\n",
      "  Validation Accuracy = 0.7162\n",
      "  Validation AUC = 0.6622\n",
      "Best parameters for dataset Dataset_16: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.8853\n",
      "  Validation Accuracy = 0.8495\n",
      "  Validation AUC = 0.8057\n",
      "Best parameters for dataset Dataset_17: {'var_smoothing': 1e-08}\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.8472\n",
      "  Validation Accuracy = 0.7917\n",
      "  Validation AUC = 0.8042\n",
      "Best parameters for dataset Dataset_18: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9902\n",
      "  Validation Accuracy = 0.9926\n",
      "  Validation AUC = 0.8750\n",
      "Best parameters for dataset Dataset_19: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9559\n",
      "  Validation Accuracy = 0.9489\n",
      "  Validation AUC = 0.9433\n",
      "Best parameters for dataset Dataset_2: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.8853\n",
      "  Validation Accuracy = 0.8495\n",
      "  Validation AUC = 0.8057\n",
      "Best parameters for dataset Dataset_20: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.8831\n",
      "  Validation Accuracy = 0.8654\n",
      "  Validation AUC = 0.8381\n",
      "Best parameters for dataset Dataset_21: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.8177\n",
      "  Validation Accuracy = 0.8115\n",
      "  Validation AUC = 0.8090\n",
      "Best parameters for dataset Dataset_22: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.6711\n",
      "  Validation Accuracy = 0.4615\n",
      "  Validation AUC = 0.5069\n",
      "Best parameters for dataset Dataset_23: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8821\n",
      "  Validation Accuracy = 0.8803\n",
      "  Validation AUC = 0.8638\n",
      "Best parameters for dataset Dataset_24: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7222\n",
      "  Validation Accuracy = 0.6750\n",
      "  Validation AUC = 0.5336\n",
      "Best parameters for dataset Dataset_25: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.8765\n",
      "  Validation Accuracy = 0.8148\n",
      "  Validation AUC = 0.7706\n",
      "Best parameters for dataset Dataset_26: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.7664\n",
      "  Validation Accuracy = 0.7222\n",
      "  Validation AUC = 0.7236\n",
      "Best parameters for dataset Dataset_27: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9187\n",
      "  Validation Accuracy = 0.9398\n",
      "  Validation AUC = 0.9444\n",
      "Best parameters for dataset Dataset_28: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7283\n",
      "  Validation AUC = 0.7115\n",
      "Best parameters for dataset Dataset_29: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.7814\n",
      "  Validation Accuracy = 0.8211\n",
      "  Validation AUC = 0.8214\n",
      "Best parameters for dataset Dataset_3: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.7073\n",
      "  Validation Accuracy = 0.5714\n",
      "  Validation AUC = 0.5714\n",
      "Best parameters for dataset Dataset_30: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.5045\n",
      "  Validation Accuracy = 0.5586\n",
      "  Validation AUC = 0.6093\n",
      "Best parameters for dataset Dataset_31: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.7708\n",
      "  Validation Accuracy = 0.7273\n",
      "  Validation AUC = 0.4800\n",
      "Best parameters for dataset Dataset_32: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8620\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5600\n",
      "Best parameters for dataset Dataset_33: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9653\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9492\n",
      "Best parameters for dataset Dataset_34: {'var_smoothing': 1e-06}\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.7561\n",
      "  Validation Accuracy = 0.7364\n",
      "  Validation AUC = 0.7455\n",
      "Best parameters for dataset Dataset_35: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7287\n",
      "Best parameters for dataset Dataset_36: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 0.4900\n",
      "  Validation Accuracy = 0.3971\n",
      "  Validation AUC = 0.5152\n",
      "Best parameters for dataset Dataset_37: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8962\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.8009\n",
      "Best parameters for dataset Dataset_38: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7081\n",
      "  Validation Accuracy = 0.6929\n",
      "  Validation AUC = 0.7397\n",
      "Best parameters for dataset Dataset_39: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9278\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9411\n",
      "Best parameters for dataset Dataset_4: {'var_smoothing': 1e-07}\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.2240\n",
      "  Validation Accuracy = 0.1990\n",
      "  Validation AUC = 0.5833\n",
      "Best parameters for dataset Dataset_40: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8080\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7287\n",
      "Best parameters for dataset Dataset_41: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.8958\n",
      "  Validation Accuracy = 0.9271\n",
      "  Validation AUC = 0.8709\n",
      "Best parameters for dataset Dataset_42: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 0.9861\n",
      "  Validation Accuracy = 0.8750\n",
      "  Validation AUC = 0.8875\n",
      "Best parameters for dataset Dataset_43: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8620\n",
      "  Validation Accuracy = 0.8151\n",
      "  Validation AUC = 0.5600\n",
      "Best parameters for dataset Dataset_44: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9062\n",
      "Best parameters for dataset Dataset_45: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9681\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 0.7417\n",
      "Best parameters for dataset Dataset_46: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8762\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7854\n",
      "Best parameters for dataset Dataset_47: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 0.9020\n",
      "  Validation Accuracy = 0.6571\n",
      "  Validation AUC = 0.6700\n",
      "Best parameters for dataset Dataset_48: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 0.8873\n",
      "  Validation Accuracy = 0.8211\n",
      "  Validation AUC = 0.8007\n",
      "Best parameters for dataset Dataset_49: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.8986\n",
      "  Validation Accuracy = 0.9000\n",
      "  Validation AUC = 0.9119\n",
      "Best parameters for dataset Dataset_5: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9433\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.5000\n",
      "Best parameters for dataset Dataset_6: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9037\n",
      "  Validation Accuracy = 0.9200\n",
      "  Validation AUC = 0.9081\n",
      "Best parameters for dataset Dataset_7: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9502\n",
      "  Validation Accuracy = 0.9527\n",
      "  Validation AUC = 0.8709\n",
      "Best parameters for dataset Dataset_8: {'var_smoothing': 1e-09}\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.8692\n",
      "  Validation Accuracy = 0.7639\n",
      "  Validation AUC = 0.6877\n",
      "Best parameters for dataset Dataset_9: {'var_smoothing': 1e-06}\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.8256\n",
      "  Validation Accuracy = 0.8448\n",
      "  Validation AUC = 0.8453\n",
      "Average AUC = 0.7406092186504035\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid \n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "average_auc = 0\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=GaussianNB(),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',  # Evaluate using AUC score\n",
    "        cv=5               # 10-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for dataset {dataset_names[i]}: {best_params}\")\n",
    "    \n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "# Calculate and print the average AUC score\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> MLP CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.9850\n",
      "  Validation Accuracy = 0.7360\n",
      "  Validation AUC = 0.6660\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.8536\n",
      "  Validation Accuracy = 0.7594\n",
      "  Validation AUC = 0.7499\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9677\n",
      "  Validation AUC = 0.9792\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7945\n",
      "  Validation AUC = 0.7545\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8904\n",
      "  Validation AUC = 0.8547\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.9227\n",
      "  Validation Accuracy = 0.6689\n",
      "  Validation AUC = 0.6128\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9964\n",
      "  Validation Accuracy = 0.9624\n",
      "  Validation AUC = 0.9613\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 0.8333\n",
      "  Validation AUC = 0.8307\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9951\n",
      "  Validation Accuracy = 0.9343\n",
      "  Validation AUC = 0.9317\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9964\n",
      "  Validation Accuracy = 0.9624\n",
      "  Validation AUC = 0.9613\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8269\n",
      "  Validation AUC = 0.7855\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8607\n",
      "  Validation AUC = 0.8559\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.9737\n",
      "  Validation Accuracy = 0.7692\n",
      "  Validation AUC = 0.7812\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.9953\n",
      "  Validation Accuracy = 0.8521\n",
      "  Validation AUC = 0.8343\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.8056\n",
      "  Validation Accuracy = 0.7042\n",
      "  Validation AUC = 0.5855\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.9877\n",
      "  Validation Accuracy = 0.9259\n",
      "  Validation AUC = 0.9309\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7222\n",
      "  Validation AUC = 0.6600\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.9348\n",
      "  Validation Accuracy = 0.7663\n",
      "  Validation AUC = 0.7508\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.9945\n",
      "  Validation Accuracy = 0.8699\n",
      "  Validation AUC = 0.8680\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7143\n",
      "  Validation AUC = 0.7143\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.9909\n",
      "  Validation Accuracy = 0.6982\n",
      "  Validation AUC = 0.6682\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7576\n",
      "  Validation AUC = 0.6275\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8761\n",
      "  Validation Accuracy = 0.8235\n",
      "  Validation AUC = 0.4975\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9695\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.8415\n",
      "  Validation Accuracy = 0.8000\n",
      "  Validation AUC = 0.7930\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.9420\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.7140\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8529\n",
      "  Validation AUC = 0.8674\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9811\n",
      "  Validation Accuracy = 0.7746\n",
      "  Validation AUC = 0.7816\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.9713\n",
      "  Validation Accuracy = 0.6857\n",
      "  Validation AUC = 0.6027\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9790\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9675\n",
      "  Validation Accuracy = 0.9515\n",
      "  Validation AUC = 0.4949\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.9420\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.7140\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9965\n",
      "  Validation Accuracy = 0.9427\n",
      "  Validation AUC = 0.7692\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9828\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8761\n",
      "  Validation Accuracy = 0.8235\n",
      "  Validation AUC = 0.4975\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9844\n",
      "  Validation AUC = 0.9917\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9905\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7830\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6000\n",
      "  Validation AUC = 0.5700\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9789\n",
      "  Validation AUC = 0.9677\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9855\n",
      "  Validation Accuracy = 0.9261\n",
      "  Validation AUC = 0.9222\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.6168\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9947\n",
      "  Validation Accuracy = 0.9280\n",
      "  Validation AUC = 0.9471\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9865\n",
      "  Validation AUC = 0.9668\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7639\n",
      "  Validation AUC = 0.6877\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8621\n",
      "  Validation AUC = 0.8590\n",
      "Average AUC = 0.7926386955651706\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = MLPClassifier(\n",
    "                hidden_layer_sizes=(50,),\n",
    "                activation='relu',\n",
    "                solver='adam',\n",
    "                alpha=0.1,\n",
    "                batch_size=32,\n",
    "                learning_rate='adaptive',\n",
    "                learning_rate_init=0.001,\n",
    "                max_iter=4000,\n",
    "                random_state=0\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (50, 50), (100, 50), (150, 100), (100, 50, 25), (150, 100, 50)],\n",
    "    'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128, 256],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [200, 400]\n",
    "}\n",
    "\n",
    "average_auc = 0\n",
    "test_indices = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45]\n",
    "\n",
    "# Iterate only through the selected indices\n",
    "for i in test_indices:\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # Use GridSearchCV to find the best parameters\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=MLPClassifier(),\n",
    "        param_grid=param_grid,\n",
    "        scoring='roc_auc',  # Evaluate using AUC score\n",
    "        cv=5               # 10-fold cross-validation\n",
    "    )\n",
    "    \n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train.squeeze())\n",
    "    \n",
    "    # Get the best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    print(f\"Best parameters for dataset {dataset_names[i]}: {best_params}\")\n",
    "    \n",
    "    # Train the best model on the training data\n",
    "    best_model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_val_pred = best_model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.7820\n",
      "  Validation Accuracy = 0.7191\n",
      "  Validation AUC = 0.6037\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.7286\n",
      "  Validation Accuracy = 0.6952\n",
      "  Validation AUC = 0.6845\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.5833\n",
      "  Validation AUC = 0.4538\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.6848\n",
      "  Validation Accuracy = 0.7903\n",
      "  Validation AUC = 0.5863\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9537\n",
      "  Validation Accuracy = 0.8082\n",
      "  Validation AUC = 0.7651\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 0.9815\n",
      "  Validation Accuracy = 0.9178\n",
      "  Validation AUC = 0.9104\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7955\n",
      "  Validation Accuracy = 0.7297\n",
      "  Validation AUC = 0.6685\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9713\n",
      "  Validation Accuracy = 0.9409\n",
      "  Validation AUC = 0.9243\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9444\n",
      "  Validation Accuracy = 0.7917\n",
      "  Validation AUC = 0.7778\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9902\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9853\n",
      "  Validation Accuracy = 0.9343\n",
      "  Validation AUC = 0.9158\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9713\n",
      "  Validation Accuracy = 0.9409\n",
      "  Validation AUC = 0.9243\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9351\n",
      "  Validation Accuracy = 0.6923\n",
      "  Validation AUC = 0.6124\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.8840\n",
      "  Validation Accuracy = 0.8525\n",
      "  Validation AUC = 0.8497\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.7763\n",
      "  Validation Accuracy = 0.6923\n",
      "  Validation AUC = 0.6736\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8538\n",
      "  Validation Accuracy = 0.8169\n",
      "  Validation AUC = 0.8208\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7306\n",
      "  Validation Accuracy = 0.7167\n",
      "  Validation AUC = 0.5399\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.6667\n",
      "  Validation Accuracy = 0.6111\n",
      "  Validation AUC = 0.4956\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.8785\n",
      "  Validation Accuracy = 0.7361\n",
      "  Validation AUC = 0.6827\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 0.9889\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8261\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.6988\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.8306\n",
      "  Validation Accuracy = 0.8455\n",
      "  Validation AUC = 0.8417\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.7561\n",
      "  Validation Accuracy = 0.7143\n",
      "  Validation AUC = 0.7143\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.8066\n",
      "  Validation Accuracy = 0.6847\n",
      "  Validation AUC = 0.6532\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.8958\n",
      "  Validation Accuracy = 0.5455\n",
      "  Validation AUC = 0.4875\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9792\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9831\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.7988\n",
      "  Validation Accuracy = 0.8273\n",
      "  Validation AUC = 0.8276\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8188\n",
      "  Validation Accuracy = 0.7446\n",
      "  Validation AUC = 0.7031\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8382\n",
      "  Validation AUC = 0.8561\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8868\n",
      "  Validation Accuracy = 0.7606\n",
      "  Validation AUC = 0.7624\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7129\n",
      "  Validation Accuracy = 0.7286\n",
      "  Validation AUC = 0.6156\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9778\n",
      "  Validation Accuracy = 0.9625\n",
      "  Validation AUC = 0.9635\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9416\n",
      "  Validation Accuracy = 0.9369\n",
      "  Validation AUC = 0.4874\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8188\n",
      "  Validation Accuracy = 0.7446\n",
      "  Validation AUC = 0.7031\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9062\n",
      "  Validation Accuracy = 0.8958\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 0.9861\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9310\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9255\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 0.6250\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8952\n",
      "  Validation Accuracy = 0.7887\n",
      "  Validation AUC = 0.7818\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.4571\n",
      "  Validation AUC = 0.4400\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 0.9366\n",
      "  Validation Accuracy = 0.8632\n",
      "  Validation AUC = 0.8236\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9333\n",
      "  Validation Accuracy = 0.9217\n",
      "  Validation AUC = 0.9127\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9330\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9091\n",
      "  Validation Accuracy = 0.8480\n",
      "  Validation AUC = 0.8750\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9548\n",
      "  Validation Accuracy = 0.9527\n",
      "  Validation AUC = 0.8197\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.8318\n",
      "  Validation Accuracy = 0.7917\n",
      "  Validation AUC = 0.7403\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.8953\n",
      "  Validation Accuracy = 0.7586\n",
      "  Validation AUC = 0.7575\n",
      "Average AUC = 0.7322830807888722\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = RidgeClassifier(\n",
    "\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.7331\n",
      "  Validation Accuracy = 0.6966\n",
      "  Validation AUC = 0.5249\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.6071\n",
      "  Validation Accuracy = 0.5989\n",
      "  Validation AUC = 0.5458\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.5417\n",
      "  Validation AUC = 0.5924\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.6196\n",
      "  Validation Accuracy = 0.7419\n",
      "  Validation AUC = 0.5804\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 0.7397\n",
      "  Validation AUC = 0.6948\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9315\n",
      "  Validation AUC = 0.9124\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7682\n",
      "  Validation Accuracy = 0.6824\n",
      "  Validation AUC = 0.5900\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.9391\n",
      "  Validation Accuracy = 0.8925\n",
      "  Validation AUC = 0.8600\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9167\n",
      "  Validation Accuracy = 0.8125\n",
      "  Validation AUC = 0.7963\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9804\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9804\n",
      "  Validation Accuracy = 0.9197\n",
      "  Validation AUC = 0.9121\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.9391\n",
      "  Validation Accuracy = 0.8925\n",
      "  Validation AUC = 0.8600\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9481\n",
      "  Validation Accuracy = 0.8077\n",
      "  Validation AUC = 0.7703\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.8950\n",
      "  Validation Accuracy = 0.8607\n",
      "  Validation AUC = 0.8591\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.6579\n",
      "  Validation Accuracy = 0.7308\n",
      "  Validation AUC = 0.6146\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.8443\n",
      "  Validation Accuracy = 0.8099\n",
      "  Validation AUC = 0.8150\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.3389\n",
      "  Validation Accuracy = 0.3083\n",
      "  Validation AUC = 0.4877\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.6543\n",
      "  Validation Accuracy = 0.5000\n",
      "  Validation AUC = 0.4382\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.8505\n",
      "  Validation Accuracy = 0.7639\n",
      "  Validation AUC = 0.7282\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 0.9889\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.7717\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7317\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.7869\n",
      "  Validation Accuracy = 0.7642\n",
      "  Validation AUC = 0.7504\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.7317\n",
      "  Validation Accuracy = 0.7143\n",
      "  Validation AUC = 0.7143\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.7674\n",
      "  Validation Accuracy = 0.6351\n",
      "  Validation AUC = 0.5895\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.8125\n",
      "  Validation Accuracy = 0.8182\n",
      "  Validation AUC = 0.7100\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.7859\n",
      "  Validation Accuracy = 0.7353\n",
      "  Validation AUC = 0.6180\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9479\n",
      "  Validation AUC = 0.9475\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.5976\n",
      "  Validation Accuracy = 0.5909\n",
      "  Validation AUC = 0.6375\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.7246\n",
      "  Validation Accuracy = 0.6630\n",
      "  Validation AUC = 0.6232\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8529\n",
      "  Validation AUC = 0.8769\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.8113\n",
      "  Validation Accuracy = 0.6479\n",
      "  Validation AUC = 0.7060\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.5215\n",
      "  Validation Accuracy = 0.4786\n",
      "  Validation AUC = 0.6339\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9444\n",
      "  Validation Accuracy = 0.9458\n",
      "  Validation AUC = 0.9538\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.8506\n",
      "  Validation Accuracy = 0.8495\n",
      "  Validation AUC = 0.4419\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.7246\n",
      "  Validation Accuracy = 0.6630\n",
      "  Validation AUC = 0.6232\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9375\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.7988\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9655\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.7859\n",
      "  Validation Accuracy = 0.7353\n",
      "  Validation AUC = 0.6180\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9688\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9833\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8952\n",
      "  Validation Accuracy = 0.6901\n",
      "  Validation AUC = 0.6800\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6000\n",
      "  Validation AUC = 0.6300\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 0.9859\n",
      "  Validation Accuracy = 0.9579\n",
      "  Validation AUC = 0.9355\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9014\n",
      "  Validation Accuracy = 0.8826\n",
      "  Validation AUC = 0.9018\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9433\n",
      "  Validation Accuracy = 0.9154\n",
      "  Validation AUC = 0.6045\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9198\n",
      "  Validation Accuracy = 0.8480\n",
      "  Validation AUC = 0.8750\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.8914\n",
      "  Validation Accuracy = 0.9324\n",
      "  Validation AUC = 0.9618\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.7477\n",
      "  Validation Accuracy = 0.6667\n",
      "  Validation AUC = 0.6723\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.8953\n",
      "  Validation Accuracy = 0.7931\n",
      "  Validation AUC = 0.7921\n",
      "Average AUC = 0.7452340180432082\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = Perceptron(\n",
    "\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Analysis for Dataset Dataset_1 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1     Feature_2   Feature_3     Feature_4   Feature_5  \\\n",
      "count  444.000000  4.440000e+02  444.000000  4.440000e+02  444.000000   \n",
      "mean    -0.068125  1.074842e-01   -0.088803 -5.046446e-02   -0.049906   \n",
      "std      1.166078  9.984732e-01    1.082061  1.089111e+00    1.380507   \n",
      "min     -4.213054 -1.475731e+00   -4.413376 -4.184013e+00   -5.199337   \n",
      "25%     -0.636397 -4.460993e-01   -0.894214 -7.916493e-01   -0.623676   \n",
      "50%      0.166808  4.482200e-07   -0.179940 -2.241100e-07   -0.022320   \n",
      "75%      0.565979  7.916386e-01    0.565970  7.915840e-01    0.565949   \n",
      "max      1.464391  5.199337e+00    4.648853  4.564503e+00    5.199337   \n",
      "\n",
      "        Feature_6   Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  \\\n",
      "count  444.000000  444.000000  444.000000  444.000000  444.000000  444.000000   \n",
      "mean    -0.187660   -0.181520    4.250000    5.457207    1.952703    1.520270   \n",
      "std      1.479040    1.423924    2.025375    3.304073    1.407820    1.117092   \n",
      "min     -4.450963   -4.140607    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     -0.674490   -0.791736    3.000000    3.000000    1.000000    1.000000   \n",
      "50%     -0.067189   -0.119318    6.000000    5.000000    2.000000    2.000000   \n",
      "75%      0.636138    0.539817    6.000000    8.000000    3.000000    3.000000   \n",
      "max      5.199337    4.342817    6.000000   12.000000    4.000000    3.000000   \n",
      "\n",
      "       Feature_12  Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  \\\n",
      "count  444.000000  444.000000  444.000000  444.000000  444.000000  444.000000   \n",
      "mean     4.159910    4.238739    0.036036    0.290541    0.988739    0.547297   \n",
      "std      1.948343    2.455332    0.186590    0.671107    0.993141    0.498319   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      3.000000    2.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      5.000000    4.000000    0.000000    0.000000    1.000000    1.000000   \n",
      "75%      6.000000    7.000000    0.000000    0.000000    2.000000    1.000000   \n",
      "max      6.000000    8.000000    1.000000    3.000000    4.000000    1.000000   \n",
      "\n",
      "       Feature_18  Feature_19  Feature_20  \n",
      "count  444.000000  444.000000  444.000000  \n",
      "mean     0.078829    0.689189    3.930180  \n",
      "std      0.269775    0.968008    1.937416  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    3.000000  \n",
      "50%      0.000000    0.000000    4.000000  \n",
      "75%      0.000000    1.000000    5.000000  \n",
      "max      1.000000    3.000000    7.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -1.476110\n",
      "Feature_2     0.638791\n",
      "Feature_3    -0.052484\n",
      "Feature_4     0.515537\n",
      "Feature_5    -0.564210\n",
      "Feature_6    -0.977733\n",
      "Feature_7    -0.733690\n",
      "Feature_8    -0.654709\n",
      "Feature_9    -0.008980\n",
      "Feature_10    0.064712\n",
      "Feature_11   -0.016870\n",
      "Feature_12   -0.708090\n",
      "Feature_13   -0.014834\n",
      "Feature_14    4.995586\n",
      "Feature_15    2.147130\n",
      "Feature_16    0.744834\n",
      "Feature_17   -0.190686\n",
      "Feature_18    3.136512\n",
      "Feature_19    1.120929\n",
      "Feature_20   -0.011397\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         313\n",
      "1         131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_10 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  467.000000  467.000000  467.000000  467.000000  467.000000  467.000000   \n",
      "mean     0.003320   -0.079979    0.087469   -0.075298    0.005414    0.068128   \n",
      "std      0.835254    0.972585    1.040397    0.956276    1.008349    0.842869   \n",
      "min     -0.867096   -1.820848   -2.326220   -4.409311   -2.438976   -0.821160   \n",
      "25%     -0.867096   -0.639831   -0.680074   -0.685649   -0.714178   -0.821160   \n",
      "50%     -0.041082   -0.081967    0.045191   -0.083692    0.025086    0.083623   \n",
      "75%      0.626000    0.612584    0.746678    0.622548    0.795106    0.727911   \n",
      "max      2.728030    5.199337    5.199337    4.698359    5.199337    4.877777   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  \n",
      "count  467.000000  467.000000  467.000000  467.000000  467.000000  \n",
      "mean    -0.063309    1.657388    0.186296    0.453961    0.773019  \n",
      "std      0.926663    1.788844    0.483177    0.498410    0.419329  \n",
      "min     -1.782139    0.000000    0.000000    0.000000    0.000000  \n",
      "25%     -0.763662    0.000000    0.000000    0.000000    1.000000  \n",
      "50%     -0.077436    1.000000    0.000000    0.000000    1.000000  \n",
      "75%      0.610545    3.000000    0.000000    1.000000    1.000000  \n",
      "max      2.715907    6.000000    2.000000    1.000000    1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.461367\n",
      "Feature_2     0.218731\n",
      "Feature_3     0.954053\n",
      "Feature_4     0.051094\n",
      "Feature_5     0.072011\n",
      "Feature_6     0.648454\n",
      "Feature_7     0.170856\n",
      "Feature_8     0.941796\n",
      "Feature_9     2.620863\n",
      "Feature_10    0.185536\n",
      "Feature_11   -1.307772\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         273\n",
      "1         194\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_11 ===\n",
      "\n",
      "Feature distribution:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "count  58.000000  58.000000  58.000000  58.000000  58.000000  58.000000   \n",
      "mean   -0.209959   0.027099   0.162357  -0.043726   0.041765   0.179501   \n",
      "std     1.378685   0.047975   1.285130   1.047091   1.286220   1.012970   \n",
      "min    -5.199337  -0.031052  -1.686947  -2.081965  -1.031235  -0.630940   \n",
      "25%    -1.015064  -0.004341  -0.478001  -0.589934  -1.002748  -0.630940   \n",
      "50%    -0.154780   0.016630   0.051683  -0.084766  -0.360672  -0.031805   \n",
      "75%     0.615233   0.040339   0.650152   0.534473   0.718045   0.775503   \n",
      "max     2.521513   0.223673   5.199337   2.443075   5.199337   5.199337   \n",
      "\n",
      "       Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_53  \\\n",
      "count  58.000000  58.000000  58.000000   58.000000  ...   58.000000   \n",
      "mean    0.249982  -0.080793  -0.031132    0.054212  ...   -0.156651   \n",
      "std     1.161257   0.908989   1.065164    0.595005  ...    1.277632   \n",
      "min    -0.338387  -0.588975  -0.379470   -0.435021  ...   -5.199337   \n",
      "25%    -0.338387  -0.588975  -0.379470   -0.353720  ...   -1.053896   \n",
      "50%    -0.338387  -0.588975  -0.379470   -0.237373  ...   -0.115270   \n",
      "75%     0.776617   0.292174  -0.232208    0.278529  ...    0.589930   \n",
      "max     5.199337   4.205012   5.199337    1.836295  ...    2.866508   \n",
      "\n",
      "       Feature_54  Feature_55  Feature_56  Feature_57  Feature_58  Feature_59  \\\n",
      "count   58.000000   58.000000   58.000000   58.000000   58.000000   58.000000   \n",
      "mean    -0.106673   -0.166972   -0.141576   -0.157683   -0.107297   -0.157146   \n",
      "std      1.176202    1.397284    1.154946    1.294241    1.021538    1.526174   \n",
      "min     -5.199337   -5.199337   -5.199337   -5.199337   -5.199337   -5.199337   \n",
      "25%     -0.694864   -0.924063   -0.812206   -0.907604   -0.680554   -1.088991   \n",
      "50%      0.012992   -0.098272   -0.012668    0.041839    0.111870   -0.141211   \n",
      "75%      0.693587    0.607529    0.571358    0.651314    0.472420    0.620273   \n",
      "max      2.118946    2.967443    2.286972    2.072034    1.438802    5.199337   \n",
      "\n",
      "       Feature_60  Feature_61  Feature_62  \n",
      "count   58.000000   58.000000   58.000000  \n",
      "mean    -0.103431    0.226244    0.195524  \n",
      "std      1.480408    1.206136    1.474452  \n",
      "min     -5.199337   -1.769013   -5.199337  \n",
      "25%     -0.727247   -0.635555   -0.578403  \n",
      "50%     -0.006865    0.157147    0.172358  \n",
      "75%      0.659119    0.784742    0.787905  \n",
      "max      5.199337    3.058424    5.199337  \n",
      "\n",
      "[8 rows x 62 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -1.331190\n",
      "Feature_2     1.837117\n",
      "Feature_3     1.912801\n",
      "Feature_4    -0.119968\n",
      "Feature_5     2.288993\n",
      "                ...   \n",
      "Feature_58   -2.093274\n",
      "Feature_59   -0.350565\n",
      "Feature_60   -0.636486\n",
      "Feature_61    0.768598\n",
      "Feature_62    0.437950\n",
      "Length: 62, dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         47\n",
      "1         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_12 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5\n",
      "count  154.000000  154.000000  154.000000  154.000000  154.000000\n",
      "mean     0.043235    0.046214   -0.003503    0.193592   -0.091047\n",
      "std      0.936154    0.971242    1.046786    0.982035    1.128514\n",
      "min     -2.497490   -2.669569   -5.199337   -2.447721   -5.199337\n",
      "25%     -0.515072   -0.515220   -0.647267   -0.455453   -0.799044\n",
      "50%     -0.042205   -0.041161    0.090007    0.209211    0.008069\n",
      "75%      0.613242    0.726863    0.845434    0.812973    0.659039\n",
      "max      5.199337    3.437998    2.789179    3.142186    2.453066\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    1.021671\n",
      "Feature_2    0.358587\n",
      "Feature_3   -0.816574\n",
      "Feature_4   -0.033455\n",
      "Feature_5   -1.017708\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         111\n",
      "1          43\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_13 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  181.000000  181.000000   \n",
      "mean     0.024505    0.028122    0.055915    0.013686   -0.024637    0.116443   \n",
      "std      0.959121    1.062019    1.053731    1.018011    1.181388    0.921717   \n",
      "min     -5.199337   -5.199337   -5.199337   -4.428582   -5.012971   -5.122005   \n",
      "25%     -0.674498   -0.645628   -0.508492   -0.677919   -0.430727   -0.318285   \n",
      "50%     -0.000002    0.034818   -0.046441    0.003817    0.105051   -0.318285   \n",
      "75%      0.764697    0.764694    0.674484    0.754039    0.764710    0.738171   \n",
      "max      2.411810    5.199337    5.199337    4.585457    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_45  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  ...  181.000000   \n",
      "mean     0.053902    0.182952    0.069206    0.035678  ...    0.138122   \n",
      "std      1.015423    1.164812    0.896499    0.986223  ...    0.345985   \n",
      "min     -1.786154   -1.790154   -2.110880   -1.908411  ...    0.000000   \n",
      "25%     -0.565949   -0.538105   -0.551638   -0.708504  ...    0.000000   \n",
      "50%      0.027855    0.271916    0.118434    0.024012  ...    0.000000   \n",
      "75%      0.589456    0.757945    0.624977    0.640667  ...    0.000000   \n",
      "max      5.199337    5.199337    5.199337    5.199337  ...    1.000000   \n",
      "\n",
      "       Feature_46  Feature_47  Feature_48  Feature_49  Feature_50  Feature_51  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  181.000000  181.000000   \n",
      "mean     0.027624    0.414365    0.325967    0.038674    0.005525    0.055249   \n",
      "std      0.164349    0.493978    0.470035    0.193352    0.074329    0.229099   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    1.000000    1.000000    0.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Feature_52  Feature_53  Feature_54  \n",
      "count  181.000000  181.000000  181.000000  \n",
      "mean     0.027624    0.994475    1.944751  \n",
      "std      0.164349    0.268685    1.129030  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    1.000000    1.000000  \n",
      "50%      0.000000    1.000000    3.000000  \n",
      "75%      0.000000    1.000000    3.000000  \n",
      "max      1.000000    2.000000    3.000000  \n",
      "\n",
      "[8 rows x 54 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     -0.807568\n",
      "Feature_2      0.484433\n",
      "Feature_3      0.010697\n",
      "Feature_4     -0.055104\n",
      "Feature_5     -1.110294\n",
      "Feature_6     -0.075038\n",
      "Feature_7      1.305276\n",
      "Feature_8      1.554714\n",
      "Feature_9      0.822292\n",
      "Feature_10     0.788453\n",
      "Feature_11    -0.480031\n",
      "Feature_12     0.009201\n",
      "Feature_13    -0.899699\n",
      "Feature_14     0.598897\n",
      "Feature_15    -0.039675\n",
      "Feature_16     1.347174\n",
      "Feature_17    -0.434243\n",
      "Feature_18    -0.304806\n",
      "Feature_19     0.726448\n",
      "Feature_20    -1.160774\n",
      "Feature_21     1.009222\n",
      "Feature_22    -0.304246\n",
      "Feature_23     1.521296\n",
      "Feature_24     4.825200\n",
      "Feature_25     1.925785\n",
      "Feature_26     4.472377\n",
      "Feature_27    -0.190260\n",
      "Feature_28     1.605559\n",
      "Feature_29     4.177579\n",
      "Feature_30     4.825200\n",
      "Feature_31     1.072741\n",
      "Feature_32     0.721912\n",
      "Feature_33    -0.339856\n",
      "Feature_34     1.632510\n",
      "Feature_35    -0.421158\n",
      "Feature_36    -0.978347\n",
      "Feature_37     7.636422\n",
      "Feature_38     9.433096\n",
      "Feature_39     6.556197\n",
      "Feature_40     5.812692\n",
      "Feature_41    13.453624\n",
      "Feature_42     0.421158\n",
      "Feature_43    13.453624\n",
      "Feature_44     5.259138\n",
      "Feature_45     2.115249\n",
      "Feature_46     5.812692\n",
      "Feature_47     0.350591\n",
      "Feature_48     0.748785\n",
      "Feature_49     4.825200\n",
      "Feature_50    13.453624\n",
      "Feature_51     3.926000\n",
      "Feature_52     5.812692\n",
      "Feature_53    -0.227231\n",
      "Feature_54    -0.312031\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         129\n",
      "1          52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_14 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  181.000000  181.000000   \n",
      "mean     0.024505    0.028122    0.055915    0.013686   -0.024637    0.116443   \n",
      "std      0.959121    1.062019    1.053731    1.018011    1.181388    0.921717   \n",
      "min     -5.199337   -5.199337   -5.199337   -4.428582   -5.012971   -5.122005   \n",
      "25%     -0.674498   -0.645628   -0.508492   -0.677919   -0.430727   -0.318285   \n",
      "50%     -0.000002    0.034818   -0.046441    0.003817    0.105051   -0.318285   \n",
      "75%      0.764697    0.764694    0.674484    0.754039    0.764710    0.738171   \n",
      "max      2.411810    5.199337    5.199337    4.585457    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_48  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  ...  181.000000   \n",
      "mean     0.053902    0.182952    0.069206    0.035678  ...    0.325967   \n",
      "std      1.015423    1.164812    0.896499    0.986223  ...    0.470035   \n",
      "min     -1.786154   -1.790154   -2.110880   -1.908411  ...    0.000000   \n",
      "25%     -0.565949   -0.538105   -0.551638   -0.708504  ...    0.000000   \n",
      "50%      0.027855    0.271916    0.118434    0.024012  ...    0.000000   \n",
      "75%      0.589456    0.757945    0.624977    0.640667  ...    1.000000   \n",
      "max      5.199337    5.199337    5.199337    5.199337  ...    1.000000   \n",
      "\n",
      "       Feature_49  Feature_50  Feature_51  Feature_52  Feature_53  Feature_54  \\\n",
      "count  181.000000  181.000000  181.000000  181.000000  181.000000  181.000000   \n",
      "mean     0.038674    0.005525    0.055249    0.027624    0.994475    1.944751   \n",
      "std      0.193352    0.074329    0.229099    0.164349    0.268685    1.129030   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    1.000000    1.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    1.000000    3.000000   \n",
      "75%      0.000000    0.000000    0.000000    0.000000    1.000000    3.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    2.000000    3.000000   \n",
      "\n",
      "       Feature_55  Feature_56  Feature_57  \n",
      "count  181.000000  181.000000  181.000000  \n",
      "mean     0.563536    0.386740    0.381215  \n",
      "std      0.497322    0.488354    0.487033  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      1.000000    0.000000    0.000000  \n",
      "75%      1.000000    1.000000    1.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 57 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     -0.807568\n",
      "Feature_2      0.484433\n",
      "Feature_3      0.010697\n",
      "Feature_4     -0.055104\n",
      "Feature_5     -1.110294\n",
      "Feature_6     -0.075038\n",
      "Feature_7      1.305276\n",
      "Feature_8      1.554714\n",
      "Feature_9      0.822292\n",
      "Feature_10     0.788453\n",
      "Feature_11    -0.480031\n",
      "Feature_12     0.009201\n",
      "Feature_13    -0.899699\n",
      "Feature_14     0.598897\n",
      "Feature_15    -0.039675\n",
      "Feature_16     1.347174\n",
      "Feature_17    -0.434243\n",
      "Feature_18    -0.304806\n",
      "Feature_19     0.726448\n",
      "Feature_20    -1.160774\n",
      "Feature_21     1.009222\n",
      "Feature_22    -0.304246\n",
      "Feature_23     1.521296\n",
      "Feature_24     4.825200\n",
      "Feature_25     1.925785\n",
      "Feature_26     4.472377\n",
      "Feature_27    -0.190260\n",
      "Feature_28     1.605559\n",
      "Feature_29     4.177579\n",
      "Feature_30     4.825200\n",
      "Feature_31     1.072741\n",
      "Feature_32     0.721912\n",
      "Feature_33    -0.339856\n",
      "Feature_34     1.632510\n",
      "Feature_35    -0.421158\n",
      "Feature_36    -0.978347\n",
      "Feature_37     7.636422\n",
      "Feature_38     9.433096\n",
      "Feature_39     6.556197\n",
      "Feature_40     5.812692\n",
      "Feature_41    13.453624\n",
      "Feature_42     0.421158\n",
      "Feature_43    13.453624\n",
      "Feature_44     5.259138\n",
      "Feature_45     2.115249\n",
      "Feature_46     5.812692\n",
      "Feature_47     0.350591\n",
      "Feature_48     0.748785\n",
      "Feature_49     4.825200\n",
      "Feature_50    13.453624\n",
      "Feature_51     3.926000\n",
      "Feature_52     5.812692\n",
      "Feature_53    -0.227231\n",
      "Feature_54    -0.312031\n",
      "Feature_55    -0.258367\n",
      "Feature_56     0.469025\n",
      "Feature_57     0.493239\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         129\n",
      "1          52\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_15 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2     Feature_3   Feature_4   Feature_5  \\\n",
      "count  368.000000  368.000000  3.680000e+02  368.000000  368.000000   \n",
      "mean     0.003100    0.105456  1.907871e-02    0.041821   -0.081313   \n",
      "std      0.893526    0.844922  9.916538e-01    1.001738    0.619887   \n",
      "min     -5.199337   -0.688240 -5.199337e+00   -5.199337   -1.448869   \n",
      "25%     -0.641872   -0.688240 -6.744897e-01    0.163642    0.237111   \n",
      "50%      0.026695    0.114632  2.988134e-07    0.163642    0.237111   \n",
      "75%      0.694708    0.707461  6.467417e-01    0.163642    0.237111   \n",
      "max      1.652834    5.199337  5.199337e+00    5.199337    0.237111   \n",
      "\n",
      "        Feature_6   Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  \n",
      "count  368.000000  368.000000  368.000000  368.000000  368.000000  368.000000  \n",
      "mean     0.839674    0.663043    0.796196    0.239130    0.203804    1.046196  \n",
      "std      0.402786    0.479036    1.079553    0.427133    0.515997    0.788567  \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "25%      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "50%      1.000000    1.000000    0.000000    0.000000    0.000000    1.000000  \n",
      "75%      1.000000    1.000000    2.000000    0.000000    0.000000    2.000000  \n",
      "max      2.000000    2.000000    4.000000    1.000000    2.000000    2.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.571220\n",
      "Feature_2     1.360230\n",
      "Feature_3     0.340744\n",
      "Feature_4     1.829725\n",
      "Feature_5    -1.506584\n",
      "Feature_6    -1.209367\n",
      "Feature_7    -0.617794\n",
      "Feature_8     1.118446\n",
      "Feature_9     1.228165\n",
      "Feature_10    2.515449\n",
      "Feature_11   -0.081928\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         250\n",
      "1         118\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_16 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  465.000000  465.000000   \n",
      "mean     0.214109    0.030362    0.056169    0.017203   -0.002278   -0.003334   \n",
      "std      1.353015    0.865771    0.715750    0.882879    0.799785    0.692477   \n",
      "min     -1.501082   -1.185164   -0.566116   -1.253993   -0.887799   -0.462229   \n",
      "25%     -0.659247   -0.578436   -0.566116   -0.577446   -0.887799   -0.462229   \n",
      "50%      0.196560   -0.004463   -0.566116   -0.004561   -0.045586   -0.462229   \n",
      "75%      0.962083    0.640989    1.084821    0.641061    0.639472    0.618597   \n",
      "max      4.763001    5.199337    1.084821    5.199337    1.540333    1.153074   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_15  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  ...  465.000000   \n",
      "mean    -0.022774   -0.039463    0.059769   -0.014922  ...   -0.039313   \n",
      "std      0.823968    0.877960    0.523785    0.552901  ...    0.354394   \n",
      "min     -0.946552   -1.539814   -0.079304   -0.164407  ...   -0.086823   \n",
      "25%     -0.946552   -0.692065   -0.079304   -0.164407  ...   -0.086823   \n",
      "50%     -0.045547   -0.067432   -0.079304   -0.164407  ...   -0.086823   \n",
      "75%      0.643146    0.648769   -0.079304   -0.164407  ...   -0.086823   \n",
      "max      1.540333    1.558097    3.298740    2.669134  ...    5.199337   \n",
      "\n",
      "       Feature_16  Feature_17  Feature_18  Feature_19  Feature_20  Feature_21  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  465.000000  465.000000   \n",
      "mean     0.051865   -0.022066    0.011585   -0.030801   -0.068227   -0.022833   \n",
      "std      0.670109    0.470027    0.409416    0.824491    0.924216    0.658836   \n",
      "min     -0.228278   -0.132567   -0.083953   -0.888339   -1.819404   -0.340306   \n",
      "25%     -0.228278   -0.132567   -0.083953   -0.888339   -0.738453   -0.340306   \n",
      "50%     -0.228278   -0.132567   -0.083953   -0.135972   -0.098440   -0.340306   \n",
      "75%     -0.228278   -0.132567   -0.083953    0.622457    0.562750   -0.340306   \n",
      "max      5.199337    2.766405    4.030447    2.124404    2.141171    5.199337   \n",
      "\n",
      "       Feature_22  Feature_23  Feature_24  \n",
      "count  465.000000  465.000000  465.000000  \n",
      "mean     0.238710    0.055914    5.159140  \n",
      "std      0.588143    0.230003    2.390816  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    4.000000  \n",
      "50%      0.000000    0.000000    7.000000  \n",
      "75%      0.000000    0.000000    7.000000  \n",
      "max      2.000000    1.000000    7.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.781579\n",
      "Feature_2     0.533288\n",
      "Feature_3     0.466981\n",
      "Feature_4     0.459155\n",
      "Feature_5     0.350350\n",
      "Feature_6     0.913265\n",
      "Feature_7     0.308505\n",
      "Feature_8    -0.017070\n",
      "Feature_9     4.077867\n",
      "Feature_10    3.734744\n",
      "Feature_11    4.318304\n",
      "Feature_12    0.971385\n",
      "Feature_13    1.308743\n",
      "Feature_14    1.020560\n",
      "Feature_15    9.626531\n",
      "Feature_16    3.083902\n",
      "Feature_17    4.371754\n",
      "Feature_18    4.801186\n",
      "Feature_19    0.446815\n",
      "Feature_20   -0.043385\n",
      "Feature_21    2.355729\n",
      "Feature_22    2.316495\n",
      "Feature_23    3.878248\n",
      "Feature_24   -0.975988\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         287\n",
      "1         178\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_17 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  120.000000  120.000000  120.000000  120.000000  120.000000  120.000000   \n",
      "mean    -0.048357    0.006824    0.111019    0.139687    0.074164   -0.047246   \n",
      "std      1.331370    1.102360    1.012075    1.018815    0.967767    0.843872   \n",
      "min     -5.199337   -5.199337   -1.981322   -1.560818   -1.607878   -1.848596   \n",
      "25%     -0.584120   -0.764742   -0.576653   -0.518547   -0.548579   -0.731217   \n",
      "50%      0.073350   -0.026084   -0.020480    0.119228   -0.118036    0.092972   \n",
      "75%      0.764709    0.768795    0.824874    0.924017    0.719251    0.599843   \n",
      "max      5.199337    5.199337    5.199337    4.097063    5.199337    2.205513   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_15  \\\n",
      "count  120.000000  120.000000  120.000000  120.000000  ...  120.000000   \n",
      "mean    -0.039250   -0.034585   -0.148238    0.011217  ...    5.758333   \n",
      "std      1.111270    1.134136    1.304530    0.844707  ...    2.734762   \n",
      "min     -5.199337   -5.199337   -5.199337   -2.009874  ...    0.000000   \n",
      "25%     -0.726507   -0.659237   -0.764735   -0.610714  ...    4.000000   \n",
      "50%     -0.013628   -0.087523   -0.139832    0.139709  ...    7.000000   \n",
      "75%      0.679496    0.727826    0.438216    0.604585  ...    8.000000   \n",
      "max      3.304374    3.849468    4.634600    1.555506  ...    8.000000   \n",
      "\n",
      "       Feature_16  Feature_17  Feature_18  Feature_19  Feature_20  Feature_21  \\\n",
      "count  120.000000  120.000000  120.000000  120.000000  120.000000  120.000000   \n",
      "mean     0.916667    0.191667    0.408333    2.675000    1.325000    0.983333   \n",
      "std      0.277544    0.395263    0.493586    0.899696    0.567502    0.128556   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    0.000000    0.000000    2.000000    1.000000    1.000000   \n",
      "50%      1.000000    0.000000    0.000000    3.000000    1.000000    1.000000   \n",
      "75%      1.000000    0.000000    1.000000    3.000000    2.000000    1.000000   \n",
      "max      1.000000    1.000000    1.000000    4.000000    2.000000    1.000000   \n",
      "\n",
      "       Feature_22  Feature_23  Feature_24  \n",
      "count  120.000000  120.000000   120.00000  \n",
      "mean     1.933333    1.908333     2.62500  \n",
      "std      0.785727    0.579711     1.44979  \n",
      "min      0.000000    0.000000     0.00000  \n",
      "25%      2.000000    2.000000     1.00000  \n",
      "50%      2.000000    2.000000     3.00000  \n",
      "75%      2.000000    2.000000     4.00000  \n",
      "max      4.000000    3.000000     4.00000  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.856658\n",
      "Feature_2     0.037942\n",
      "Feature_3     1.003082\n",
      "Feature_4     0.381351\n",
      "Feature_5     1.302708\n",
      "Feature_6     0.044698\n",
      "Feature_7    -0.857884\n",
      "Feature_8    -0.887042\n",
      "Feature_9    -0.708167\n",
      "Feature_10   -0.239595\n",
      "Feature_11   -1.306079\n",
      "Feature_12    1.695279\n",
      "Feature_13    0.549744\n",
      "Feature_14    0.365865\n",
      "Feature_15   -0.887485\n",
      "Feature_16   -3.053414\n",
      "Feature_17    1.586588\n",
      "Feature_18    0.377727\n",
      "Feature_19   -0.644972\n",
      "Feature_20   -0.116250\n",
      "Feature_21   -7.646877\n",
      "Feature_22   -0.304269\n",
      "Feature_23   -1.575187\n",
      "Feature_24   -0.312075\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       63\n",
      "1.0       57\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_18 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  340.000000  340.000000  340.000000  340.000000  340.000000  340.000000   \n",
      "mean     0.024284   -0.002580    0.011444    0.094267   -0.001474    0.137196   \n",
      "std      1.235642    1.064873    0.644670    0.787181    0.418951    0.665872   \n",
      "min     -3.412010   -3.932424   -0.273478   -0.578372   -1.751080   -3.050248   \n",
      "25%     -0.773653   -0.509246   -0.273478   -0.578372   -0.045619    0.012025   \n",
      "50%      0.272962    0.114145   -0.273478   -0.578372   -0.045619    0.012025   \n",
      "75%      0.723394    0.680536   -0.273478    0.828362   -0.045619    0.012025   \n",
      "max      4.207087    4.352317    3.505438    3.945505    3.800163    2.476074   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  340.000000  340.000000  340.000000  340.000000  340.000000  340.000000   \n",
      "mean     3.141176    2.635294    2.202941    0.502941    0.176471    2.411765   \n",
      "std      2.683514    2.057275    1.646483    0.512375    0.381782    1.705754   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    0.000000    1.000000    0.000000    0.000000    1.000000   \n",
      "50%      2.000000    4.000000    2.000000    0.000000    0.000000    2.000000   \n",
      "75%      6.000000    4.000000    4.000000    1.000000    0.000000    4.000000   \n",
      "max      7.000000    5.000000    6.000000    2.000000    1.000000    5.000000   \n",
      "\n",
      "       Feature_13  Feature_14  \n",
      "count  340.000000  340.000000  \n",
      "mean     3.352941    2.414706  \n",
      "std      1.605344    1.656779  \n",
      "min      0.000000    0.000000  \n",
      "25%      3.000000    1.000000  \n",
      "50%      4.000000    2.000000  \n",
      "75%      5.000000    4.000000  \n",
      "max      5.000000    5.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.313218\n",
      "Feature_2    -0.552183\n",
      "Feature_3     2.088259\n",
      "Feature_4     0.830048\n",
      "Feature_5     3.570965\n",
      "Feature_6     1.717770\n",
      "Feature_7     0.315563\n",
      "Feature_8    -0.241855\n",
      "Feature_9     0.912538\n",
      "Feature_10    0.120550\n",
      "Feature_11    1.704868\n",
      "Feature_12   -0.031193\n",
      "Feature_13   -0.880748\n",
      "Feature_14    0.460044\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       321\n",
      "1.0        19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_19 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  341.000000  341.000000  341.000000  341.000000  341.000000  341.000000   \n",
      "mean     0.070748   -0.005605    0.072157    0.055729    0.027560    0.027582   \n",
      "std      0.964304    0.899084    0.969518    0.948661    0.205413    0.828639   \n",
      "min     -2.032784   -2.198278   -2.090111   -2.180312   -0.457596   -1.614739   \n",
      "25%     -0.577780   -0.700329   -0.538275   -0.586022   -0.132959   -0.668707   \n",
      "50%      0.057762    0.041930    0.080620    0.053913    0.024284    0.071684   \n",
      "75%      0.690226    0.642490    0.696104    0.679597    0.167341    0.593651   \n",
      "max      5.199337    1.810410    5.199337    5.199337    0.891841    1.900342   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_21  \\\n",
      "count  341.000000  341.000000  341.000000  341.000000  ...  341.000000   \n",
      "mean     0.059352    0.088257   -0.013707   -0.049405  ...    0.052113   \n",
      "std      0.907866    0.715033    0.608991    0.041906  ...    0.948853   \n",
      "min     -1.532044   -1.073767   -1.526670   -0.124829  ...   -2.031112   \n",
      "25%     -0.638459   -0.491335   -0.433770   -0.079913  ...   -0.594564   \n",
      "50%      0.051662   -0.084179   -0.065861   -0.057173  ...    0.053365   \n",
      "75%      0.709065    0.675459    0.342362   -0.027818  ...    0.756013   \n",
      "max      5.199337    2.272661    2.042458    0.151130  ...    5.199337   \n",
      "\n",
      "       Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  Feature_27  \\\n",
      "count  341.000000  341.000000  341.000000  341.000000  341.000000  341.000000   \n",
      "mean    -0.024746    0.041746    0.051429   -0.004003    0.025622   -0.003854   \n",
      "std      0.911796    0.946519    0.955963    0.473581    0.976555    0.894478   \n",
      "min     -2.465050   -2.111879   -2.099144   -1.017162   -1.988317   -1.969196   \n",
      "25%     -0.682100   -0.601204   -0.611526   -0.319725   -0.666698   -0.648903   \n",
      "50%      0.005160    0.057251    0.063918   -0.038070    0.013402    0.044195   \n",
      "75%      0.689812    0.689066    0.783344    0.291613    0.697763    0.655863   \n",
      "max      2.202465    5.199337    5.199337    1.441581    5.199337    2.059138   \n",
      "\n",
      "       Feature_28  Feature_29  Feature_30  \n",
      "count  341.000000  341.000000  341.000000  \n",
      "mean     0.047935    0.044313   -0.112589  \n",
      "std      0.871875    0.833946    0.284298  \n",
      "min     -1.743976   -1.900736   -0.513576  \n",
      "25%     -0.670560   -0.564437   -0.315560  \n",
      "50%      0.042607    0.037819   -0.183418  \n",
      "75%      0.671275    0.631449    0.013313  \n",
      "max      1.999767    1.884757    1.672746  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.618839\n",
      "Feature_2    -0.119369\n",
      "Feature_3     0.715615\n",
      "Feature_4     0.429401\n",
      "Feature_5     0.309905\n",
      "Feature_6     0.063353\n",
      "Feature_7     0.572497\n",
      "Feature_8     0.467615\n",
      "Feature_9     0.435647\n",
      "Feature_10    1.225925\n",
      "Feature_11    0.307731\n",
      "Feature_12   -0.818940\n",
      "Feature_13    0.067194\n",
      "Feature_14   -0.132394\n",
      "Feature_15    1.634658\n",
      "Feature_16    1.361629\n",
      "Feature_17    0.987938\n",
      "Feature_18    1.488279\n",
      "Feature_19    0.887271\n",
      "Feature_20    4.119544\n",
      "Feature_21    0.349988\n",
      "Feature_22   -0.065397\n",
      "Feature_23    0.355979\n",
      "Feature_24    0.306867\n",
      "Feature_25    0.290056\n",
      "Feature_26    0.734056\n",
      "Feature_27   -0.144843\n",
      "Feature_28    0.018946\n",
      "Feature_29   -0.055839\n",
      "Feature_30    1.649829\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         208\n",
      "1         133\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_2 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  465.000000  465.000000   \n",
      "mean     0.214109    0.030362    0.056169    0.017203   -0.002278   -0.003334   \n",
      "std      1.353015    0.865771    0.715750    0.882879    0.799785    0.692477   \n",
      "min     -1.501082   -1.185164   -0.566116   -1.253993   -0.887799   -0.462229   \n",
      "25%     -0.659247   -0.578436   -0.566116   -0.577446   -0.887799   -0.462229   \n",
      "50%      0.196560   -0.004463   -0.566116   -0.004561   -0.045586   -0.462229   \n",
      "75%      0.962083    0.640989    1.084821    0.641061    0.639472    0.618597   \n",
      "max      4.763001    5.199337    1.084821    5.199337    1.540333    1.153074   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_15  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  ...  465.000000   \n",
      "mean    -0.022774   -0.039463    0.059769   -0.014922  ...   -0.039313   \n",
      "std      0.823968    0.877960    0.523785    0.552901  ...    0.354394   \n",
      "min     -0.946552   -1.539814   -0.079304   -0.164407  ...   -0.086823   \n",
      "25%     -0.946552   -0.692065   -0.079304   -0.164407  ...   -0.086823   \n",
      "50%     -0.045547   -0.067432   -0.079304   -0.164407  ...   -0.086823   \n",
      "75%      0.643146    0.648769   -0.079304   -0.164407  ...   -0.086823   \n",
      "max      1.540333    1.558097    3.298740    2.669134  ...    5.199337   \n",
      "\n",
      "       Feature_16  Feature_17  Feature_18  Feature_19  Feature_20  Feature_21  \\\n",
      "count  465.000000  465.000000  465.000000  465.000000  465.000000  465.000000   \n",
      "mean     0.051865   -0.022066    0.011585   -0.030801   -0.068227   -0.022833   \n",
      "std      0.670109    0.470027    0.409416    0.824491    0.924216    0.658836   \n",
      "min     -0.228278   -0.132567   -0.083953   -0.888339   -1.819404   -0.340306   \n",
      "25%     -0.228278   -0.132567   -0.083953   -0.888339   -0.738453   -0.340306   \n",
      "50%     -0.228278   -0.132567   -0.083953   -0.135972   -0.098440   -0.340306   \n",
      "75%     -0.228278   -0.132567   -0.083953    0.622457    0.562750   -0.340306   \n",
      "max      5.199337    2.766405    4.030447    2.124404    2.141171    5.199337   \n",
      "\n",
      "       Feature_22  Feature_23  Feature_24  \n",
      "count  465.000000  465.000000  465.000000  \n",
      "mean     0.238710    0.055914    5.159140  \n",
      "std      0.588143    0.230003    2.390816  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    4.000000  \n",
      "50%      0.000000    0.000000    7.000000  \n",
      "75%      0.000000    0.000000    7.000000  \n",
      "max      2.000000    1.000000    7.000000  \n",
      "\n",
      "[8 rows x 24 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.781579\n",
      "Feature_2     0.533288\n",
      "Feature_3     0.466981\n",
      "Feature_4     0.459155\n",
      "Feature_5     0.350350\n",
      "Feature_6     0.913265\n",
      "Feature_7     0.308505\n",
      "Feature_8    -0.017070\n",
      "Feature_9     4.077867\n",
      "Feature_10    3.734744\n",
      "Feature_11    4.318304\n",
      "Feature_12    0.971385\n",
      "Feature_13    1.308743\n",
      "Feature_14    1.020560\n",
      "Feature_15    9.626531\n",
      "Feature_16    3.083902\n",
      "Feature_17    4.371754\n",
      "Feature_18    4.801186\n",
      "Feature_19    0.446815\n",
      "Feature_20   -0.043385\n",
      "Feature_21    2.355729\n",
      "Feature_22    2.316495\n",
      "Feature_23    3.878248\n",
      "Feature_24   -0.975988\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         287\n",
      "1         178\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_20 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
      "mean     0.142166    0.031662    0.122763   -0.040121   -0.033535    0.080916   \n",
      "std      1.319257    0.947350    1.135731    0.907124    1.238014    0.987899   \n",
      "min     -5.199337   -5.167721   -4.822929   -2.729252   -5.199337   -2.301715   \n",
      "25%     -0.602995   -0.513155   -0.627226   -0.688367   -0.764710   -0.580173   \n",
      "50%      0.185658    0.139712    0.212197    0.013586   -0.063398    0.068290   \n",
      "75%      0.841299    0.659946    0.817373    0.764695    0.596057    0.716940   \n",
      "max      5.199337    1.821247    5.199337    1.652068    5.166578    4.927129   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  129.000000  129.000000  129.000000  129.000000  129.000000  129.000000   \n",
      "mean     0.651163    0.457364    0.620155    0.511628    0.581395    0.341085   \n",
      "std      0.478460    0.500121    0.487240    0.600992    0.881207    0.475922   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      1.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    1.000000    1.000000    1.000000    2.000000    1.000000   \n",
      "max      1.000000    1.000000    1.000000    2.000000    2.000000    1.000000   \n",
      "\n",
      "       Feature_13  \n",
      "count  129.000000  \n",
      "mean     0.434109  \n",
      "std      0.497572  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      1.000000  \n",
      "max      1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.188750\n",
      "Feature_2    -1.365537\n",
      "Feature_3     0.036202\n",
      "Feature_4    -0.295275\n",
      "Feature_5    -0.443180\n",
      "Feature_6     0.831832\n",
      "Feature_7    -0.641822\n",
      "Feature_8     0.173186\n",
      "Feature_9    -0.500974\n",
      "Feature_10    0.722438\n",
      "Feature_11    0.931051\n",
      "Feature_12    0.678335\n",
      "Feature_13    0.269023\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         91\n",
      "1         38\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_21 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    -0.013943    0.021429    0.003742    0.243233   -0.035322   -0.033900   \n",
      "std      0.940749    0.928010    0.978447    1.584495    0.941616    1.002556   \n",
      "min     -2.355705   -2.470238   -5.199337   -5.199337   -5.199337   -5.199337   \n",
      "25%     -0.706059   -0.714542   -0.736787   -0.627385   -0.707056   -0.725891   \n",
      "50%     -0.017823    0.075624   -0.051413   -0.066881    0.039562    0.050371   \n",
      "75%      0.691536    0.615806    0.668369    0.665334    0.617436    0.648063   \n",
      "max      5.199337    2.260020    5.199337    4.399540    2.640476    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    -0.016819   -0.015662    0.020212   -0.003540    0.015074    0.017146   \n",
      "std      0.945718    0.917493    0.892274    0.931747    0.953397    0.929379   \n",
      "min     -2.414584   -3.760774   -1.399850   -4.406436   -4.083365   -5.199337   \n",
      "25%     -0.697394   -0.579803   -0.693828   -0.624354   -0.560691   -0.749300   \n",
      "50%      0.026234    0.031871   -0.046293   -0.060783    0.023466    0.124250   \n",
      "75%      0.674151    0.648506    0.546167    0.763530    0.643270    0.727121   \n",
      "max      5.199337    2.797411    4.107166    2.468759    3.681373    5.090231   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  \n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
      "mean     0.054424    0.048834    1.405941    0.534653    1.795380  \n",
      "std      1.279705    0.100890    0.882256    0.499623    1.138306  \n",
      "min     -4.343318   -0.144869    0.000000    0.000000    0.000000  \n",
      "25%     -0.622926   -0.029819    0.000000    0.000000    1.000000  \n",
      "50%      0.027851    0.043438    2.000000    1.000000    2.000000  \n",
      "75%      0.772814    0.107424    2.000000    1.000000    3.000000  \n",
      "max      4.444211    0.366602    2.000000    1.000000    3.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.435858\n",
      "Feature_2     0.160240\n",
      "Feature_3     0.102123\n",
      "Feature_4     1.374041\n",
      "Feature_5    -0.488802\n",
      "Feature_6    -0.098364\n",
      "Feature_7     0.406883\n",
      "Feature_8    -0.236612\n",
      "Feature_9     0.829476\n",
      "Feature_10   -0.310492\n",
      "Feature_11   -0.090636\n",
      "Feature_12   -0.114996\n",
      "Feature_13   -0.222340\n",
      "Feature_14    0.672691\n",
      "Feature_15   -0.890881\n",
      "Feature_16   -0.139640\n",
      "Feature_17   -0.459196\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       175\n",
      "1.0       128\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_22 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  128.000000  128.000000  128.000000  128.000000  128.000000  128.000000   \n",
      "mean     0.156991    0.031488   -0.001876    0.034639   -0.067475   -0.051792   \n",
      "std      0.008570    1.158372    0.898000    1.326596    1.320282    0.988062   \n",
      "min      0.136862   -5.199337   -1.343427   -5.199337   -5.199337   -1.480801   \n",
      "25%      0.151609   -0.614433   -0.703057   -0.629661   -0.775410   -0.761777   \n",
      "50%      0.155129    0.180555    0.059857   -0.003099   -0.162592   -0.027160   \n",
      "75%      0.158751    0.807722    0.769298    0.743120    0.735057    0.550579   \n",
      "max      0.198632    3.780298    1.435517    5.199337    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  \n",
      "count  128.000000  128.000000  128.000000  \n",
      "mean    -0.095293    0.109300    0.034832  \n",
      "std      1.245317    0.783177    0.683370  \n",
      "min     -5.199337   -0.241508   -0.415951  \n",
      "25%     -0.794350   -0.241508   -0.415951  \n",
      "50%      0.000349   -0.241508   -0.415951  \n",
      "75%      0.623339   -0.241508    0.678343  \n",
      "max      5.199337    5.199337    1.608315  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    1.886113\n",
      "Feature_2   -1.359746\n",
      "Feature_3   -0.146087\n",
      "Feature_4   -0.068709\n",
      "Feature_5   -0.058296\n",
      "Feature_6    1.063634\n",
      "Feature_7   -0.956648\n",
      "Feature_8    2.998788\n",
      "Feature_9    0.993177\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         81\n",
      "1         47\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_23 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  354.000000  354.000000  354.000000  354.000000  354.000000  354.000000   \n",
      "mean    -0.020140   -0.194905    0.002980    0.056403    0.027727    0.030969   \n",
      "std      0.902775    1.055877    0.980758    0.826357    0.924049    0.764349   \n",
      "min     -1.952972   -3.841816   -1.529941   -0.518673   -1.421009   -0.727335   \n",
      "25%     -0.576014   -0.788705   -0.748062   -0.518673   -0.604585   -0.727335   \n",
      "50%     -0.095818   -0.114223    0.102932   -0.518673   -0.000644   -0.057429   \n",
      "75%      0.605595    0.451138    0.635665    0.604588    0.747859    0.671647   \n",
      "max      5.199337    2.399377    5.199337    4.877777    5.199337    1.492724   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  354.000000  354.000000  354.000000  354.000000  354.000000  354.000000   \n",
      "mean     1.666667    1.245763    1.245763    3.550847    3.079096    0.485876   \n",
      "std      0.512359    0.462836    0.462836    2.855135    1.299145    0.500508   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    1.000000    1.000000    1.000000    3.000000    0.000000   \n",
      "50%      2.000000    1.000000    1.000000    3.000000    4.000000    0.000000   \n",
      "75%      2.000000    2.000000    2.000000    6.000000    4.000000    1.000000   \n",
      "max      2.000000    2.000000    2.000000    9.000000    4.000000    1.000000   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  \n",
      "count  354.000000  354.000000  354.000000  \n",
      "mean     0.392655    0.460452    1.087571  \n",
      "std      0.489032    0.499139    0.320611  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    1.000000  \n",
      "50%      0.000000    0.000000    1.000000  \n",
      "75%      1.000000    1.000000    1.000000  \n",
      "max      1.000000    1.000000    2.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.546417\n",
      "Feature_2    -0.982880\n",
      "Feature_3     0.758598\n",
      "Feature_4     1.722625\n",
      "Feature_5     0.317800\n",
      "Feature_6     0.423750\n",
      "Feature_7    -1.148524\n",
      "Feature_8     0.746884\n",
      "Feature_9     0.746884\n",
      "Feature_10    0.422365\n",
      "Feature_11   -1.207772\n",
      "Feature_12    0.056761\n",
      "Feature_13    0.441503\n",
      "Feature_14    0.159365\n",
      "Feature_15    1.835251\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         217\n",
      "1         137\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_24 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  600.000000  600.000000  600.000000  600.000000  600.000000  600.000000   \n",
      "mean     0.027833    0.051548   -0.039675    0.042515    0.022990    0.975000   \n",
      "std      1.252188    0.977545    1.039108    0.932483    0.939118    0.807545   \n",
      "min     -4.737202   -2.326352   -5.190458   -1.796753   -1.592918    0.000000   \n",
      "25%     -0.673401   -0.524407   -0.635657   -0.524397   -0.674492    0.000000   \n",
      "50%      0.025068    0.062705    0.025069    0.062708    0.000013    1.000000   \n",
      "75%      0.635657    0.674490    0.684882    0.674499    0.674500    2.000000   \n",
      "max      4.591025    5.199337    2.004789    5.166578    5.090231    2.000000   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  \n",
      "count  600.000000  600.000000  600.000000  600.000000  600.000000  \n",
      "mean     0.490000    1.645000    0.051667    0.518333    1.290000  \n",
      "std      0.500317    1.242933    0.221538    0.500081    1.423356  \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.000000    1.000000    0.000000    0.000000    0.000000  \n",
      "50%      0.000000    1.000000    0.000000    1.000000    1.000000  \n",
      "75%      1.000000    3.000000    0.000000    1.000000    2.000000  \n",
      "max      1.000000    4.000000    1.000000    1.000000    5.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.689675\n",
      "Feature_2     0.210849\n",
      "Feature_3    -1.228252\n",
      "Feature_4     0.202018\n",
      "Feature_5     0.242968\n",
      "Feature_6     0.045504\n",
      "Feature_7     0.040108\n",
      "Feature_8     0.221029\n",
      "Feature_9     4.061001\n",
      "Feature_10   -0.073567\n",
      "Feature_11    1.009320\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         426\n",
      "1         174\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_25 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6\n",
      "count  135.000000  135.000000  135.000000  135.000000  135.000000  135.000000\n",
      "mean    -0.052474   -0.015834   -0.090897   -0.133437    0.115161    0.082577\n",
      "std      1.153356    1.085332    1.030626    0.995714    1.254312    1.052368\n",
      "min     -5.199337   -2.966320   -5.199337   -5.199337   -1.771257   -4.938058\n",
      "25%     -0.623744   -0.709684   -0.732321   -0.811555   -0.687655   -0.626985\n",
      "50%      0.024252    0.088249   -0.017103   -0.120984   -0.071038    0.149134\n",
      "75%      0.758159    0.774612    0.682433    0.611948    0.986593    0.839428\n",
      "max      5.199337    5.199337    3.230228    1.491033    4.301982    5.199337\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1   -0.373428\n",
      "Feature_2    0.327897\n",
      "Feature_3   -0.756084\n",
      "Feature_4   -1.036621\n",
      "Feature_5    1.277556\n",
      "Feature_6   -0.036241\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         87\n",
      "1         48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_26 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  179.000000  179.000000  179.000000  179.000000  179.000000  179.000000   \n",
      "mean    -0.006919   -0.008946   -0.095901   -0.147655   -0.007086   -0.001563   \n",
      "std      1.138086    0.906765    0.984802    0.965014    0.855036    1.129248   \n",
      "min     -5.199337   -5.199337   -5.073793   -4.787157   -1.876673   -5.199337   \n",
      "25%     -0.664229   -0.589243   -0.764711   -0.764710   -0.064910   -0.864513   \n",
      "50%     -0.175213   -0.037785   -0.139709   -0.139691   -0.064910   -0.139703   \n",
      "75%      0.549473    0.764924    0.604585    0.350810   -0.064910    0.664023   \n",
      "max      5.199337    1.892095    5.199337    2.085352    5.199337    4.927129   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_18  \\\n",
      "count  179.000000  179.000000  179.000000  179.000000  ...  179.000000   \n",
      "mean     0.034978   -0.017582   -0.019603    0.011173  ...    2.592179   \n",
      "std      0.919020    0.802388    1.152648    0.105406  ...    1.644243   \n",
      "min     -4.530329   -1.619508   -1.311835    0.000000  ...    0.000000   \n",
      "25%     -0.657497    0.096148   -0.897226    0.000000  ...    1.000000   \n",
      "50%     -0.054314    0.096148    0.112942    0.000000  ...    3.000000   \n",
      "75%      0.829329    0.096148    0.461541    0.000000  ...    4.000000   \n",
      "max      1.786156    2.927791    5.199337    1.000000  ...    5.000000   \n",
      "\n",
      "       Feature_19  Feature_20  Feature_21  Feature_22  Feature_23  Feature_24  \\\n",
      "count  179.000000  179.000000  179.000000  179.000000  179.000000  179.000000   \n",
      "mean     2.301676    2.022346    1.368715    2.044693    2.363128    2.396648   \n",
      "std      1.184425    1.445471    1.266830    0.964663    1.178927    1.282637   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      1.000000    1.000000    0.000000    2.000000    1.000000    1.000000   \n",
      "50%      3.000000    2.000000    1.000000    2.000000    3.000000    3.000000   \n",
      "75%      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
      "max      4.000000    4.000000    3.000000    3.000000    4.000000    5.000000   \n",
      "\n",
      "       Feature_25  Feature_26  Feature_27  \n",
      "count  179.000000  179.000000  179.000000  \n",
      "mean     1.687151    0.603352    0.351955  \n",
      "std      0.900937    0.490574    0.478920  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      1.000000    0.000000    0.000000  \n",
      "50%      2.000000    1.000000    0.000000  \n",
      "75%      2.000000    1.000000    1.000000  \n",
      "max      3.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 27 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.217083\n",
      "Feature_2    -1.064197\n",
      "Feature_3     0.278608\n",
      "Feature_4    -0.581464\n",
      "Feature_5     2.532494\n",
      "Feature_6     0.481753\n",
      "Feature_7    -0.514614\n",
      "Feature_8     0.049193\n",
      "Feature_9     1.925277\n",
      "Feature_10    9.379932\n",
      "Feature_11    0.000000\n",
      "Feature_12   -0.378323\n",
      "Feature_13    3.491774\n",
      "Feature_14    0.077999\n",
      "Feature_15   -0.442845\n",
      "Feature_16   -0.446158\n",
      "Feature_17    1.095210\n",
      "Feature_18   -0.122815\n",
      "Feature_19   -0.297166\n",
      "Feature_20    0.073489\n",
      "Feature_21    0.248824\n",
      "Feature_22   -0.811531\n",
      "Feature_23   -0.239530\n",
      "Feature_24    0.062919\n",
      "Feature_25   -0.597585\n",
      "Feature_26   -0.426112\n",
      "Feature_27    0.625230\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         114\n",
      "1          65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_27 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6\n",
      "count  206.000000  206.000000  206.000000  206.000000  206.000000  206.000000\n",
      "mean    -0.071736    0.042795   -0.019313   -0.113870    0.684466    0.519417\n",
      "std      1.016790    1.024186    1.003793    1.165855    0.740765    0.556217\n",
      "min     -5.199337   -2.085752   -5.199337   -5.199337    0.000000    0.000000\n",
      "25%     -0.687665   -0.636309   -0.674491   -0.764710    0.000000    0.000000\n",
      "50%      0.104624   -0.039904   -0.069686   -0.059801    1.000000    0.000000\n",
      "75%      0.615298    0.634797    0.622931    0.681455    1.000000    1.000000\n",
      "max      2.051155    5.199337    5.199337    5.199337    2.000000    2.000000\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1   -1.223865\n",
      "Feature_2    1.233344\n",
      "Feature_3    0.240117\n",
      "Feature_4   -0.749120\n",
      "Feature_5    0.581133\n",
      "Feature_6    0.438082\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         114\n",
      "1          92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_28 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  460.000000  460.000000  460.000000  460.000000  460.000000  460.000000   \n",
      "mean     0.059816   -0.021654   -0.025359   -0.020796   -0.027362   -0.056671   \n",
      "std      0.993947    1.077432    0.968599    0.883728    0.946923    0.951828   \n",
      "min     -1.426992   -5.199337   -5.199337   -2.393947   -5.199337   -4.561380   \n",
      "25%     -0.773767   -0.727913   -0.622934   -0.692072   -0.651605   -0.652174   \n",
      "50%      0.083616   -0.083651   -0.083304    0.018732    0.159248   -0.083635   \n",
      "75%      0.622988    0.674490    0.706304    0.622927    0.159248    0.594206   \n",
      "max      5.199337    5.199337    5.199337    1.633419    2.075452    1.828936   \n",
      "\n",
      "        Feature_7   Feature_8  \n",
      "count  460.000000  460.000000  \n",
      "mean    -0.005373    0.013017  \n",
      "std      0.920948    0.938929  \n",
      "min     -2.778992   -1.621861  \n",
      "25%     -0.602744   -0.622943  \n",
      "50%     -0.034779   -0.000004  \n",
      "75%      0.667360    0.727914  \n",
      "max      2.820177    1.918879  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.768816\n",
      "Feature_2    0.374948\n",
      "Feature_3    0.045343\n",
      "Feature_4   -0.090799\n",
      "Feature_5   -0.809444\n",
      "Feature_6   -0.441914\n",
      "Feature_7   -0.022876\n",
      "Feature_8   -0.000224\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         299\n",
      "1         161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_29 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  306.000000  306.000000  306.000000  306.000000  306.000000  306.000000   \n",
      "mean    -0.081019    0.127676   -0.062130    0.003720   -0.022594    0.167015   \n",
      "std      0.897367    0.744772    0.945163    0.940595    0.940223    1.519330   \n",
      "min     -2.052602   -0.254636   -5.199337   -2.021098   -5.199337   -5.199337   \n",
      "25%     -0.754153   -0.254636   -0.607024   -0.730354   -0.717496   -0.711990   \n",
      "50%     -0.085721   -0.254636    0.015779    0.014973   -0.039803    0.023451   \n",
      "75%      0.618074   -0.254636    0.611813    0.591088    0.651518    0.620103   \n",
      "max      1.661737    5.199337    4.648853    2.451036    3.843855    4.392496   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  306.000000  306.000000  306.000000  306.000000  306.000000  306.000000   \n",
      "mean     0.021199   -0.146115   -0.010488   -0.017649    0.047729    0.068627   \n",
      "std      0.980414    1.171290    1.052506    1.054968    1.004287    0.253234   \n",
      "min     -5.199337   -5.199337   -4.205360   -5.199337   -5.199337    0.000000   \n",
      "25%     -0.638624   -0.804835   -0.604611   -0.613948   -0.635369    0.000000   \n",
      "50%      0.038374   -0.064428    0.083337    0.059730    0.033227    0.000000   \n",
      "75%      0.682888    0.494156    0.620939    0.669768    0.726259    0.000000   \n",
      "max      4.585457    5.199337    5.199337    1.252789    5.199337    1.000000   \n",
      "\n",
      "       Feature_13  \n",
      "count  306.000000  \n",
      "mean     2.401961  \n",
      "std      1.956543  \n",
      "min      0.000000  \n",
      "25%      1.000000  \n",
      "50%      2.000000  \n",
      "75%      3.000000  \n",
      "max      6.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.097906\n",
      "Feature_2     2.277333\n",
      "Feature_3    -0.190232\n",
      "Feature_4     0.430770\n",
      "Feature_5    -0.253633\n",
      "Feature_6     1.368648\n",
      "Feature_7    -0.268483\n",
      "Feature_8    -1.270501\n",
      "Feature_9     0.442670\n",
      "Feature_10   -1.049256\n",
      "Feature_11    0.339433\n",
      "Feature_12    3.429327\n",
      "Feature_13    0.456141\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       175\n",
      "1.0       131\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_3 ===\n",
      "\n",
      "Feature distribution:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "count  69.000000  69.000000  69.000000  69.000000  69.000000  69.000000   \n",
      "mean    0.165822   0.114523  -0.241394  -0.063479  -0.079091   0.129411   \n",
      "std     0.959170   1.501861   1.406143   0.951160   1.155175   1.326293   \n",
      "min    -1.833919  -5.199337  -5.199337  -1.867280  -3.790537  -2.658188   \n",
      "25%    -0.430736  -0.764695  -0.764705  -0.777255  -0.891861  -0.812381   \n",
      "50%     0.246163  -0.001333  -0.069680  -0.116156  -0.041578   0.077707   \n",
      "75%     0.876142   0.751106   0.535084   0.622061   0.709373   0.822660   \n",
      "max     1.949122   5.199337   2.800113   2.090512   4.515455   5.199337   \n",
      "\n",
      "       Feature_7  Feature_8  Feature_9  \n",
      "count  69.000000  69.000000  69.000000  \n",
      "mean   -0.202482  -0.104632   0.003819  \n",
      "std     1.247500   1.325162   1.393438  \n",
      "min    -5.199337  -5.199337  -5.199337  \n",
      "25%    -0.912483  -0.764689  -0.851049  \n",
      "50%    -0.374231  -0.012115   0.135712  \n",
      "75%     0.542476   0.583538   0.724458  \n",
      "max     5.199337   5.035406   5.199337  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1   -0.158997\n",
      "Feature_2    0.827887\n",
      "Feature_3   -1.604237\n",
      "Feature_4    0.058951\n",
      "Feature_5    0.340650\n",
      "Feature_6    1.408273\n",
      "Feature_7    0.296128\n",
      "Feature_8   -0.180786\n",
      "Feature_9    0.629531\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         35\n",
      "0         34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_30 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  553.000000  553.000000  553.000000  553.000000  553.000000  553.000000   \n",
      "mean     0.007182    0.027929   -0.021493    0.015541   -0.011392    0.002030   \n",
      "std      1.008836    0.975115    0.949454    0.968705    0.950175    0.919704   \n",
      "min     -4.934463   -2.209387   -5.199337   -5.199337   -4.765190   -1.993708   \n",
      "25%     -0.708219   -0.680929   -0.661761   -0.687312   -0.718565   -0.674317   \n",
      "50%      0.002799    0.023269   -0.021065   -0.009971    0.228519    0.100550   \n",
      "75%      0.609724    0.683858    0.627782    0.739021    0.631014    0.604987   \n",
      "max      5.199337    5.199337    5.199337    4.596740    5.035406    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_26  \\\n",
      "count  553.000000  553.000000  553.000000  553.000000  ...  553.000000   \n",
      "mean    -0.174259   -0.023033    0.018188    1.253165  ...    0.323689   \n",
      "std      1.202125    1.047935    0.917915    1.245686  ...    0.468307   \n",
      "min     -4.087315   -5.199337   -1.132559    0.000000  ...    0.000000   \n",
      "25%     -0.716262   -0.684599   -0.645799    0.000000  ...    0.000000   \n",
      "50%     -0.139814   -0.018141   -0.000082    1.000000  ...    0.000000   \n",
      "75%      0.589472    0.707708    0.645619    2.000000  ...    1.000000   \n",
      "max      5.199337    5.199337    5.199337    4.000000  ...    1.000000   \n",
      "\n",
      "       Feature_27  Feature_28  Feature_29  Feature_30  Feature_31  Feature_32  \\\n",
      "count  553.000000  553.000000  553.000000  553.000000  553.000000  553.000000   \n",
      "mean     0.316456    0.280289    0.502712    0.381555    0.240506    0.083183   \n",
      "std      0.465514    0.449547    0.500445    0.486208    0.427778    0.276408   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    1.000000    1.000000    1.000000    0.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Feature_33  Feature_34  Feature_35  \n",
      "count  553.000000       553.0       553.0  \n",
      "mean     0.795660         0.0         0.0  \n",
      "std      0.403584         0.0         0.0  \n",
      "min      0.000000         0.0         0.0  \n",
      "25%      1.000000         0.0         0.0  \n",
      "50%      1.000000         0.0         0.0  \n",
      "75%      1.000000         0.0         0.0  \n",
      "max      1.000000         0.0         0.0  \n",
      "\n",
      "[8 rows x 35 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     -0.065452\n",
      "Feature_2      0.213409\n",
      "Feature_3      0.041630\n",
      "Feature_4     -0.089172\n",
      "Feature_5     -0.006624\n",
      "Feature_6      0.293980\n",
      "Feature_7     -1.193861\n",
      "Feature_8     -0.205850\n",
      "Feature_9      0.585089\n",
      "Feature_10     0.769867\n",
      "Feature_11     0.422417\n",
      "Feature_12    -0.054417\n",
      "Feature_13     2.354649\n",
      "Feature_14     2.864242\n",
      "Feature_15     4.389970\n",
      "Feature_16     1.288977\n",
      "Feature_17     1.887414\n",
      "Feature_18     1.728200\n",
      "Feature_19     2.753373\n",
      "Feature_20     3.419034\n",
      "Feature_21     3.535323\n",
      "Feature_22     4.291669\n",
      "Feature_23     5.282724\n",
      "Feature_24     5.126728\n",
      "Feature_25    23.515952\n",
      "Feature_26     0.755706\n",
      "Feature_27     0.791428\n",
      "Feature_28     0.981023\n",
      "Feature_29    -0.010880\n",
      "Feature_30     0.488987\n",
      "Feature_31     1.217620\n",
      "Feature_32     3.026903\n",
      "Feature_33    -1.470492\n",
      "Feature_34     0.000000\n",
      "Feature_35     0.000000\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         355\n",
      "1         198\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_31 ===\n",
      "\n",
      "Feature distribution:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "count  81.000000  81.000000  81.000000  81.000000  81.000000  81.000000   \n",
      "mean    0.134059  -0.033681  -0.022223   0.105749   0.085139  -0.027029   \n",
      "std     1.090544   1.101594   1.195589   1.091817   1.199315   1.344153   \n",
      "min    -1.871715  -5.199337  -2.640014  -2.190591  -5.199337  -5.199337   \n",
      "25%    -0.585735  -0.801097  -0.671710  -0.580971  -0.503504  -0.535083   \n",
      "50%     0.139639   0.154752  -0.139373   0.032709   0.045988   0.139710   \n",
      "75%     0.828608   0.734557   0.782613   0.777146   0.766910   0.764710   \n",
      "max     5.199337   2.269280   5.199337   5.199337   5.199337   5.199337   \n",
      "\n",
      "       Feature_7  Feature_8  Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  81.000000  81.000000  81.000000   81.000000   81.000000   81.000000   \n",
      "mean    0.135018   1.975309   4.506173    4.604938    4.530864    0.024691   \n",
      "std     1.080819   1.524593   2.894492    2.926940    2.617663    0.156150   \n",
      "min    -1.786165   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
      "25%    -0.589452   1.000000   2.000000    2.000000    2.000000    0.000000   \n",
      "50%     0.139729   2.000000   4.000000    5.000000    5.000000    0.000000   \n",
      "75%     0.764717   3.000000   7.000000    7.000000    7.000000    0.000000   \n",
      "max     5.199337   5.000000   9.000000    9.000000    9.000000    1.000000   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  \n",
      "count   81.000000   81.000000   81.000000  \n",
      "mean     1.555556    4.691358    1.037037  \n",
      "std      0.866025    2.644059    0.813087  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      2.000000    2.000000    0.000000  \n",
      "50%      2.000000    5.000000    1.000000  \n",
      "75%      2.000000    7.000000    2.000000  \n",
      "max      3.000000    9.000000    2.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.089623\n",
      "Feature_2    -1.233524\n",
      "Feature_3     0.741814\n",
      "Feature_4     0.973900\n",
      "Feature_5    -0.126489\n",
      "Feature_6    -0.739530\n",
      "Feature_7     1.166527\n",
      "Feature_8     0.194487\n",
      "Feature_9     0.014118\n",
      "Feature_10   -0.052508\n",
      "Feature_11   -0.112993\n",
      "Feature_12    6.241983\n",
      "Feature_13   -1.122544\n",
      "Feature_14   -0.110079\n",
      "Feature_15   -0.068683\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         59\n",
      "1         22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_32 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4\n",
      "count  593.000000  593.000000  593.000000  593.000000\n",
      "mean     0.058206    0.767285    0.517707    0.817875\n",
      "std      0.976148    0.609449    0.500108    0.386273\n",
      "min     -2.558036    0.000000    0.000000    0.000000\n",
      "25%     -0.589453    0.000000    0.000000    1.000000\n",
      "50%      0.075270    1.000000    1.000000    1.000000\n",
      "75%      0.674488    1.000000    1.000000    1.000000\n",
      "max      5.199337    2.000000    1.000000    1.000000\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.405656\n",
      "Feature_2    0.172102\n",
      "Feature_3   -0.071051\n",
      "Feature_4   -1.651427\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         506\n",
      "1          87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_33 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  240.000000  240.000000  240.000000  240.000000  240.000000  240.000000   \n",
      "mean     0.167842    0.043945    0.085474    0.002531   -0.013697   -0.091246   \n",
      "std      0.026445    0.992563    1.067115    0.975142    0.947516    1.083519   \n",
      "min      0.094300   -5.199337   -1.786044   -5.199337   -3.739107   -5.199337   \n",
      "25%      0.155912   -0.662054   -0.589181   -0.764721   -0.727123   -0.771969   \n",
      "50%      0.179683    0.092971    0.104713   -0.121969    0.194902   -0.139062   \n",
      "75%      0.179683    0.822984    0.768316    0.764703    0.633231    0.524566   \n",
      "max      0.203555    5.199337    5.199337    5.199337    4.763001    4.060370   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  240.000000  240.000000  240.000000  240.000000  240.000000  240.000000   \n",
      "mean     0.010587   -0.106652    0.123036    2.479167    1.058333    0.158333   \n",
      "std      0.890421    1.012480    0.629151    1.287038    1.282622    0.365816   \n",
      "min     -1.623067   -5.199337   -0.391783    0.000000    0.000000    0.000000   \n",
      "25%     -0.723886   -0.802379   -0.391783    2.000000    0.000000    0.000000   \n",
      "50%      0.124529   -0.005743   -0.391783    2.500000    1.000000    0.000000   \n",
      "75%      0.706387    0.588745    0.895411    3.000000    2.000000    0.000000   \n",
      "max      5.199337    4.107166    0.895411    5.000000    5.000000    1.000000   \n",
      "\n",
      "       Feature_13  \n",
      "count  240.000000  \n",
      "mean     0.887500  \n",
      "std      0.316641  \n",
      "min      0.000000  \n",
      "25%      1.000000  \n",
      "50%      1.000000  \n",
      "75%      1.000000  \n",
      "max      1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.502692\n",
      "Feature_2    -0.011696\n",
      "Feature_3     1.082912\n",
      "Feature_4    -0.048474\n",
      "Feature_5    -0.040532\n",
      "Feature_6    -0.221171\n",
      "Feature_7     0.757340\n",
      "Feature_8    -0.789511\n",
      "Feature_9     0.411104\n",
      "Feature_10   -0.000998\n",
      "Feature_11    1.030078\n",
      "Feature_12    1.883666\n",
      "Feature_13   -2.468135\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         152\n",
      "1          88\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_34 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  274.000000  274.000000  274.000000  274.000000  274.000000  274.000000   \n",
      "mean     0.019014   -0.009933   -0.004889    0.110009    0.044824    0.031238   \n",
      "std      0.968670    0.948206    0.936850    0.453850    0.813991    0.719155   \n",
      "min     -1.376935   -1.416759   -1.356357    0.000204   -0.603432   -0.592422   \n",
      "25%     -0.687015   -0.671219   -0.673680    0.000204   -0.603432   -0.592422   \n",
      "50%      0.078937    0.044181    0.051059    0.000204   -0.603432   -0.592422   \n",
      "75%      0.692062    0.685877    0.697498    0.000204    0.631386    0.644278   \n",
      "max      5.199337    5.166578    5.199337    4.031962    5.199337    1.721940   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  274.000000  274.000000  274.000000  274.000000  274.000000  274.000000   \n",
      "mean    -0.036777   -0.010040    0.039181    0.043631   -0.056263    0.065552   \n",
      "std      0.901969    0.052519    0.977712    0.824878    0.958773    0.953900   \n",
      "min     -1.286383   -0.020772   -0.735294   -0.640318   -1.362306   -5.199337   \n",
      "25%     -0.773083   -0.020772   -0.735294   -0.640318   -0.817411   -0.522318   \n",
      "50%     -0.066121   -0.020772   -0.735294   -0.640318   -0.053132    0.087887   \n",
      "75%      0.687167   -0.020772    0.703922    0.645632    0.654452    0.757195   \n",
      "max      1.651508    0.452757    5.199337    5.199337    5.199337    1.372638   \n",
      "\n",
      "       Feature_13  \n",
      "count  274.000000  \n",
      "mean     6.624088  \n",
      "std      4.056506  \n",
      "min      0.000000  \n",
      "25%      3.000000  \n",
      "50%      7.000000  \n",
      "75%     10.000000  \n",
      "max     12.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.515552\n",
      "Feature_2     0.449747\n",
      "Feature_3     0.518058\n",
      "Feature_4     4.733023\n",
      "Feature_5     1.394283\n",
      "Feature_6     0.642196\n",
      "Feature_7     0.012855\n",
      "Feature_8     6.238948\n",
      "Feature_9     1.499570\n",
      "Feature_10    1.376287\n",
      "Feature_11    0.547435\n",
      "Feature_12   -0.711552\n",
      "Feature_13   -0.141423\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       157\n",
      "1.0       117\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_35 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  460.000000  460.000000  460.000000  460.000000  460.000000  460.000000   \n",
      "mean     0.059816   -0.021374   -0.171396    0.016042    0.009950   -0.090772   \n",
      "std      0.993947    1.101135    1.384392    0.835721    0.802462    1.073373   \n",
      "min     -1.426992   -5.199337   -5.173660   -1.035060   -0.702472   -4.879405   \n",
      "25%     -0.773767   -0.749869   -0.727914   -1.035060   -0.702472   -0.668574   \n",
      "50%      0.083616   -0.055733   -0.083653   -0.027854   -0.031274   -0.083656   \n",
      "75%      0.622988    0.674490    0.706303    0.622926    0.648742    0.594205   \n",
      "max      5.199337    5.199337    5.199337    1.633419    2.075452    1.828936   \n",
      "\n",
      "        Feature_7   Feature_8  \n",
      "count  460.000000  460.000000  \n",
      "mean    -0.005373    0.013017  \n",
      "std      0.920948    0.938929  \n",
      "min     -2.778992   -1.621861  \n",
      "25%     -0.602744   -0.622943  \n",
      "50%     -0.034779   -0.000004  \n",
      "75%      0.667360    0.727914  \n",
      "max      2.820177    1.918879  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.768816\n",
      "Feature_2    0.017236\n",
      "Feature_3   -1.739825\n",
      "Feature_4    0.162648\n",
      "Feature_5    0.659723\n",
      "Feature_6   -1.352810\n",
      "Feature_7   -0.022876\n",
      "Feature_8   -0.000224\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         299\n",
      "1         161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_36 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  168.000000  168.000000  168.000000  168.000000  168.000000  168.000000   \n",
      "mean     0.105099   -0.070382    0.010857   -0.021071   -0.042179    0.132154   \n",
      "std      1.258648    1.007817    1.179435    0.884974    0.912115    0.958765   \n",
      "min     -4.893860   -5.199337   -5.075026   -1.593201   -1.690617   -0.174532   \n",
      "25%     -0.528731   -0.709251   -0.695734   -0.764626   -0.764707   -0.174532   \n",
      "50%      0.092975   -0.069578   -0.103932   -0.139597   -0.139712   -0.174532   \n",
      "75%      0.674487    0.580843    1.005128    0.546026    0.548678   -0.174532   \n",
      "max      5.199337    1.958188    4.992494    4.550007    5.199337    3.164649   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_88  \\\n",
      "count  168.000000  168.000000  168.000000  168.000000  ...  168.000000   \n",
      "mean     0.857143    0.404762    0.404762    0.827381  ...    0.470238   \n",
      "std      0.752526    0.492313    0.492313    0.437700  ...    0.500606   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    1.000000  ...    0.000000   \n",
      "50%      1.000000    0.000000    0.000000    1.000000  ...    0.000000   \n",
      "75%      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "max      3.000000    1.000000    1.000000    2.000000  ...    1.000000   \n",
      "\n",
      "       Feature_89  Feature_90  Feature_91  Feature_92  Feature_93  Feature_94  \\\n",
      "count  168.000000  168.000000  168.000000  168.000000  168.000000  168.000000   \n",
      "mean     0.047619    0.023810    0.053571    0.452381    0.398810    0.101190   \n",
      "std      0.213596    0.152911    0.225843    0.499215    0.491117    0.302482   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Feature_95  Feature_96  Feature_97  \n",
      "count  168.000000  168.000000  168.000000  \n",
      "mean     0.023810    0.047619    0.005952  \n",
      "std      0.152911    0.213596    0.077152  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 97 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1      1.052466\n",
      "Feature_2     -0.844411\n",
      "Feature_3      0.446163\n",
      "Feature_4      0.869264\n",
      "Feature_5      1.130572\n",
      "                ...    \n",
      "Feature_93     0.417048\n",
      "Feature_94     2.668681\n",
      "Feature_95     6.303371\n",
      "Feature_96     4.286900\n",
      "Feature_97    12.961481\n",
      "Length: 97, dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         108\n",
      "0          60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_37 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  177.000000  177.000000  177.000000  177.000000  177.000000  177.000000   \n",
      "mean    -0.105650   -0.104613   -0.009602   -0.051571   -0.016109    0.201636   \n",
      "std      0.916936    1.158070    0.934345    1.070677    0.813102    1.114961   \n",
      "min     -1.754375   -5.199337   -5.199337   -5.199337   -0.939149   -0.511382   \n",
      "25%     -0.764726   -0.764700   -0.596316   -0.649720   -0.939149   -0.511382   \n",
      "50%     -0.241041    0.024912    0.017408    0.031834   -0.139682   -0.511382   \n",
      "75%      0.474816    0.430733    0.754664    0.712443    0.728153    0.540962   \n",
      "max      5.199337    5.199337    1.447712    1.852181    1.533922    3.534974   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  177.000000  177.000000  177.000000  177.000000  177.000000  177.000000   \n",
      "mean    -0.053596    0.677966    2.186441    0.163842    0.474576    0.327684   \n",
      "std      0.654522    0.468581    0.913433    0.371182    0.511990    0.470700   \n",
      "min     -0.594890    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     -0.594890    0.000000    2.000000    0.000000    0.000000    0.000000   \n",
      "50%     -0.594890    1.000000    2.000000    0.000000    0.000000    0.000000   \n",
      "75%      0.777369    1.000000    3.000000    0.000000    1.000000    1.000000   \n",
      "max      0.777369    1.000000    3.000000    1.000000    2.000000    1.000000   \n",
      "\n",
      "       Feature_13  \n",
      "count  177.000000  \n",
      "mean     0.615819  \n",
      "std      0.630096  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      1.000000  \n",
      "75%      1.000000  \n",
      "max      2.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.205675\n",
      "Feature_2    -1.087425\n",
      "Feature_3    -1.116203\n",
      "Feature_4    -1.331732\n",
      "Feature_5     0.282944\n",
      "Feature_6     1.799406\n",
      "Feature_7     0.430919\n",
      "Feature_8    -0.768276\n",
      "Feature_9    -0.831566\n",
      "Feature_10    1.831985\n",
      "Feature_11    0.231083\n",
      "Feature_12    0.740538\n",
      "Feature_13    0.518509\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         95\n",
      "1         82\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_38 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  349.000000  349.000000  349.000000  349.000000  349.000000  349.000000   \n",
      "mean    -0.013008   -0.112712   -0.060990   -0.033531    0.005089   -0.014926   \n",
      "std      0.991966    1.006559    0.927162    0.988652    0.933456    0.981733   \n",
      "min     -5.199337   -5.199337   -1.695720   -5.199337   -2.226597   -5.199337   \n",
      "25%     -0.747856   -0.541926   -0.573801   -0.747007   -0.604586   -0.620293   \n",
      "50%     -0.114181   -0.038124   -0.114178   -0.071271    0.037988   -0.004954   \n",
      "75%      0.718043    0.519307    0.558896    0.642211    0.630437    0.568611   \n",
      "max      5.199337    5.199337    5.199337    5.199337    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  \n",
      "count  349.000000  349.000000  349.000000  349.000000  349.000000  \n",
      "mean    -0.017629    0.039578    0.066885    0.750716    2.034384  \n",
      "std      0.996408    0.987265    0.954136    0.433219    1.405641  \n",
      "min     -5.199337   -5.199337   -2.933978    0.000000    0.000000  \n",
      "25%     -0.748275   -0.605540   -0.484393    1.000000    1.000000  \n",
      "50%     -0.020962    0.113552    0.292513    1.000000    2.000000  \n",
      "75%      0.698421    0.908057    0.613356    1.000000    3.000000  \n",
      "max      5.199337    3.559153    5.199337    1.000000    4.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.041570\n",
      "Feature_2    -0.473071\n",
      "Feature_3     0.489573\n",
      "Feature_4     0.121826\n",
      "Feature_5     0.353837\n",
      "Feature_6     0.353354\n",
      "Feature_7    -0.001657\n",
      "Feature_8    -0.759890\n",
      "Feature_9     0.106237\n",
      "Feature_10   -1.164128\n",
      "Feature_11   -0.042603\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         249\n",
      "0         100\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_39 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  600.000000  600.000000  600.000000  600.000000  600.000000  600.000000   \n",
      "mean     0.000207    0.027557   -0.068529    0.028387    0.037362   -0.011593   \n",
      "std      1.060228    1.012112    0.968824    0.962207    0.970777    0.987278   \n",
      "min     -5.199337   -5.199337   -2.249017   -4.893579   -5.199337   -2.208275   \n",
      "25%     -0.668405   -0.596963   -0.754493   -0.602561   -0.688561   -0.691435   \n",
      "50%     -0.007594   -0.018720   -0.094351    0.019741    0.021991   -0.094188   \n",
      "75%      0.656317    0.688370    0.543804    0.738836    0.737587    0.632177   \n",
      "max      5.199337    3.867073    4.017695    4.356229    2.123716    5.166578   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  600.000000  600.000000  600.000000  600.000000  600.000000  600.000000   \n",
      "mean     0.003649    0.053472   -0.066258    0.076282   -0.000739    0.014320   \n",
      "std      0.963113    0.947056    1.092733    1.000427    0.989291    0.923200   \n",
      "min     -3.874242   -2.181221   -5.199337   -2.820447   -5.199337   -2.272860   \n",
      "25%     -0.682346   -0.573542   -0.746185   -0.600194   -0.665502   -0.633418   \n",
      "50%      0.013723    0.115315   -0.083493    0.037138   -0.061717    0.033107   \n",
      "75%      0.648088    0.685804    0.628669    0.763706    0.673452    0.609026   \n",
      "max      2.494260    4.108545    5.199337    5.199337    5.199337    3.369283   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  \n",
      "count  600.000000  600.000000  600.000000  600.000000   600.00000  600.000000  \n",
      "mean    -0.033003   -0.026138    0.476667    1.808333     0.16500    0.543333  \n",
      "std      0.970550    1.016953    0.499872    1.058362     0.37149    0.498534  \n",
      "min     -2.819839   -5.199337    0.000000    0.000000     0.00000    0.000000  \n",
      "25%     -0.670432   -0.632746    0.000000    1.000000     0.00000    0.000000  \n",
      "50%     -0.067661   -0.021043    0.000000    2.000000     0.00000    1.000000  \n",
      "75%      0.584536    0.667538    1.000000    3.000000     0.00000    1.000000  \n",
      "max      5.199337    2.424017    1.000000    3.000000     1.00000    1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.114300\n",
      "Feature_2    -0.387854\n",
      "Feature_3     0.217520\n",
      "Feature_4    -0.121683\n",
      "Feature_5    -0.239025\n",
      "Feature_6     0.422775\n",
      "Feature_7    -0.082947\n",
      "Feature_8     0.071779\n",
      "Feature_9    -0.255411\n",
      "Feature_10    0.493147\n",
      "Feature_11   -0.001729\n",
      "Feature_12    0.078618\n",
      "Feature_13    0.390858\n",
      "Feature_14   -0.514754\n",
      "Feature_15    0.093669\n",
      "Feature_16   -0.137018\n",
      "Feature_17    1.809579\n",
      "Feature_18   -0.174424\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         353\n",
      "0         247\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_4 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  514.000000  514.000000  514.000000  514.000000  514.000000  514.000000   \n",
      "mean    -0.014911   -0.020450    0.014506   -0.061122    0.018263    0.103927   \n",
      "std      0.930446    0.894770    0.957779    0.974816    0.567580    0.591062   \n",
      "min     -4.612755   -1.163766   -4.199819   -3.600782   -0.214660   -0.127366   \n",
      "25%     -0.721518   -1.163766   -0.769986   -0.908081   -0.214660   -0.127366   \n",
      "50%     -0.073789   -0.309579    0.171586   -0.089795   -0.214660   -0.127366   \n",
      "75%      0.628911    0.571577    0.601860    0.665704   -0.214660   -0.127366   \n",
      "max      2.071595    4.656350    5.199337    2.334000    1.446239    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_21  \\\n",
      "count  514.000000  514.000000  514.000000  514.000000  ...  514.000000   \n",
      "mean     0.077601   -0.089711   -0.026737   -0.039880  ...    0.067439   \n",
      "std      0.573676    0.738805    0.875655    0.694118  ...    0.733655   \n",
      "min     -0.146207   -1.056991   -1.005783   -0.399515  ...   -0.216356   \n",
      "25%     -0.146207   -1.056991   -1.005783   -0.399515  ...   -0.216356   \n",
      "50%     -0.146207    0.558545    0.073769   -0.399515  ...   -0.216356   \n",
      "75%     -0.146207    0.558545    0.477428   -0.399515  ...   -0.216356   \n",
      "max      5.090231    0.558545    2.025838    1.646583  ...    3.300641   \n",
      "\n",
      "       Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  Feature_27  \\\n",
      "count  514.000000  514.000000  514.000000  514.000000  514.000000  514.000000   \n",
      "mean    -0.008902    0.042427   -0.156147   -0.123527    0.087549    0.019455   \n",
      "std      0.138483    0.152971    0.832868    0.862905    0.302879    0.138253   \n",
      "min     -0.026930    0.006055   -4.355983   -4.289017    0.000000    0.000000   \n",
      "25%     -0.026930    0.006055   -0.012458    0.039647    0.000000    0.000000   \n",
      "50%     -0.026930    0.006055   -0.012458    0.039647    0.000000    0.000000   \n",
      "75%     -0.026930    0.006055   -0.012458    0.039647    0.000000    0.000000   \n",
      "max      3.039767    2.975983    4.447136    4.450099    2.000000    1.000000   \n",
      "\n",
      "       Feature_28  Feature_29  Feature_30  \n",
      "count  514.000000  514.000000  514.000000  \n",
      "mean     0.009728    0.021401    0.025292  \n",
      "std      0.098243    0.144857    0.157163  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000  \n",
      "75%      0.000000    0.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     -0.248822\n",
      "Feature_2      0.437196\n",
      "Feature_3      0.148548\n",
      "Feature_4     -0.685797\n",
      "Feature_5      2.056194\n",
      "Feature_6      2.913667\n",
      "Feature_7      2.958266\n",
      "Feature_8     -0.391843\n",
      "Feature_9      0.396295\n",
      "Feature_10     1.550657\n",
      "Feature_11     2.160547\n",
      "Feature_12     1.586754\n",
      "Feature_13     2.080596\n",
      "Feature_14     2.616402\n",
      "Feature_15    11.543789\n",
      "Feature_16     2.590649\n",
      "Feature_17     2.741062\n",
      "Feature_18     2.281189\n",
      "Feature_19    22.671568\n",
      "Feature_20    21.626337\n",
      "Feature_21     2.794692\n",
      "Feature_22    20.900486\n",
      "Feature_23    14.110890\n",
      "Feature_24    -2.875536\n",
      "Feature_25    -3.012205\n",
      "Feature_26     3.542366\n",
      "Feature_27     6.978819\n",
      "Feature_28    10.019751\n",
      "Feature_29     6.633688\n",
      "Feature_30     6.064564\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         486\n",
      "1          28\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_40 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  460.000000  460.000000  460.000000  460.000000  460.000000  460.000000   \n",
      "mean     0.059816   -0.021374   -0.171396    0.016042    0.009950   -0.090772   \n",
      "std      0.993947    1.101135    1.384392    0.835721    0.802462    1.073373   \n",
      "min     -1.426992   -5.199337   -5.173660   -1.035060   -0.702472   -4.879405   \n",
      "25%     -0.773767   -0.749869   -0.727914   -1.035060   -0.702472   -0.668574   \n",
      "50%      0.083616   -0.055733   -0.083653   -0.027854   -0.031274   -0.083656   \n",
      "75%      0.622988    0.674490    0.706303    0.622926    0.648742    0.594205   \n",
      "max      5.199337    5.199337    5.199337    1.633419    2.075452    1.828936   \n",
      "\n",
      "        Feature_7   Feature_8  \n",
      "count  460.000000  460.000000  \n",
      "mean    -0.005373    0.013017  \n",
      "std      0.920948    0.938929  \n",
      "min     -2.778992   -1.621861  \n",
      "25%     -0.602744   -0.622943  \n",
      "50%     -0.034779   -0.000004  \n",
      "75%      0.667360    0.727914  \n",
      "max      2.820177    1.918879  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.768816\n",
      "Feature_2    0.017236\n",
      "Feature_3   -1.739825\n",
      "Feature_4    0.162648\n",
      "Feature_5    0.659723\n",
      "Feature_6   -1.352810\n",
      "Feature_7   -0.022876\n",
      "Feature_8   -0.000224\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         299\n",
      "1         161\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_41 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5  \\\n",
      "count  480.000000  480.000000  480.000000  480.000000  480.000000   \n",
      "mean    -0.031769    0.010446    0.031575    0.029717   -0.010805   \n",
      "std      1.027102    1.008046    0.972847    0.989879    1.533163   \n",
      "min     -5.199337   -5.199337   -5.199337   -5.199337   -5.120117   \n",
      "25%     -0.674490   -0.674490   -0.489300   -0.560704   -0.347687   \n",
      "50%     -0.000001    0.000002    0.001038    0.047021   -0.347687   \n",
      "75%      0.674490    0.674489    0.675580    0.714367    0.674490   \n",
      "max      5.199337    5.199337    4.321500    5.199337    5.035406   \n",
      "\n",
      "          Feature_6   Feature_7   Feature_8   Feature_9  Feature_10  \n",
      "count  4.800000e+02  480.000000  480.000000  480.000000  480.000000  \n",
      "mean   4.340390e-02    0.088013    0.048898    0.008413    2.668750  \n",
      "std    1.025401e+00    0.976437    0.972184    1.077922    1.936535  \n",
      "min   -5.066145e+00   -5.077310   -5.115684   -4.813659    0.000000  \n",
      "25%   -4.887769e-01   -0.674487   -0.619307   -0.640736    1.000000  \n",
      "50%    2.988134e-07    0.157310    0.022383    0.035312    3.000000  \n",
      "75%    7.647097e-01    0.726403    0.715433    0.725683    4.000000  \n",
      "max    5.199337e+00    5.199337    2.100164    5.199337    6.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.259976\n",
      "Feature_2     0.027567\n",
      "Feature_3    -0.552183\n",
      "Feature_4    -0.099705\n",
      "Feature_5    -0.413848\n",
      "Feature_6    -0.506373\n",
      "Feature_7    -0.119434\n",
      "Feature_8    -0.574620\n",
      "Feature_9    -0.353561\n",
      "Feature_10    0.136700\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         432\n",
      "1          48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_42 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6\n",
      "count  120.000000  120.000000  120.000000  120.000000  120.000000  120.000000\n",
      "mean     0.095726    0.007877    0.025799   -0.014161   -0.013407    0.055049\n",
      "std      1.000659    0.864059    0.964369    1.175598    1.074294    1.057564\n",
      "min     -2.160051   -1.447411   -3.342309   -3.789032   -5.199337   -3.813040\n",
      "25%     -0.757807   -0.760552   -0.766033   -0.657170   -0.787799   -0.614327\n",
      "50%      0.143735   -0.132379    0.144553    0.027844   -0.000693    0.063440\n",
      "75%      0.759784    0.768441    0.805842    0.603708    0.587423    0.796069\n",
      "max      5.199337    1.609992    1.669039    5.199337    5.199337    3.707192\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.790531\n",
      "Feature_2    0.034761\n",
      "Feature_3   -0.485610\n",
      "Feature_4   -0.084139\n",
      "Feature_5    0.086441\n",
      "Feature_6   -0.210206\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         62\n",
      "1         58\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_43 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4\n",
      "count  593.000000  593.000000  593.000000  593.000000\n",
      "mean     0.058206    0.767285    0.517707    0.817875\n",
      "std      0.976148    0.609449    0.500108    0.386273\n",
      "min     -2.558036    0.000000    0.000000    0.000000\n",
      "25%     -0.589453    0.000000    0.000000    1.000000\n",
      "50%      0.075270    1.000000    1.000000    1.000000\n",
      "75%      0.674488    1.000000    1.000000    1.000000\n",
      "max      5.199337    2.000000    1.000000    1.000000\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    0.405656\n",
      "Feature_2    0.172102\n",
      "Feature_3   -0.071051\n",
      "Feature_4   -1.651427\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         506\n",
      "1          87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_44 ===\n",
      "\n",
      "Feature distribution:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6\n",
      "count  60.000000  60.000000  60.000000  60.000000  60.000000  60.000000\n",
      "mean    0.210634  -0.021849  -0.161465   0.433333   0.033333   0.183333\n",
      "std     0.863293   1.215904   0.933418   0.499717   0.181020   0.567231\n",
      "min    -1.593238  -3.579762  -1.314524   0.000000   0.000000   0.000000\n",
      "25%    -0.355855  -0.512111  -1.314524   0.000000   0.000000   0.000000\n",
      "50%     0.186969   0.066660  -0.161902   0.000000   0.000000   0.000000\n",
      "75%     0.967425   0.765074   0.544130   1.000000   0.000000   0.000000\n",
      "max     2.355062   4.372582   1.880375   1.000000   1.000000   3.000000\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1   -0.068068\n",
      "Feature_2   -0.168891\n",
      "Feature_3    0.135531\n",
      "Feature_4    0.276018\n",
      "Feature_5    5.333750\n",
      "Feature_6    3.476742\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         43\n",
      "0         17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_45 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4\n",
      "count  158.000000  158.000000  158.000000  158.000000\n",
      "mean    -0.049282    0.095269   -0.061415    0.348101\n",
      "std      1.284409    1.257000    1.304435    0.477883\n",
      "min     -5.199337   -5.199337   -4.833602    0.000000\n",
      "25%     -0.764693   -0.535087   -0.765526    0.000000\n",
      "50%     -0.137540   -0.035630   -0.139694    0.000000\n",
      "75%      0.790091    0.764711    0.430721    1.000000\n",
      "max      5.199337    4.680553    4.430132    1.000000\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1   -0.080470\n",
      "Feature_2    0.703342\n",
      "Feature_3    0.597850\n",
      "Feature_4    0.643865\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         147\n",
      "1          11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_46 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
      "mean     0.059789    0.068576    0.041978    0.316175    0.181307    0.046890   \n",
      "std      1.076087    0.989703    1.080964    0.860183    0.741321    0.977956   \n",
      "min     -5.199337   -4.959011   -5.199337    0.039787   -0.183907   -2.043694   \n",
      "25%     -0.572966   -0.642205   -0.653013    0.039787   -0.183907   -0.745217   \n",
      "50%      0.000007   -0.038037    0.116061    0.039787   -0.183907    0.139705   \n",
      "75%      0.764702    0.430731    0.669147    0.039787   -0.183907    0.589458   \n",
      "max      5.199337    5.199337    5.199337    3.168945    3.333582    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9    Feature_10  Feature_11  \\\n",
      "count  176.000000  176.000000  176.000000  1.760000e+02  176.000000   \n",
      "mean     0.124945    0.038900    0.071397 -2.267217e-02    0.066572   \n",
      "std      0.665769    0.788471    0.839908  3.479346e-18    0.943728   \n",
      "min     -0.339561   -0.492246   -2.944075 -2.267217e-02   -3.662274   \n",
      "25%     -0.339561   -0.492246   -0.307656 -2.267217e-02    0.012123   \n",
      "50%     -0.339561   -0.492246   -0.307656 -2.267217e-02    0.012123   \n",
      "75%      1.079649    0.609077    1.119049 -2.267217e-02    0.012123   \n",
      "max      1.079649    4.344686    1.119049 -2.267217e-02    3.653269   \n",
      "\n",
      "       Feature_12  Feature_13  \n",
      "count  176.000000  176.000000  \n",
      "mean     0.755682    1.159091  \n",
      "std      0.430908    0.954824  \n",
      "min      0.000000    0.000000  \n",
      "25%      1.000000    0.000000  \n",
      "50%      1.000000    1.000000  \n",
      "75%      1.000000    2.000000  \n",
      "max      1.000000    3.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.025373\n",
      "Feature_2     0.169703\n",
      "Feature_3     0.535371\n",
      "Feature_4     2.950933\n",
      "Feature_5     2.246043\n",
      "Feature_6     0.713569\n",
      "Feature_7     0.741042\n",
      "Feature_8     1.504107\n",
      "Feature_9    -0.770355\n",
      "Feature_10    0.000000\n",
      "Feature_11    0.208752\n",
      "Feature_12   -1.200352\n",
      "Feature_13   -0.125196\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0.0       107\n",
      "1.0        69\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_47 ===\n",
      "\n",
      "Feature distribution:\n",
      "       Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
      "count  86.000000  86.000000  86.000000  86.000000  86.000000  86.000000   \n",
      "mean   -0.025506   0.192184  -0.019937  -0.203516  -0.022883  -0.184386   \n",
      "std     1.282061   1.355576   1.393315   1.441053   1.267390   1.214193   \n",
      "min    -5.199337  -4.980336  -5.199337  -5.199337  -5.199337  -5.199337   \n",
      "25%    -0.713393  -0.508514  -0.638145  -0.717962  -0.480812  -0.639334   \n",
      "50%     0.061870   0.139726  -0.019298  -0.064443   0.017545  -0.029210   \n",
      "75%     0.780078   0.764701   0.712777   0.699404   0.651829   0.414208   \n",
      "max     4.260634   5.199337   5.199337   1.783649   5.199337   2.921284   \n",
      "\n",
      "       Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_67  \\\n",
      "count  86.000000  86.000000  86.000000   86.000000  ...   86.000000   \n",
      "mean   -0.031627  -0.134259  -0.037498    0.064590  ...    0.001008   \n",
      "std     1.019641   1.193838   0.958525    1.381505  ...    1.209385   \n",
      "min    -3.038369  -5.199337  -2.483230   -5.199337  ...   -5.199337   \n",
      "25%    -0.823517  -0.858743  -0.693806   -0.677255  ...   -0.507643   \n",
      "50%     0.074906  -0.158832  -0.090080    0.052391  ...    0.010004   \n",
      "75%     0.674735   0.392327   0.713360    0.787094  ...    0.700632   \n",
      "max     1.802787   5.199337   1.992115    5.199337  ...    5.199337   \n",
      "\n",
      "       Feature_68  Feature_69  Feature_70  Feature_71  Feature_72  Feature_73  \\\n",
      "count   86.000000   86.000000   86.000000   86.000000   86.000000   86.000000   \n",
      "mean    -0.014144   -0.026920    0.006609    0.047899    0.059604    0.511628   \n",
      "std      1.257431    0.921683    0.981907    0.950264    1.386490    0.502797   \n",
      "min     -5.199337   -2.683480   -2.432387   -3.044703   -2.693931    0.000000   \n",
      "25%     -0.731686   -0.505998   -0.553069   -0.501458   -0.858320    0.000000   \n",
      "50%      0.101321   -0.023651   -0.077678    0.098268   -0.010765    1.000000   \n",
      "75%      0.797912    0.712836    0.594329    0.612132    0.704611    1.000000   \n",
      "max      5.199337    1.538432    3.783730    2.993125    5.199337    1.000000   \n",
      "\n",
      "       Feature_74  Feature_75  Feature_76  \n",
      "count   86.000000   86.000000   86.000000  \n",
      "mean     0.255814    0.802326    0.906977  \n",
      "std      0.438877    0.400581    0.834941  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    1.000000    0.000000  \n",
      "50%      0.000000    1.000000    1.000000  \n",
      "75%      0.750000    1.000000    2.000000  \n",
      "max      1.000000    1.000000    2.000000  \n",
      "\n",
      "[8 rows x 76 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -1.079068\n",
      "Feature_2     0.885842\n",
      "Feature_3    -0.637807\n",
      "Feature_4    -1.906041\n",
      "Feature_5    -0.770660\n",
      "                ...   \n",
      "Feature_72    1.559977\n",
      "Feature_73   -0.047354\n",
      "Feature_74    1.139272\n",
      "Feature_75   -1.545374\n",
      "Feature_76    0.178082\n",
      "Length: 76, dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         59\n",
      "1         27\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_48 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  237.000000  237.000000  237.000000  237.000000  237.000000  237.000000   \n",
      "mean    -0.023409   -0.035895   -0.090573   -0.282206    0.869198    0.527426   \n",
      "std      0.925735    1.115362    1.271783    1.530701    0.337897    0.500304   \n",
      "min     -1.097014   -5.199337   -4.422124   -4.274073    0.000000    0.000000   \n",
      "25%     -1.097014   -0.764664   -0.764716   -0.764704    1.000000    0.000000   \n",
      "50%     -0.000004    0.139634    0.139547    0.139663    1.000000    1.000000   \n",
      "75%      0.764699    0.430887    0.430834    0.430748    1.000000    1.000000   \n",
      "max      5.199337    5.199337    4.193914    2.009835    1.000000    1.000000   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_20  \\\n",
      "count  237.000000  237.000000  237.000000  237.000000  ...  237.000000   \n",
      "mean     1.713080    0.763713    0.316456    0.886076  ...    0.780591   \n",
      "std      1.218657    0.425699    0.466077    0.318391  ...    0.414722   \n",
      "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
      "25%      1.000000    1.000000    0.000000    1.000000  ...    1.000000   \n",
      "50%      2.000000    1.000000    0.000000    1.000000  ...    1.000000   \n",
      "75%      3.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "max      4.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
      "\n",
      "       Feature_21  Feature_22  Feature_23  Feature_24  Feature_25  Feature_26  \\\n",
      "count  237.000000  237.000000  237.000000  237.000000  237.000000  237.000000   \n",
      "mean     0.046414    0.835443    0.316456    2.004219    1.527426    2.059072   \n",
      "std      0.210824    0.371565    0.466077    0.846217    1.067771    1.106937   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    1.000000    0.000000    2.000000    1.000000    1.000000   \n",
      "50%      0.000000    1.000000    0.000000    2.000000    1.000000    2.000000   \n",
      "75%      0.000000    1.000000    1.000000    3.000000    2.000000    3.000000   \n",
      "max      1.000000    1.000000    1.000000    4.000000    4.000000    4.000000   \n",
      "\n",
      "       Feature_27  Feature_28  Feature_29  \n",
      "count  237.000000  237.000000  237.000000  \n",
      "mean     0.476793    1.265823    2.565401  \n",
      "std      0.831382    1.289221    1.359580  \n",
      "min      0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    2.000000  \n",
      "50%      0.000000    1.000000    3.000000  \n",
      "75%      1.000000    2.000000    4.000000  \n",
      "max      3.000000    4.000000    4.000000  \n",
      "\n",
      "[8 rows x 29 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.808803\n",
      "Feature_2     0.068840\n",
      "Feature_3    -1.131125\n",
      "Feature_4    -1.449945\n",
      "Feature_5    -2.203870\n",
      "Feature_6    -0.110571\n",
      "Feature_7     0.182482\n",
      "Feature_8    -1.249508\n",
      "Feature_9     0.794316\n",
      "Feature_10   -2.445805\n",
      "Feature_11   -0.203281\n",
      "Feature_12    0.083958\n",
      "Feature_13    1.530942\n",
      "Feature_14    0.587072\n",
      "Feature_15    1.830274\n",
      "Feature_16    1.998799\n",
      "Feature_17   -0.425330\n",
      "Feature_18    0.196258\n",
      "Feature_19    0.025480\n",
      "Feature_20   -1.364666\n",
      "Feature_21    4.339605\n",
      "Feature_22   -1.820935\n",
      "Feature_23    0.794316\n",
      "Feature_24   -0.177286\n",
      "Feature_25    0.528223\n",
      "Feature_26    0.090440\n",
      "Feature_27    1.725144\n",
      "Feature_28    0.665570\n",
      "Feature_29   -0.491048\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         150\n",
      "0          87\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_49 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  575.000000  575.000000  575.000000  575.000000  575.000000  575.000000   \n",
      "mean     0.103983    0.011153    0.006625    0.066278   -0.044599   -0.002533   \n",
      "std      0.723375    1.007894    1.020341    0.970133    1.143864    1.052170   \n",
      "min     -0.627544   -4.368375   -4.120306   -1.648312   -5.199337   -5.048680   \n",
      "25%     -0.505093   -0.595020   -0.612713   -0.607659   -0.657493   -0.586424   \n",
      "50%     -0.184800    0.033610    0.019913    0.038406    0.002007   -0.042365   \n",
      "75%      0.556757    0.592756    0.592948    0.783292    0.631869    0.629967   \n",
      "max      2.363854    5.199337    5.199337    3.137721    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_35  \\\n",
      "count  575.000000  575.000000  575.000000  575.000000  ...  575.000000   \n",
      "mean     0.045983    0.005424    0.008773    0.064795  ...    0.063789   \n",
      "std      0.872419    1.052883    1.045873    0.967932  ...    1.002781   \n",
      "min     -1.187136   -5.199337   -5.199337   -1.660800  ...   -2.845694   \n",
      "25%     -0.724976   -0.574860   -0.608970   -0.610355  ...   -0.633677   \n",
      "50%     -0.109599    0.005903    0.015811    0.090230  ...    0.092399   \n",
      "75%      0.655773    0.629359    0.643412    0.754747  ...    0.752111   \n",
      "max      5.199337    5.199337    5.199337    2.864622  ...    5.199337   \n",
      "\n",
      "       Feature_36  Feature_37  Feature_38  Feature_39  Feature_40  Feature_41  \\\n",
      "count  575.000000  575.000000  575.000000  575.000000  575.000000  575.000000   \n",
      "mean     0.012946    0.062346    0.115546    0.002298    0.045357   -0.012503   \n",
      "std      0.959164    0.997906    0.547000    0.906453    0.462654    0.952831   \n",
      "min     -5.199337   -2.554646   -0.064021   -1.418438   -0.067933   -3.414067   \n",
      "25%     -0.597957   -0.638788   -0.064021   -0.633630   -0.067933   -0.662137   \n",
      "50%      0.023817    0.076635   -0.064021    0.063544   -0.067933    0.029217   \n",
      "75%      0.690534    0.737879   -0.064021    0.604241   -0.067933    0.610796   \n",
      "max      2.262630    5.199337    2.516619    2.123327    5.199337    3.173875   \n",
      "\n",
      "       Feature_42  Feature_43  Feature_44  \n",
      "count  575.000000       575.0       575.0  \n",
      "mean     0.023763         0.0         0.0  \n",
      "std      0.810675         0.0         0.0  \n",
      "min     -0.888563         0.0         0.0  \n",
      "25%     -0.888563         0.0         0.0  \n",
      "50%     -0.022413         0.0         0.0  \n",
      "75%      0.625964         0.0         0.0  \n",
      "max      1.747267         0.0         0.0  \n",
      "\n",
      "[8 rows x 44 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.834172\n",
      "Feature_2     0.322631\n",
      "Feature_3     0.346254\n",
      "Feature_4     0.107192\n",
      "Feature_5    -0.015377\n",
      "Feature_6     0.681449\n",
      "Feature_7     0.761699\n",
      "Feature_8    -0.069625\n",
      "Feature_9     0.056381\n",
      "Feature_10    0.078589\n",
      "Feature_11    0.063499\n",
      "Feature_12    0.605134\n",
      "Feature_13    2.918328\n",
      "Feature_14   -1.611758\n",
      "Feature_15    0.135386\n",
      "Feature_16   -0.093244\n",
      "Feature_17    0.338292\n",
      "Feature_18    0.000000\n",
      "Feature_19    0.618211\n",
      "Feature_20    1.028649\n",
      "Feature_21    0.144158\n",
      "Feature_22   -0.070869\n",
      "Feature_23    0.279494\n",
      "Feature_24    1.380504\n",
      "Feature_25    0.059288\n",
      "Feature_26    0.106569\n",
      "Feature_27   -0.195104\n",
      "Feature_28   -0.651714\n",
      "Feature_29    0.098575\n",
      "Feature_30    0.184227\n",
      "Feature_31    0.922557\n",
      "Feature_32    0.200293\n",
      "Feature_33   -0.240474\n",
      "Feature_34    0.209881\n",
      "Feature_35    0.478767\n",
      "Feature_36   -0.372566\n",
      "Feature_37    0.536189\n",
      "Feature_38    2.882205\n",
      "Feature_39    0.032114\n",
      "Feature_40    4.927906\n",
      "Feature_41   -0.117837\n",
      "Feature_42    0.366237\n",
      "Feature_43    0.000000\n",
      "Feature_44    0.000000\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         368\n",
      "0         207\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_5 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  324.000000  324.000000  324.000000  324.000000  324.000000  324.000000   \n",
      "mean     0.006737   -0.039531   -0.024168    0.076944    0.055185   -0.020775   \n",
      "std      1.192321    1.063362    1.055390    1.049247    1.002625    1.026336   \n",
      "min     -5.199337   -5.199337   -5.199337   -3.571630   -2.212831   -3.052756   \n",
      "25%     -0.786470   -0.773182   -0.692013   -0.607819   -0.579718   -0.669957   \n",
      "50%      0.055737   -0.043883    0.049526    0.104623   -0.008545    0.004618   \n",
      "75%      0.761244    0.635884    0.609775    0.809956    0.682590    0.635268   \n",
      "max      5.199337    5.199337    2.721746    2.595553    5.199337    3.666215   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  324.000000  324.000000  324.000000  324.000000  324.000000  324.000000   \n",
      "mean    -0.053038   -0.053615   -0.050112    0.070838   -0.095894    0.013239   \n",
      "std      1.063796    1.015056    1.037388    1.025889    1.040066    0.988094   \n",
      "min     -5.199337   -2.820941   -2.582115   -2.952210   -2.890494   -3.935045   \n",
      "25%     -0.670254   -0.759884   -0.765299   -0.631261   -0.845813   -0.601710   \n",
      "50%     -0.088633   -0.070786   -0.052812    0.072757   -0.131983   -0.017619   \n",
      "75%      0.650972    0.675384    0.664880    0.708664    0.674355    0.640753   \n",
      "max      3.359717    2.262605    5.199337    5.199337    2.462929    2.902181   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  Feature_16  Feature_17  Feature_18  \\\n",
      "count  324.000000  324.000000  324.000000  324.000000  324.000000  324.000000   \n",
      "mean     0.075075   -0.000669   -0.058448    0.032371   -0.110469   -0.010770   \n",
      "std      0.975720    0.994787    1.129543    1.032217    1.006374    0.955351   \n",
      "min     -2.438321   -3.500244   -5.199337   -2.566386   -2.726597   -2.946412   \n",
      "25%     -0.611107   -0.587077   -0.730130   -0.703739   -0.801215   -0.642749   \n",
      "50%      0.043839   -0.031494   -0.062533    0.103580   -0.111408   -0.056776   \n",
      "75%      0.705045    0.623760    0.651370    0.727756    0.556964    0.645549   \n",
      "max      3.495048    2.855281    2.866172    3.253839    5.199337    3.216538   \n",
      "\n",
      "       Feature_19  \n",
      "count  324.000000  \n",
      "mean     0.981481  \n",
      "std      0.825088  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      1.000000  \n",
      "75%      2.000000  \n",
      "max      2.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -0.218897\n",
      "Feature_2     0.051524\n",
      "Feature_3    -0.384361\n",
      "Feature_4    -0.153007\n",
      "Feature_5     0.538420\n",
      "Feature_6    -0.050124\n",
      "Feature_7    -0.344797\n",
      "Feature_8    -0.076242\n",
      "Feature_9     0.450432\n",
      "Feature_10    0.398006\n",
      "Feature_11   -0.014456\n",
      "Feature_12   -0.041038\n",
      "Feature_13    0.182693\n",
      "Feature_14   -0.102142\n",
      "Feature_15   -0.725908\n",
      "Feature_16   -0.033050\n",
      "Feature_17    0.385416\n",
      "Feature_18    0.056944\n",
      "Feature_19    0.034486\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         303\n",
      "1          21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_6 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  312.000000  312.000000  312.000000  312.000000  312.000000  312.000000   \n",
      "mean     0.044962    0.618590    0.480769    0.439103    0.410256    0.599359   \n",
      "std      0.944589    0.486513    0.500433    0.497075    0.492670    0.490816   \n",
      "min     -5.199337    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     -0.622924    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.041824    1.000000    0.000000    0.000000    0.000000    1.000000   \n",
      "75%      0.768643    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "max      5.199337    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \\\n",
      "count  312.000000  312.000000  312.000000  312.000000  312.000000  312.000000   \n",
      "mean     0.461538    0.230769    0.464744    0.483974    0.253205    0.480769   \n",
      "std      0.499319    0.422002    0.499557    0.500546    0.435546    0.500433   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "75%      1.000000    0.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "       Feature_13  Feature_14  Feature_15  Feature_16  \n",
      "count  312.000000  312.000000  312.000000  312.000000  \n",
      "mean     0.400641    0.394231    0.352564    0.179487  \n",
      "std      0.490816    0.489470    0.478536    0.384376  \n",
      "min      0.000000    0.000000    0.000000    0.000000  \n",
      "25%      0.000000    0.000000    0.000000    0.000000  \n",
      "50%      0.000000    0.000000    0.000000    0.000000  \n",
      "75%      1.000000    1.000000    1.000000    0.000000  \n",
      "max      1.000000    1.000000    1.000000    1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.019560\n",
      "Feature_2    -0.490654\n",
      "Feature_3     0.077352\n",
      "Feature_4     0.246604\n",
      "Feature_5     0.366665\n",
      "Feature_6    -0.407485\n",
      "Feature_7     0.155050\n",
      "Feature_8     1.284202\n",
      "Feature_9     0.142061\n",
      "Feature_10    0.064446\n",
      "Feature_11    1.140578\n",
      "Feature_12    0.077352\n",
      "Feature_13    0.407485\n",
      "Feature_14    0.434967\n",
      "Feature_15    0.620171\n",
      "Feature_16    1.678463\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         188\n",
      "1         124\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_7 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  369.000000  369.000000  369.000000  369.000000  369.000000  369.000000   \n",
      "mean     0.078172    0.051354   -0.006300   -0.014919   -0.029993   -0.016458   \n",
      "std      0.987782    0.948287    1.070771    0.989694    0.921117    1.024669   \n",
      "min     -2.000420   -5.199337   -5.199337   -5.199337   -5.199337   -5.199337   \n",
      "25%     -0.674482   -0.581934   -0.652912   -0.699675   -0.703920   -0.674490   \n",
      "50%      0.000001    0.056990    0.025848   -0.013190   -0.053358   -0.048189   \n",
      "75%      0.764702    0.871710    0.621665    0.705760    0.622358    0.633645   \n",
      "max      5.199337    1.678105    5.199337    5.199337    3.005103    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \n",
      "count  369.000000  369.000000  369.000000  369.000000  369.000000  369.000000  \n",
      "mean    -0.033071    0.000116   -0.047026    0.000429    0.032250    0.590786  \n",
      "std      0.979389    1.082365    0.906091    0.991522    0.944357    0.492356  \n",
      "min     -5.199337   -5.199337   -5.199337   -5.199337   -4.660316    0.000000  \n",
      "25%     -0.739631   -0.722667   -0.674487   -0.645272   -0.693794    0.000000  \n",
      "50%     -0.000394    0.083837   -0.069685    0.022998    0.076034    1.000000  \n",
      "75%      0.695821    0.757742    0.619306    0.596291    0.736297    1.000000  \n",
      "max      2.060313    5.199337    1.481017    5.199337    1.956275    1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     0.696585\n",
      "Feature_2    -0.577199\n",
      "Feature_3    -0.279209\n",
      "Feature_4    -0.152254\n",
      "Feature_5    -0.295023\n",
      "Feature_6     0.578366\n",
      "Feature_7    -0.548800\n",
      "Feature_8    -0.219050\n",
      "Feature_9    -0.475311\n",
      "Feature_10    0.366556\n",
      "Feature_11   -0.388139\n",
      "Feature_12   -0.370791\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         321\n",
      "1          48\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_8 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  179.000000  179.000000  179.000000  179.000000  179.000000  179.000000   \n",
      "mean    -0.074231    0.026635    0.111999   -0.119016    0.114883    0.070905   \n",
      "std      1.084634    0.885223    1.285627    0.950910    0.974493    1.068401   \n",
      "min     -4.752712   -1.447406   -5.199337   -5.199337   -1.784403   -4.850764   \n",
      "25%     -0.692084   -0.591772   -0.764704   -0.795868   -0.331485   -0.764729   \n",
      "50%     -0.139705   -0.022318    0.139709   -0.109715    0.134703    0.139657   \n",
      "75%      0.728394    0.430727    0.764711    0.544902    0.763117    0.764751   \n",
      "max      2.539165    5.199337    5.199337    1.959964    5.199337    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  Feature_11  Feature_12  \n",
      "count  179.000000  179.000000  179.000000  179.000000  179.000000  179.000000  \n",
      "mean    -0.052384    0.435754    0.402235    0.324022    0.675978    0.357542  \n",
      "std      1.137909    0.497246    0.491724    0.469321    0.469321    0.480621  \n",
      "min     -5.199337    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "25%     -0.576265    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
      "50%     -0.028593    0.000000    0.000000    0.000000    1.000000    0.000000  \n",
      "75%      0.612075    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
      "max      5.199337    1.000000    1.000000    1.000000    1.000000    1.000000  \n",
      "\n",
      "Skewness of features:\n",
      "Feature_1    -1.137742\n",
      "Feature_2     1.124025\n",
      "Feature_3    -0.029052\n",
      "Feature_4    -0.733825\n",
      "Feature_5     0.604227\n",
      "Feature_6     0.174995\n",
      "Feature_7    -0.561432\n",
      "Feature_8     0.261326\n",
      "Feature_9     0.402136\n",
      "Feature_10    0.758398\n",
      "Feature_11   -0.758398\n",
      "Feature_12    0.599507\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "0         121\n",
      "1          58\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Analysis for Dataset Dataset_9 ===\n",
      "\n",
      "Feature distribution:\n",
      "        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n",
      "count  144.000000  144.000000  144.000000  144.000000  144.000000  144.000000   \n",
      "mean     0.056910    0.137769   -0.091520    0.117700   -0.007956   -0.065405   \n",
      "std      1.197233    0.000062    0.009839    0.009271    0.327874    1.131899   \n",
      "min     -1.916115    0.137725   -0.097305    0.113450   -0.416586   -5.199337   \n",
      "25%     -0.739799    0.137736   -0.095855    0.114252   -0.200817   -0.657082   \n",
      "50%      0.009197    0.137756   -0.093659    0.116427   -0.095230   -0.122362   \n",
      "75%      0.636438    0.137780   -0.090738    0.118293    0.081978    0.552383   \n",
      "max      5.199337    0.138351    0.008596    0.219856    1.841895    5.199337   \n",
      "\n",
      "        Feature_7   Feature_8   Feature_9  Feature_10  ...  Feature_37  \\\n",
      "count  144.000000  144.000000  144.000000  144.000000  ...  144.000000   \n",
      "mean    -0.098993   -0.093123   -0.021138   -0.020558  ...    0.088704   \n",
      "std      0.152644    0.158869    0.192668    1.134842  ...    1.149240   \n",
      "min     -0.298028   -0.370000   -0.257482   -5.199337  ...   -3.192187   \n",
      "25%     -0.181933   -0.177124   -0.127484   -0.553076  ...   -0.736652   \n",
      "50%     -0.123131   -0.119295   -0.073568    0.064331  ...    0.060004   \n",
      "75%     -0.060888   -0.050380    0.038893    0.734401  ...    0.690657   \n",
      "max      0.984028    0.947406    1.265479    4.900964  ...    5.199337   \n",
      "\n",
      "       Feature_38  Feature_39  Feature_40  Feature_41  Feature_42  Feature_43  \\\n",
      "count  144.000000  144.000000  144.000000  144.000000  144.000000  144.000000   \n",
      "mean    -0.023969   -0.033501   -0.009536   -0.029724   -0.020643   -0.043189   \n",
      "std      0.999857    0.987933    1.005308    0.976084    0.948102    1.074424   \n",
      "min     -5.199337   -3.431605   -2.934513   -2.366518   -2.137811   -5.199337   \n",
      "25%     -0.686510   -0.639228   -0.639623   -0.701283   -0.615582   -0.677935   \n",
      "50%     -0.027031   -0.168680   -0.076461   -0.128415   -0.111528    0.015068   \n",
      "75%      0.723694    0.651545    0.655952    0.663974    0.580526    0.670693   \n",
      "max      3.811220    5.199337    5.199337    5.199337    5.199337    3.051672   \n",
      "\n",
      "       Feature_44  Feature_45  Feature_46  \n",
      "count  144.000000  144.000000  144.000000  \n",
      "mean    -0.059606    0.986111    0.416667  \n",
      "std      0.902137    0.827720    0.494727  \n",
      "min     -2.768244    0.000000    0.000000  \n",
      "25%     -0.681214    0.000000    0.000000  \n",
      "50%     -0.081045    1.000000    0.000000  \n",
      "75%      0.530269    2.000000    1.000000  \n",
      "max      3.235620    2.000000    1.000000  \n",
      "\n",
      "[8 rows x 46 columns]\n",
      "\n",
      "Skewness of features:\n",
      "Feature_1     1.692552\n",
      "Feature_2     6.376310\n",
      "Feature_3     7.752748\n",
      "Feature_4     9.589388\n",
      "Feature_5     2.782396\n",
      "Feature_6     0.710436\n",
      "Feature_7     4.052112\n",
      "Feature_8     2.977406\n",
      "Feature_9     3.499269\n",
      "Feature_10   -0.758684\n",
      "Feature_11   -0.186854\n",
      "Feature_12   -0.128429\n",
      "Feature_13   -0.118571\n",
      "Feature_14   -0.235141\n",
      "Feature_15    0.124124\n",
      "Feature_16   -0.773725\n",
      "Feature_17    0.080857\n",
      "Feature_18    0.129981\n",
      "Feature_19   -1.514790\n",
      "Feature_20    0.055669\n",
      "Feature_21   -0.929767\n",
      "Feature_22   -0.376257\n",
      "Feature_23   -0.487793\n",
      "Feature_24    0.697417\n",
      "Feature_25   -0.701323\n",
      "Feature_26   -1.256699\n",
      "Feature_27   -0.607097\n",
      "Feature_28    0.053983\n",
      "Feature_29    0.113222\n",
      "Feature_30    0.825932\n",
      "Feature_31   -0.659060\n",
      "Feature_32    0.001381\n",
      "Feature_33   -0.150484\n",
      "Feature_34    0.134704\n",
      "Feature_35    0.615085\n",
      "Feature_36    0.070318\n",
      "Feature_37    1.047518\n",
      "Feature_38   -0.614551\n",
      "Feature_39    0.813449\n",
      "Feature_40    0.709494\n",
      "Feature_41    0.955688\n",
      "Feature_42    1.047714\n",
      "Feature_43   -1.250655\n",
      "Feature_44    0.243711\n",
      "Feature_45    0.026043\n",
      "Feature_46    0.341631\n",
      "dtype: float64\n",
      "\n",
      "Target label distribution:\n",
      "target\n",
      "1         74\n",
      "0         70\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Analyze every dataset\n",
    "for i, name in enumerate(dataset_names):\n",
    "    print(f\"\\n=== Analysis for Dataset {name} ===\")\n",
    "    \n",
    "    # Access the current dataset\n",
    "    X_sample = X_trains[i]\n",
    "    y_sample = y_trains[i]\n",
    "    \n",
    "    # Check feature distribution\n",
    "    print(\"\\nFeature distribution:\")\n",
    "    print(X_sample.describe())\n",
    "    \n",
    "    # Check for skewness in features\n",
    "    skewness = X_sample.skew()\n",
    "    print(\"\\nSkewness of features:\")\n",
    "    print(skewness)\n",
    "    \n",
    "    # Check target label distribution\n",
    "    print(\"\\nTarget label distribution:\")\n",
    "    print(y_sample.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7809\n",
      "  Validation AUC = 0.7286\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6845\n",
      "  Validation AUC = 0.6722\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9355\n",
      "  Validation AUC = 0.9077\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7945\n",
      "  Validation AUC = 0.7373\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7230\n",
      "  Validation AUC = 0.6674\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9857\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9101\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9635\n",
      "  Validation AUC = 0.9510\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9857\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8269\n",
      "  Validation AUC = 0.7743\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8852\n",
      "  Validation AUC = 0.8825\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8077\n",
      "  Validation AUC = 0.8090\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8732\n",
      "  Validation AUC = 0.8704\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.9972\n",
      "  Validation Accuracy = 0.6500\n",
      "  Validation AUC = 0.5222\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9815\n",
      "  Validation AUC = 0.9750\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7778\n",
      "  Validation AUC = 0.7127\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7165\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8862\n",
      "  Validation AUC = 0.8808\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8214\n",
      "  Validation AUC = 0.8214\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7432\n",
      "  Validation AUC = 0.7114\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6970\n",
      "  Validation AUC = 0.5875\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.9352\n",
      "  Validation Accuracy = 0.8193\n",
      "  Validation AUC = 0.5722\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9695\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.9817\n",
      "  Validation Accuracy = 0.7727\n",
      "  Validation AUC = 0.7557\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7283\n",
      "  Validation AUC = 0.6902\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7324\n",
      "  Validation AUC = 0.7483\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7357\n",
      "  Validation AUC = 0.6370\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9750\n",
      "  Validation AUC = 0.9717\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9369\n",
      "  Validation AUC = 0.4874\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7283\n",
      "  Validation AUC = 0.6902\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.8221\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9828\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.9352\n",
      "  Validation Accuracy = 0.8193\n",
      "  Validation AUC = 0.5722\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9688\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9833\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8310\n",
      "  Validation AUC = 0.8247\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8286\n",
      "  Validation AUC = 0.8200\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9348\n",
      "  Validation AUC = 0.9319\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.5584\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9760\n",
      "  Validation AUC = 0.9824\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9797\n",
      "  Validation AUC = 0.9374\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7778\n",
      "  Validation AUC = 0.7309\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8621\n",
      "  Validation AUC = 0.8638\n",
      "Average AUC = 0.8124538657927755\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "loss: Literal['log_loss', 'deviance', 'exponential'] = \"log_loss\",\n",
    "learning_rate: Float = 0.1,\n",
    "n_estimators: Int = 100,\n",
    "subsample: Float = 1,\n",
    "criterion: Literal['friedman_mse', 'squared_error'] = \"friedman_mse\",\n",
    "min_samples_split: float | int = 2,\n",
    "min_samples_leaf: float | int = 1,\n",
    "min_weight_fraction_leaf: Float = 0,\n",
    "max_depth: int | None = 3,\n",
    "random_state: Int | RandomState | None = None,\n",
    "max_features: float | int | Literal['auto', 'sqrt', 'log2'] | None = None,\n",
    "max_leaf_nodes: Int | None = None\n",
    "\"\"\"\n",
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    model = GradientBoostingClassifier(\n",
    "                loss='log_loss',\n",
    "                learning_rate=0.05,\n",
    "                n_estimators=500,\n",
    "                subsample=0.7,\n",
    "                criterion='friedman_mse',\n",
    "                #min_samples_split=2,\n",
    "                min_samples_leaf=3,\n",
    "                min_weight_fraction_leaf=0,\n",
    "                max_depth=3,\n",
    "                random_state=0,     #=123\n",
    "                max_features=None,\n",
    "                max_leaf_nodes=None\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.8308\n",
      "  Validation Accuracy = 0.7584\n",
      "  Validation AUC = 0.6646\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.8000\n",
      "  Validation Accuracy = 0.7701\n",
      "  Validation AUC = 0.7474\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8750\n",
      "  Validation AUC = 0.7045\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.9674\n",
      "  Validation Accuracy = 0.9516\n",
      "  Validation AUC = 0.9454\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8493\n",
      "  Validation AUC = 0.8028\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7864\n",
      "  Validation Accuracy = 0.7973\n",
      "  Validation AUC = 0.6917\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9946\n",
      "  Validation AUC = 0.9921\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8125\n",
      "  Validation AUC = 0.7995\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9926\n",
      "  Validation AUC = 0.9962\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9270\n",
      "  Validation AUC = 0.9203\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9946\n",
      "  Validation AUC = 0.9921\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7885\n",
      "  Validation AUC = 0.7425\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8852\n",
      "  Validation AUC = 0.8858\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8077\n",
      "  Validation AUC = 0.7909\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.9528\n",
      "  Validation Accuracy = 0.8592\n",
      "  Validation AUC = 0.8579\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7361\n",
      "  Validation Accuracy = 0.6917\n",
      "  Validation AUC = 0.5758\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8333\n",
      "  Validation AUC = 0.8148\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8696\n",
      "  Validation Accuracy = 0.7609\n",
      "  Validation AUC = 0.7334\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.9454\n",
      "  Validation Accuracy = 0.8374\n",
      "  Validation AUC = 0.8268\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7143\n",
      "  Validation AUC = 0.7111\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.8248\n",
      "  Validation Accuracy = 0.7523\n",
      "  Validation AUC = 0.6733\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6970\n",
      "  Validation AUC = 0.6181\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8648\n",
      "  Validation Accuracy = 0.8361\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9836\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.8780\n",
      "  Validation Accuracy = 0.7727\n",
      "  Validation AUC = 0.7702\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8659\n",
      "  Validation Accuracy = 0.7554\n",
      "  Validation AUC = 0.7292\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7606\n",
      "  Validation AUC = 0.7631\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7321\n",
      "  Validation Accuracy = 0.7643\n",
      "  Validation AUC = 0.6076\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9875\n",
      "  Validation AUC = 0.9861\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9481\n",
      "  Validation Accuracy = 0.9515\n",
      "  Validation AUC = 0.4975\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8659\n",
      "  Validation Accuracy = 0.7554\n",
      "  Validation AUC = 0.7292\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9740\n",
      "  Validation AUC = 0.9358\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9808\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8648\n",
      "  Validation Accuracy = 0.8361\n",
      "  Validation AUC = 0.5000\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9444\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9524\n",
      "  Validation Accuracy = 0.8169\n",
      "  Validation AUC = 0.7825\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8000\n",
      "  Validation AUC = 0.7311\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9087\n",
      "  Validation AUC = 0.9130\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9154\n",
      "  Validation AUC = 0.5791\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9305\n",
      "  Validation Accuracy = 0.9040\n",
      "  Validation AUC = 0.8955\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9527\n",
      "  Validation AUC = 0.8656\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.9813\n",
      "  Validation Accuracy = 0.8056\n",
      "  Validation AUC = 0.7809\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7241\n",
      "  Validation AUC = 0.7241\n",
      "Average AUC = 0.8099217838684903\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "n_estimators: Int = 50,\n",
    "learning_rate: Float = 1,\n",
    "algorithm: Literal['SAMME', 'SAMME.R'] = \"SAMME.R\",\n",
    "random_state: Int | RandomState | None = None,\n",
    "base_estimator: Any = \"deprecated\"\n",
    "\"\"\"\n",
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=1000)\n",
    "    model = AdaBoostClassifier(\n",
    "                n_estimators=50,\n",
    "                learning_rate=1,\n",
    "                algorithm='SAMME',\n",
    "                random_state=1\n",
    "            )\n",
    "    \n",
    "    model.fit(X_train, y_train.squeeze())\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, y_val_pred)\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7755102\tbest: 0.7755102 (0)\ttotal: 1.43ms\tremaining: 1.43s\n",
      "100:\ttest: 0.8398988\tbest: 0.8452776 (86)\ttotal: 139ms\tremaining: 1.23s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8452776459\n",
      "bestIteration = 86\n",
      "\n",
      "Shrink model to first 87 iterations.\n",
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.9060\n",
      "  Validation Accuracy = 0.7640\n",
      "  Validation AUC = 0.8453\n",
      "0:\ttest: 0.6462264\tbest: 0.6462264 (0)\ttotal: 1.62ms\tremaining: 1.61s\n",
      "100:\ttest: 0.7575122\tbest: 0.7590263 (83)\ttotal: 169ms\tremaining: 1.5s\n",
      "200:\ttest: 0.7628698\tbest: 0.7665968 (157)\ttotal: 356ms\tremaining: 1.41s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7665967855\n",
      "bestIteration = 157\n",
      "\n",
      "Shrink model to first 158 iterations.\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.9536\n",
      "  Validation Accuracy = 0.7005\n",
      "  Validation AUC = 0.7666\n",
      "0:\ttest: 0.5420168\tbest: 0.5420168 (0)\ttotal: 1.83ms\tremaining: 1.83s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.731092437\n",
      "bestIteration = 18\n",
      "\n",
      "Shrink model to first 19 iterations.\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.7311\n",
      "0:\ttest: 0.9486607\tbest: 0.9486607 (0)\ttotal: 1.14ms\tremaining: 1.14s\n",
      "100:\ttest: 0.9851190\tbest: 0.9895833 (51)\ttotal: 123ms\tremaining: 1.09s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9895833333\n",
      "bestIteration = 51\n",
      "\n",
      "Shrink model to first 52 iterations.\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9516\n",
      "  Validation AUC = 0.9896\n",
      "0:\ttest: 0.7725041\tbest: 0.7725041 (0)\ttotal: 1.88ms\tremaining: 1.88s\n",
      "100:\ttest: 0.8862520\tbest: 0.8878887 (80)\ttotal: 210ms\tremaining: 1.86s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.887888707\n",
      "bestIteration = 80\n",
      "\n",
      "Shrink model to first 81 iterations.\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7671\n",
      "  Validation AUC = 0.8879\n",
      "0:\ttest: 0.8698854\tbest: 0.8698854 (0)\ttotal: 2.06ms\tremaining: 2.06s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 29\n",
      "\n",
      "Shrink model to first 30 iterations.\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 0.9907\n",
      "  Validation Accuracy = 0.9315\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.6461768\tbest: 0.6461768 (0)\ttotal: 1.39ms\tremaining: 1.39s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7478649454\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.8182\n",
      "  Validation Accuracy = 0.7297\n",
      "  Validation AUC = 0.7479\n",
      "0:\ttest: 0.9922414\tbest: 0.9922414 (0)\ttotal: 2.2ms\tremaining: 2.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9997536946\n",
      "bestIteration = 19\n",
      "\n",
      "Shrink model to first 20 iterations.\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9998\n",
      "0:\ttest: 0.9717813\tbest: 0.9717813 (0)\ttotal: 1.37ms\tremaining: 1.37s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9894179894\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9167\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9894\n",
      "0:\ttest: 1.0000000\tbest: 1.0000000 (0)\ttotal: 1.53ms\tremaining: 1.52s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9902\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.9722982\tbest: 0.9722982 (0)\ttotal: 2.55ms\tremaining: 2.55s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9933880529\n",
      "bestIteration = 15\n",
      "\n",
      "Shrink model to first 16 iterations.\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9706\n",
      "  Validation Accuracy = 0.9708\n",
      "  Validation AUC = 0.9934\n",
      "0:\ttest: 0.9922414\tbest: 0.9922414 (0)\ttotal: 1.74ms\tremaining: 1.74s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9997536946\n",
      "bestIteration = 19\n",
      "\n",
      "Shrink model to first 20 iterations.\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9998\n",
      "0:\ttest: 0.6140351\tbest: 0.6140351 (0)\ttotal: 1.71ms\tremaining: 1.71s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9282296651\n",
      "bestIteration = 18\n",
      "\n",
      "Shrink model to first 19 iterations.\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9610\n",
      "  Validation Accuracy = 0.8462\n",
      "  Validation AUC = 0.9282\n",
      "0:\ttest: 0.9135237\tbest: 0.9135237 (0)\ttotal: 1.87ms\tremaining: 1.87s\n",
      "100:\ttest: 0.9474677\tbest: 0.9485453 (97)\ttotal: 174ms\tremaining: 1.55s\n",
      "200:\ttest: 0.9490841\tbest: 0.9507004 (184)\ttotal: 363ms\tremaining: 1.44s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9512392241\n",
      "bestIteration = 215\n",
      "\n",
      "Shrink model to first 216 iterations.\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8607\n",
      "  Validation AUC = 0.9512\n",
      "0:\ttest: 0.7456597\tbest: 0.7456597 (0)\ttotal: 2.29ms\tremaining: 2.29s\n",
      "100:\ttest: 0.8732639\tbest: 0.8767361 (99)\ttotal: 140ms\tremaining: 1.25s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8819444444\n",
      "bestIteration = 104\n",
      "\n",
      "Shrink model to first 105 iterations.\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7692\n",
      "  Validation AUC = 0.8819\n",
      "0:\ttest: 0.8633721\tbest: 0.8633721 (0)\ttotal: 1.47ms\tremaining: 1.47s\n",
      "100:\ttest: 0.9476744\tbest: 0.9491279 (88)\ttotal: 173ms\tremaining: 1.54s\n",
      "200:\ttest: 0.9507890\tbest: 0.9509967 (156)\ttotal: 311ms\tremaining: 1.24s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9520348837\n",
      "bestIteration = 233\n",
      "\n",
      "Shrink model to first 234 iterations.\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8803\n",
      "  Validation AUC = 0.9520\n",
      "0:\ttest: 0.5840278\tbest: 0.5840278 (0)\ttotal: 1.95ms\tremaining: 1.95s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7125194615\n",
      "bestIteration = 47\n",
      "\n",
      "Shrink model to first 48 iterations.\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.7806\n",
      "  Validation Accuracy = 0.6667\n",
      "  Validation AUC = 0.7125\n",
      "0:\ttest: 0.8500000\tbest: 0.8500000 (0)\ttotal: 1.44ms\tremaining: 1.44s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.9753\n",
      "  Validation Accuracy = 0.9815\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.7681818\tbest: 0.7681818 (0)\ttotal: 1.3ms\tremaining: 1.3s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8927272727\n",
      "bestIteration = 21\n",
      "\n",
      "Shrink model to first 22 iterations.\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.9346\n",
      "  Validation Accuracy = 0.8472\n",
      "  Validation AUC = 0.8927\n",
      "0:\ttest: 0.9856725\tbest: 0.9856725 (0)\ttotal: 1.16ms\tremaining: 1.15s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9756\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.7430274\tbest: 0.7430274 (0)\ttotal: 1.92ms\tremaining: 1.92s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8220081136\n",
      "bestIteration = 24\n",
      "\n",
      "Shrink model to first 25 iterations.\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8406\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.8220\n",
      "0:\ttest: 0.9076289\tbest: 0.9076289 (0)\ttotal: 1.52ms\tremaining: 1.52s\n",
      "100:\ttest: 0.9665072\tbest: 0.9675704 (95)\ttotal: 138ms\tremaining: 1.23s\n",
      "200:\ttest: 0.9686337\tbest: 0.9699628 (150)\ttotal: 286ms\tremaining: 1.14s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9699627858\n",
      "bestIteration = 150\n",
      "\n",
      "Shrink model to first 151 iterations.\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.9945\n",
      "  Validation Accuracy = 0.9268\n",
      "  Validation AUC = 0.9700\n",
      "0:\ttest: 0.7295918\tbest: 0.7295918 (0)\ttotal: 1.34ms\tremaining: 1.34s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8724489796\n",
      "bestIteration = 12\n",
      "\n",
      "Shrink model to first 13 iterations.\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7857\n",
      "  Validation AUC = 0.8724\n",
      "0:\ttest: 0.6082622\tbest: 0.6082622 (0)\ttotal: 2.04ms\tremaining: 2.04s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7501900819\n",
      "bestIteration = 16\n",
      "\n",
      "Shrink model to first 17 iterations.\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.8278\n",
      "  Validation Accuracy = 0.7162\n",
      "  Validation AUC = 0.7502\n",
      "0:\ttest: 0.6875000\tbest: 0.6875000 (0)\ttotal: 1.63ms\tremaining: 1.62s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7025\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.9375\n",
      "  Validation Accuracy = 0.6364\n",
      "  Validation AUC = 0.7025\n",
      "0:\ttest: 0.7900210\tbest: 0.7900210 (0)\ttotal: 1.19ms\tremaining: 1.19s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8047542404\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.7211\n",
      "  Validation Accuracy = 0.7311\n",
      "  Validation AUC = 0.8048\n",
      "0:\ttest: 0.9425103\tbest: 0.9425103 (0)\ttotal: 1.28ms\tremaining: 1.28s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9990838296\n",
      "bestIteration = 30\n",
      "\n",
      "Shrink model to first 31 iterations.\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9931\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9991\n",
      "0:\ttest: 0.8032759\tbest: 0.8032759 (0)\ttotal: 1.95ms\tremaining: 1.95s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8817966903\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.8293\n",
      "  Validation Accuracy = 0.7909\n",
      "  Validation AUC = 0.8818\n",
      "0:\ttest: 0.7421400\tbest: 0.7421400 (0)\ttotal: 1.57ms\tremaining: 1.56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8069852941\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8333\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.8070\n",
      "0:\ttest: 1.0000000\tbest: 1.0000000 (0)\ttotal: 2.59ms\tremaining: 2.58s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 0.9900\n",
      "  Validation Accuracy = 0.9559\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.7670940\tbest: 0.7670940 (0)\ttotal: 1.72ms\tremaining: 1.72s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8777777778\n",
      "bestIteration = 28\n",
      "\n",
      "Shrink model to first 29 iterations.\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9434\n",
      "  Validation Accuracy = 0.7606\n",
      "  Validation AUC = 0.8778\n",
      "0:\ttest: 0.6604747\tbest: 0.6604747 (0)\ttotal: 1.72ms\tremaining: 1.72s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7725748194\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.7273\n",
      "  Validation Accuracy = 0.6714\n",
      "  Validation AUC = 0.7726\n",
      "0:\ttest: 0.9656938\tbest: 0.9656938 (0)\ttotal: 2.49ms\tremaining: 2.49s\n",
      "100:\ttest: 0.9983908\tbest: 0.9989028 (74)\ttotal: 177ms\tremaining: 1.57s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9989027869\n",
      "bestIteration = 74\n",
      "\n",
      "Shrink model to first 75 iterations.\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9972\n",
      "  Validation Accuracy = 0.9833\n",
      "  Validation AUC = 0.9989\n",
      "0:\ttest: 0.4905303\tbest: 0.4905303 (0)\ttotal: 1.51ms\tremaining: 1.51s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.6518308081\n",
      "bestIteration = 11\n",
      "\n",
      "Shrink model to first 12 iterations.\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9286\n",
      "  Validation Accuracy = 0.8932\n",
      "  Validation AUC = 0.6518\n",
      "0:\ttest: 0.7421400\tbest: 0.7421400 (0)\ttotal: 2.21ms\tremaining: 2.21s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8069852941\n",
      "bestIteration = 5\n",
      "\n",
      "Shrink model to first 6 iterations.\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8333\n",
      "  Validation Accuracy = 0.7337\n",
      "  Validation AUC = 0.8070\n",
      "0:\ttest: 0.9202035\tbest: 0.9202035 (0)\ttotal: 2.78ms\tremaining: 2.78s\n",
      "100:\ttest: 0.9869186\tbest: 0.9869186 (73)\ttotal: 180ms\tremaining: 1.6s\n",
      "200:\ttest: 0.9889535\tbest: 0.9892442 (190)\ttotal: 354ms\tremaining: 1.41s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9904069767\n",
      "bestIteration = 217\n",
      "\n",
      "Shrink model to first 218 iterations.\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9688\n",
      "  Validation AUC = 0.9904\n",
      "0:\ttest: 0.9700544\tbest: 0.9700544 (0)\ttotal: 1.27ms\tremaining: 1.27s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 15\n",
      "\n",
      "Shrink model to first 16 iterations.\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.7900210\tbest: 0.7900210 (0)\ttotal: 1.56ms\tremaining: 1.56s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8047542404\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.7211\n",
      "  Validation Accuracy = 0.7311\n",
      "  Validation AUC = 0.8048\n",
      "0:\ttest: 0.9492188\tbest: 0.9492188 (0)\ttotal: 1.12ms\tremaining: 1.12s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 0.9722\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.9750000\tbest: 0.9750000 (0)\ttotal: 1.15ms\tremaining: 1.15s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 10\n",
      "\n",
      "Shrink model to first 11 iterations.\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9574\n",
      "  Validation Accuracy = 0.9531\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.8259141\tbest: 0.8259141 (0)\ttotal: 1.24ms\tremaining: 1.24s\n",
      "100:\ttest: 0.9125596\tbest: 0.9189189 (50)\ttotal: 131ms\tremaining: 1.17s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9189189189\n",
      "bestIteration = 50\n",
      "\n",
      "Shrink model to first 51 iterations.\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.9333\n",
      "  Validation Accuracy = 0.8028\n",
      "  Validation AUC = 0.9189\n",
      "0:\ttest: 0.6720000\tbest: 0.6720000 (0)\ttotal: 2.31ms\tremaining: 2.31s\n",
      "100:\ttest: 0.8080000\tbest: 0.8120000 (99)\ttotal: 201ms\tremaining: 1.79s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.868\n",
      "bestIteration = 141\n",
      "\n",
      "Shrink model to first 142 iterations.\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8000\n",
      "  Validation AUC = 0.8680\n",
      "0:\ttest: 1.0000000\tbest: 1.0000000 (0)\ttotal: 1.69ms\tremaining: 1.69s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 0\n",
      "\n",
      "Shrink model to first 1 iterations.\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9684\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.9118590\tbest: 0.9118590 (0)\ttotal: 3.32ms\tremaining: 3.32s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.989962888\n",
      "bestIteration = 27\n",
      "\n",
      "Shrink model to first 28 iterations.\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9536\n",
      "  Validation Accuracy = 0.9304\n",
      "  Validation AUC = 0.9900\n",
      "0:\ttest: 0.8355533\tbest: 0.8355533 (0)\ttotal: 2.47ms\tremaining: 2.47s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9651639344\n",
      "bestIteration = 13\n",
      "\n",
      "Shrink model to first 14 iterations.\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9794\n",
      "  Validation Accuracy = 0.9538\n",
      "  Validation AUC = 0.9652\n",
      "0:\ttest: 0.9342647\tbest: 0.9342647 (0)\ttotal: 1.63ms\tremaining: 1.63s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 1\n",
      "bestIteration = 47\n",
      "\n",
      "Shrink model to first 48 iterations.\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9733\n",
      "  Validation Accuracy = 0.9360\n",
      "  Validation AUC = 1.0000\n",
      "0:\ttest: 0.9012124\tbest: 0.9012124 (0)\ttotal: 1.68ms\tremaining: 1.68s\n",
      "100:\ttest: 0.9923664\tbest: 0.9928154 (87)\ttotal: 181ms\tremaining: 1.61s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9928154468\n",
      "bestIteration = 87\n",
      "\n",
      "Shrink model to first 88 iterations.\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9595\n",
      "  Validation AUC = 0.9928\n",
      "0:\ttest: 0.8098312\tbest: 0.8098312 (0)\ttotal: 1.3ms\tremaining: 1.3s\n",
      "100:\ttest: 0.8331678\tbest: 0.8401192 (56)\ttotal: 156ms\tremaining: 1.39s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.8401191658\n",
      "bestIteration = 56\n",
      "\n",
      "Shrink model to first 57 iterations.\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.9813\n",
      "  Validation Accuracy = 0.7778\n",
      "  Validation AUC = 0.8401\n",
      "0:\ttest: 0.7580645\tbest: 0.7580645 (0)\ttotal: 2.72ms\tremaining: 2.72s\n",
      "100:\ttest: 0.9366786\tbest: 0.9366786 (94)\ttotal: 206ms\tremaining: 1.83s\n",
      "200:\ttest: 0.9510155\tbest: 0.9510155 (194)\ttotal: 463ms\tremaining: 1.84s\n",
      "300:\ttest: 0.9522103\tbest: 0.9545998 (270)\ttotal: 685ms\tremaining: 1.59s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.9545997611\n",
      "bestIteration = 270\n",
      "\n",
      "Shrink model to first 271 iterations.\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8793\n",
      "  Validation AUC = 0.9546\n",
      "Average AUC = 0.9043\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "for i in range(len(dataset_names)):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.05,\n",
    "        depth=5,\n",
    "        l2_leaf_reg=3,\n",
    "        auto_class_weights='Balanced',\n",
    "        eval_metric='AUC',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=100\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train.squeeze(),\n",
    "        eval_set=(X_val, y_val),   # 使用驗證集監控模型性能\n",
    "        use_best_model=True        # 保留驗證集表現最好的模型\n",
    "    )\n",
    "\n",
    "    # Predictions for training and validation sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate AUC for the validation set\n",
    "    auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    average_auc += auc\n",
    "    \n",
    "    # Calculate accuracy for training and validation sets\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7921\n",
      "  Validation AUC = 0.8389\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6898\n",
      "  Validation AUC = 0.7510\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.9706\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.6723\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9355\n",
      "  Validation AUC = 0.9792\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7260\n",
      "  Validation AUC = 0.8568\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6892\n",
      "  Validation AUC = 0.6725\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9984\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8958\n",
      "  Validation AUC = 0.9700\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9926\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9562\n",
      "  Validation AUC = 0.9877\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9892\n",
      "  Validation AUC = 0.9984\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7885\n",
      "  Validation AUC = 0.8868\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8525\n",
      "  Validation AUC = 0.9442\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8846\n",
      "  Validation AUC = 0.8750\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8803\n",
      "  Validation AUC = 0.9560\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6333\n",
      "  Validation AUC = 0.5899\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8056\n",
      "  Validation AUC = 0.8473\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9919\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.8030\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8862\n",
      "  Validation AUC = 0.9673\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.7908\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7252\n",
      "  Validation AUC = 0.7289\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.6970\n",
      "  Validation AUC = 0.6700\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.9239\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.6947\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9991\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.9817\n",
      "  Validation Accuracy = 0.7636\n",
      "  Validation AUC = 0.8477\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.8048\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7042\n",
      "  Validation AUC = 0.8752\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7357\n",
      "  Validation AUC = 0.7454\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9792\n",
      "  Validation AUC = 0.9980\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9968\n",
      "  Validation Accuracy = 0.9563\n",
      "  Validation AUC = 0.5552\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7391\n",
      "  Validation AUC = 0.8048\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9837\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9167\n",
      "  Validation AUC = 0.9310\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.9239\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.6947\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9583\n",
      "  Validation AUC = 0.9922\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8028\n",
      "  Validation AUC = 0.8665\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8571\n",
      "  Validation AUC = 0.8760\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 1.0000\n",
      "  Validation AUC = 1.0000\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9217\n",
      "  Validation AUC = 0.9806\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9615\n",
      "  Validation AUC = 0.9621\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9680\n",
      "  Validation AUC = 0.9953\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.9730\n",
      "  Validation AUC = 0.9852\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.7500\n",
      "  Validation AUC = 0.8073\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 1.0000\n",
      "  Validation Accuracy = 0.8103\n",
      "  Validation AUC = 0.9283\n",
      "Average AUC = 0.8798\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # 分割資料集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    \n",
    "    # 建立 XGBoost 模型\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=1000,          # 等價於 iterations\n",
    "        learning_rate=0.05,         # 學習率\n",
    "        max_depth=5,                # 樹的深度\n",
    "        reg_lambda=3,               # L2 正則化\n",
    "        scale_pos_weight=1,         # 用來處理類別不平衡\n",
    "        objective='binary:logistic',# 二元分類\n",
    "        #eval_metric='auc',          # 監控的評估指標\n",
    "        random_state=42,            # 隨機種子\n",
    "    )\n",
    "    \n",
    "    # 訓練模型，啟用 early stopping\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train.squeeze()\n",
    "    )\n",
    "\n",
    "    # 預測\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # 計算 AUC\n",
    "    auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    average_auc += auc\n",
    "    \n",
    "    # 計算準確率\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc:.4f}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 82, number of negative: 184\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 223\n",
      "[LightGBM] [Info] Number of data points in the train set: 266, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.308271 -> initscore=-0.808217\n",
      "[LightGBM] [Info] Start training from score -0.808217\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.954169\tvalid_0's binary_logloss: 0.348818\tvalid_1's auc: 0.840452\tvalid_1's binary_logloss: 0.454688\n",
      "Dataset Dataset_1:\n",
      "  Train Accuracy = 0.8835\n",
      "  Validation Accuracy = 0.7697\n",
      "  Validation AUC = 0.8405\n",
      "[LightGBM] [Info] Number of positive: 113, number of negative: 167\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 423\n",
      "[LightGBM] [Info] Number of data points in the train set: 280, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.403571 -> initscore=-0.390606\n",
      "[LightGBM] [Info] Start training from score -0.390606\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's auc: 0.922182\tvalid_0's binary_logloss: 0.44969\tvalid_1's auc: 0.719951\tvalid_1's binary_logloss: 0.612099\n",
      "Dataset Dataset_10:\n",
      "  Train Accuracy = 0.8500\n",
      "  Validation Accuracy = 0.6738\n",
      "  Validation AUC = 0.7200\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 4, number of negative: 30\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 34, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117647 -> initscore=-2.014903\n",
      "[LightGBM] [Info] Start training from score -2.014903\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.362211\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.712843\n",
      "Dataset Dataset_11:\n",
      "  Train Accuracy = 0.8824\n",
      "  Validation Accuracy = 0.7083\n",
      "  Validation AUC = 0.5000\n",
      "[LightGBM] [Info] Number of positive: 29, number of negative: 63\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 138\n",
      "[LightGBM] [Info] Number of data points in the train set: 92, number of used features: 5\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.315217 -> initscore=-0.775839\n",
      "[LightGBM] [Info] Start training from score -0.775839\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.974275\tvalid_0's binary_logloss: 0.319535\tvalid_1's auc: 0.920387\tvalid_1's binary_logloss: 0.381307\n",
      "Dataset Dataset_12:\n",
      "  Train Accuracy = 0.9239\n",
      "  Validation Accuracy = 0.8548\n",
      "  Validation AUC = 0.9204\n",
      "[LightGBM] [Info] Number of positive: 26, number of negative: 82\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 522\n",
      "[LightGBM] [Info] Number of data points in the train set: 108, number of used features: 36\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.163595\tvalid_1's auc: 0.851882\tvalid_1's binary_logloss: 0.458833\n",
      "Dataset Dataset_13:\n",
      "  Train Accuracy = 0.9630\n",
      "  Validation Accuracy = 0.7260\n",
      "  Validation AUC = 0.8519\n",
      "[LightGBM] [Info] Number of positive: 26, number of negative: 82\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 528\n",
      "[LightGBM] [Info] Number of data points in the train set: 108, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240741 -> initscore=-1.148623\n",
      "[LightGBM] [Info] Start training from score -1.148623\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.162118\tvalid_1's auc: 0.983633\tvalid_1's binary_logloss: 0.242951\n",
      "Dataset Dataset_14:\n",
      "  Train Accuracy = 0.9537\n",
      "  Validation Accuracy = 0.9315\n",
      "  Validation AUC = 0.9836\n",
      "[LightGBM] [Info] Number of positive: 65, number of negative: 155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 200\n",
      "[LightGBM] [Info] Number of data points in the train set: 220, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.295455 -> initscore=-0.869038\n",
      "[LightGBM] [Info] Start training from score -0.869038\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's auc: 0.892258\tvalid_0's binary_logloss: 0.517559\tvalid_1's auc: 0.703575\tvalid_1's binary_logloss: 0.603078\n",
      "Dataset Dataset_15:\n",
      "  Train Accuracy = 0.7045\n",
      "  Validation Accuracy = 0.6419\n",
      "  Validation AUC = 0.7036\n",
      "[LightGBM] [Info] Number of positive: 108, number of negative: 171\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 279, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.387097 -> initscore=-0.459532\n",
      "[LightGBM] [Info] Start training from score -0.459532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.618686\tvalid_1's auc: 0.985714\tvalid_1's binary_logloss: 0.615619\n",
      "Dataset Dataset_16:\n",
      "  Train Accuracy = 0.6129\n",
      "  Validation Accuracy = 0.6237\n",
      "  Validation AUC = 0.9857\n",
      "[LightGBM] [Info] Number of positive: 36, number of negative: 36\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 265\n",
      "[LightGBM] [Info] Number of data points in the train set: 72, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.986111\tvalid_0's binary_logloss: 0.331306\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.317656\n",
      "Dataset Dataset_17:\n",
      "  Train Accuracy = 0.9306\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 15, number of negative: 189\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 92\n",
      "[LightGBM] [Info] Number of data points in the train set: 204, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.073529 -> initscore=-2.533697\n",
      "[LightGBM] [Info] Start training from score -2.533697\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.901411\tvalid_0's binary_logloss: 0.237186\tvalid_1's auc: 0.784091\tvalid_1's binary_logloss: 0.151545\n",
      "Dataset Dataset_18:\n",
      "  Train Accuracy = 0.9265\n",
      "  Validation Accuracy = 0.9706\n",
      "  Validation AUC = 0.7841\n",
      "[LightGBM] [Info] Number of positive: 82, number of negative: 122\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2061\n",
      "[LightGBM] [Info] Number of data points in the train set: 204, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401961 -> initscore=-0.397302\n",
      "[LightGBM] [Info] Start training from score -0.397302\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.109215\tvalid_1's auc: 0.979252\tvalid_1's binary_logloss: 0.191435\n",
      "Dataset Dataset_19:\n",
      "  Train Accuracy = 0.9951\n",
      "  Validation Accuracy = 0.9343\n",
      "  Validation AUC = 0.9793\n",
      "[LightGBM] [Info] Number of positive: 108, number of negative: 171\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 609\n",
      "[LightGBM] [Info] Number of data points in the train set: 279, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.387097 -> initscore=-0.459532\n",
      "[LightGBM] [Info] Start training from score -0.459532\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.618686\tvalid_1's auc: 0.985714\tvalid_1's binary_logloss: 0.615619\n",
      "Dataset Dataset_2:\n",
      "  Train Accuracy = 0.6129\n",
      "  Validation Accuracy = 0.6237\n",
      "  Validation AUC = 0.9857\n",
      "[LightGBM] [Info] Number of positive: 19, number of negative: 58\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 163\n",
      "[LightGBM] [Info] Number of data points in the train set: 77, number of used features: 13\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.246753 -> initscore=-1.116004\n",
      "[LightGBM] [Info] Start training from score -1.116004\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.998639\tvalid_0's binary_logloss: 0.159118\tvalid_1's auc: 0.872408\tvalid_1's binary_logloss: 0.4493\n",
      "Dataset Dataset_20:\n",
      "  Train Accuracy = 0.9610\n",
      "  Validation Accuracy = 0.8269\n",
      "  Validation AUC = 0.8724\n",
      "[LightGBM] [Info] Number of positive: 70, number of negative: 111\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 775\n",
      "[LightGBM] [Info] Number of data points in the train set: 181, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.386740 -> initscore=-0.461035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -0.461035\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.999485\tvalid_0's binary_logloss: 0.108244\tvalid_1's auc: 0.956088\tvalid_1's binary_logloss: 0.277721\n",
      "Dataset Dataset_21:\n",
      "  Train Accuracy = 0.9945\n",
      "  Validation Accuracy = 0.8852\n",
      "  Validation AUC = 0.9561\n",
      "[LightGBM] [Info] Number of positive: 31, number of negative: 45\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 173\n",
      "[LightGBM] [Info] Number of data points in the train set: 76, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.407895 -> initscore=-0.372675\n",
      "[LightGBM] [Info] Start training from score -0.372675\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's auc: 0.992832\tvalid_0's binary_logloss: 0.197624\tvalid_1's auc: 0.885417\tvalid_1's binary_logloss: 0.422522\n",
      "Dataset Dataset_22:\n",
      "  Train Accuracy = 0.9605\n",
      "  Validation Accuracy = 0.8846\n",
      "  Validation AUC = 0.8854\n",
      "[LightGBM] [Info] Number of positive: 81, number of negative: 131\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 286\n",
      "[LightGBM] [Info] Number of data points in the train set: 212, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.382075 -> initscore=-0.480748\n",
      "[LightGBM] [Info] Start training from score -0.480748\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.99755\tvalid_0's binary_logloss: 0.145522\tvalid_1's auc: 0.958991\tvalid_1's binary_logloss: 0.277701\n",
      "Dataset Dataset_23:\n",
      "  Train Accuracy = 0.9717\n",
      "  Validation Accuracy = 0.8873\n",
      "  Validation AUC = 0.9590\n",
      "[LightGBM] [Info] Number of positive: 113, number of negative: 247\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 288\n",
      "[LightGBM] [Info] Number of data points in the train set: 360, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.313889 -> initscore=-0.782001\n",
      "[LightGBM] [Info] Start training from score -0.782001\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.806062\tvalid_0's binary_logloss: 0.602485\tvalid_1's auc: 0.625286\tvalid_1's binary_logloss: 0.573092\n",
      "Dataset Dataset_24:\n",
      "  Train Accuracy = 0.6861\n",
      "  Validation Accuracy = 0.7458\n",
      "  Validation AUC = 0.6253\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 53\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 166\n",
      "[LightGBM] [Info] Number of data points in the train set: 81, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345679 -> initscore=-0.638087\n",
      "[LightGBM] [Info] Start training from score -0.638087\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.20614\tvalid_1's auc: 0.997059\tvalid_1's binary_logloss: 0.208802\n",
      "Dataset Dataset_25:\n",
      "  Train Accuracy = 0.9753\n",
      "  Validation Accuracy = 0.9630\n",
      "  Validation AUC = 0.9971\n",
      "[LightGBM] [Info] Number of positive: 43, number of negative: 64\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 245\n",
      "[LightGBM] [Info] Number of data points in the train set: 107, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.401869 -> initscore=-0.397683\n",
      "[LightGBM] [Info] Start training from score -0.397683\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's auc: 0.99564\tvalid_0's binary_logloss: 0.187289\tvalid_1's auc: 0.849091\tvalid_1's binary_logloss: 0.41829\n",
      "Dataset Dataset_26:\n",
      "  Train Accuracy = 0.9813\n",
      "  Validation Accuracy = 0.8194\n",
      "  Validation AUC = 0.8491\n",
      "[LightGBM] [Info] Number of positive: 54, number of negative: 69\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 138\n",
      "[LightGBM] [Info] Number of data points in the train set: 123, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.439024 -> initscore=-0.245122\n",
      "[LightGBM] [Info] Start training from score -0.245122\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.999732\tvalid_0's binary_logloss: 0.0711674\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.071218\n",
      "Dataset Dataset_27:\n",
      "  Train Accuracy = 0.9919\n",
      "  Validation Accuracy = 0.9880\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 93, number of negative: 183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 394\n",
      "[LightGBM] [Info] Number of data points in the train set: 276, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336957 -> initscore=-0.676887\n",
      "[LightGBM] [Info] Start training from score -0.676887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.966244\tvalid_0's binary_logloss: 0.319254\tvalid_1's auc: 0.828283\tvalid_1's binary_logloss: 0.491678\n",
      "Dataset Dataset_28:\n",
      "  Train Accuracy = 0.8877\n",
      "  Validation Accuracy = 0.7609\n",
      "  Validation AUC = 0.8283\n",
      "[LightGBM] [Info] Number of positive: 74, number of negative: 109\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 498\n",
      "[LightGBM] [Info] Number of data points in the train set: 183, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.404372 -> initscore=-0.387283\n",
      "[LightGBM] [Info] Start training from score -0.387283\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.998264\tvalid_0's binary_logloss: 0.148773\tvalid_1's auc: 0.975811\tvalid_1's binary_logloss: 0.228491\n",
      "Dataset Dataset_29:\n",
      "  Train Accuracy = 0.9945\n",
      "  Validation Accuracy = 0.9106\n",
      "  Validation AUC = 0.9758\n",
      "[LightGBM] [Info] Number of positive: 21, number of negative: 20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122\n",
      "[LightGBM] [Info] Number of data points in the train set: 41, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.512195 -> initscore=0.048790\n",
      "[LightGBM] [Info] Start training from score 0.048790\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.755952\tvalid_0's binary_logloss: 0.652072\tvalid_1's auc: 0.755102\tvalid_1's binary_logloss: 0.64637\n",
      "Dataset Dataset_3:\n",
      "  Train Accuracy = 0.6585\n",
      "  Validation Accuracy = 0.6786\n",
      "  Validation AUC = 0.7551\n",
      "[LightGBM] [Info] Number of positive: 109, number of negative: 222\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 331, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.329305 -> initscore=-0.711329\n",
      "[LightGBM] [Info] Start training from score -0.711329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.965121\tvalid_0's binary_logloss: 0.393734\tvalid_1's auc: 0.718805\tvalid_1's binary_logloss: 0.597241\n",
      "Dataset Dataset_30:\n",
      "  Train Accuracy = 0.9003\n",
      "  Validation Accuracy = 0.6892\n",
      "  Validation AUC = 0.7188\n",
      "[LightGBM] [Info] Number of positive: 14, number of negative: 34\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 161\n",
      "[LightGBM] [Info] Number of data points in the train set: 48, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.291667 -> initscore=-0.887303\n",
      "[LightGBM] [Info] Start training from score -0.887303\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's auc: 0.802521\tvalid_0's binary_logloss: 0.582554\tvalid_1's auc: 0.6875\tvalid_1's binary_logloss: 0.557282\n",
      "Dataset Dataset_31:\n",
      "  Train Accuracy = 0.7083\n",
      "  Validation Accuracy = 0.7576\n",
      "  Validation AUC = 0.6875\n",
      "[LightGBM] [Info] Number of positive: 46, number of negative: 309\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129577 -> initscore=-1.904700\n",
      "[LightGBM] [Info] Start training from score -1.904700\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.855178\tvalid_0's binary_logloss: 0.358518\tvalid_1's auc: 0.793611\tvalid_1's binary_logloss: 0.432318\n",
      "Dataset Dataset_32:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.7936\n",
      "[LightGBM] [Info] Number of positive: 51, number of negative: 93\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 231\n",
      "[LightGBM] [Info] Number of data points in the train set: 144, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.354167 -> initscore=-0.600774\n",
      "[LightGBM] [Info] Start training from score -0.600774\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.999789\tvalid_0's binary_logloss: 0.0690414\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.0794514\n",
      "Dataset Dataset_33:\n",
      "  Train Accuracy = 0.9931\n",
      "  Validation Accuracy = 0.9896\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 70, number of negative: 94\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 398\n",
      "[LightGBM] [Info] Number of data points in the train set: 164, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.426829 -> initscore=-0.294800\n",
      "[LightGBM] [Info] Start training from score -0.294800\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.907903\tvalid_0's binary_logloss: 0.467704\tvalid_1's auc: 0.877744\tvalid_1's binary_logloss: 0.499346\n",
      "Dataset Dataset_34:\n",
      "  Train Accuracy = 0.7866\n",
      "  Validation Accuracy = 0.8000\n",
      "  Validation AUC = 0.8777\n",
      "[LightGBM] [Info] Number of positive: 93, number of negative: 183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 394\n",
      "[LightGBM] [Info] Number of data points in the train set: 276, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336957 -> initscore=-0.676887\n",
      "[LightGBM] [Info] Start training from score -0.676887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.965098\tvalid_0's binary_logloss: 0.320612\tvalid_1's auc: 0.824544\tvalid_1's binary_logloss: 0.501087\n",
      "Dataset Dataset_35:\n",
      "  Train Accuracy = 0.8804\n",
      "  Validation Accuracy = 0.7609\n",
      "  Validation AUC = 0.8245\n",
      "[LightGBM] [Info] Number of positive: 64, number of negative: 36\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 206\n",
      "[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.640000 -> initscore=0.575364\n",
      "[LightGBM] [Info] Start training from score 0.575364\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.992188\tvalid_0's binary_logloss: 0.606189\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.601747\n",
      "Dataset Dataset_36:\n",
      "  Train Accuracy = 0.6400\n",
      "  Validation Accuracy = 0.6471\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 56, number of negative: 50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 150\n",
      "[LightGBM] [Info] Number of data points in the train set: 106, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528302 -> initscore=0.113329\n",
      "[LightGBM] [Info] Start training from score 0.113329\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.994643\tvalid_0's binary_logloss: 0.180018\tvalid_1's auc: 0.882906\tvalid_1's binary_logloss: 0.463595\n",
      "Dataset Dataset_37:\n",
      "  Train Accuracy = 0.9717\n",
      "  Validation Accuracy = 0.7606\n",
      "  Validation AUC = 0.8829\n",
      "[LightGBM] [Info] Number of positive: 147, number of negative: 62\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 363\n",
      "[LightGBM] [Info] Number of data points in the train set: 209, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.703349 -> initscore=0.863298\n",
      "[LightGBM] [Info] Start training from score 0.863298\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.887316\tvalid_0's binary_logloss: 0.487732\tvalid_1's auc: 0.748452\tvalid_1's binary_logloss: 0.550436\n",
      "Dataset Dataset_38:\n",
      "  Train Accuracy = 0.8182\n",
      "  Validation Accuracy = 0.7000\n",
      "  Validation AUC = 0.7485\n",
      "[LightGBM] [Info] Number of positive: 206, number of negative: 154\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1704\n",
      "[LightGBM] [Info] Number of data points in the train set: 360, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.572222 -> initscore=0.290924\n",
      "[LightGBM] [Info] Start training from score 0.290924\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.0609588\tvalid_1's auc: 0.997001\tvalid_1's binary_logloss: 0.0923204\n",
      "Dataset Dataset_39:\n",
      "  Train Accuracy = 0.9944\n",
      "  Validation Accuracy = 0.9750\n",
      "  Validation AUC = 0.9970\n",
      "[LightGBM] [Info] Number of positive: 20, number of negative: 288\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 187\n",
      "[LightGBM] [Info] Number of data points in the train set: 308, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.064935 -> initscore=-2.667228\n",
      "[LightGBM] [Info] Start training from score -2.667228\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.875174\tvalid_0's binary_logloss: 0.220913\tvalid_1's auc: 0.434343\tvalid_1's binary_logloss: 0.180993\n",
      "Dataset Dataset_4:\n",
      "  Train Accuracy = 0.9351\n",
      "  Validation Accuracy = 0.9612\n",
      "  Validation AUC = 0.4343\n",
      "[LightGBM] [Info] Number of positive: 93, number of negative: 183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 394\n",
      "[LightGBM] [Info] Number of data points in the train set: 276, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.336957 -> initscore=-0.676887\n",
      "[LightGBM] [Info] Start training from score -0.676887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.965098\tvalid_0's binary_logloss: 0.320612\tvalid_1's auc: 0.824544\tvalid_1's binary_logloss: 0.501087\n",
      "Dataset Dataset_40:\n",
      "  Train Accuracy = 0.8804\n",
      "  Validation Accuracy = 0.7609\n",
      "  Validation AUC = 0.8245\n",
      "[LightGBM] [Info] Number of positive: 28, number of negative: 260\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 373\n",
      "[LightGBM] [Info] Number of data points in the train set: 288, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.097222 -> initscore=-2.228477\n",
      "[LightGBM] [Info] Start training from score -2.228477\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.144134\tvalid_1's auc: 0.95407\tvalid_1's binary_logloss: 0.19929\n",
      "Dataset Dataset_41:\n",
      "  Train Accuracy = 0.9896\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 0.9541\n",
      "[LightGBM] [Info] Number of positive: 39, number of negative: 33\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 101\n",
      "[LightGBM] [Info] Number of data points in the train set: 72, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.541667 -> initscore=0.167054\n",
      "[LightGBM] [Info] Start training from score 0.167054\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640921\tvalid_1's auc: 0.982759\tvalid_1's binary_logloss: 0.665162\n",
      "Dataset Dataset_42:\n",
      "  Train Accuracy = 0.5417\n",
      "  Validation Accuracy = 0.3958\n",
      "  Validation AUC = 0.9828\n",
      "[LightGBM] [Info] Number of positive: 46, number of negative: 309\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63\n",
      "[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.129577 -> initscore=-1.904700\n",
      "[LightGBM] [Info] Start training from score -1.904700\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[2]\tvalid_0's auc: 0.855178\tvalid_0's binary_logloss: 0.358518\tvalid_1's auc: 0.793611\tvalid_1's binary_logloss: 0.432318\n",
      "Dataset Dataset_43:\n",
      "  Train Accuracy = 0.8704\n",
      "  Validation Accuracy = 0.8277\n",
      "  Validation AUC = 0.7936\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 27, number of negative: 9\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 36, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.750000 -> initscore=1.098612\n",
      "[LightGBM] [Info] Start training from score 1.098612\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.562335\tvalid_1's auc: 0.5\tvalid_1's binary_logloss: 0.653886\n",
      "Dataset Dataset_44:\n",
      "  Train Accuracy = 0.7500\n",
      "  Validation Accuracy = 0.6667\n",
      "  Validation AUC = 0.5000\n",
      "[LightGBM] [Info] Number of positive: 7, number of negative: 87\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 72\n",
      "[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074468 -> initscore=-2.519998\n",
      "[LightGBM] [Info] Start training from score -2.519998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.113203\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.110588\n",
      "Dataset Dataset_45:\n",
      "  Train Accuracy = 0.9255\n",
      "  Validation Accuracy = 0.9375\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 35, number of negative: 70\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 117\n",
      "[LightGBM] [Info] Number of data points in the train set: 105, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.927143\tvalid_0's binary_logloss: 0.431082\tvalid_1's auc: 0.916932\tvalid_1's binary_logloss: 0.504668\n",
      "Dataset Dataset_46:\n",
      "  Train Accuracy = 0.8667\n",
      "  Validation Accuracy = 0.7746\n",
      "  Validation AUC = 0.9169\n",
      "[LightGBM] [Info] Number of positive: 17, number of negative: 34\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 51, number of used features: 74\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.333333 -> initscore=-0.693147\n",
      "[LightGBM] [Info] Start training from score -0.693147\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.808824\tvalid_0's binary_logloss: 0.617145\tvalid_1's auc: 0.83\tvalid_1's binary_logloss: 0.585018\n",
      "Dataset Dataset_47:\n",
      "  Train Accuracy = 0.6667\n",
      "  Validation Accuracy = 0.7143\n",
      "  Validation AUC = 0.8300\n",
      "[LightGBM] [Info] Number of positive: 86, number of negative: 56\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 134\n",
      "[LightGBM] [Info] Number of data points in the train set: 142, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.605634 -> initscore=0.428996\n",
      "[LightGBM] [Info] Start training from score 0.428996\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.621914\tvalid_1's auc: 1\tvalid_1's binary_logloss: 0.595654\n",
      "Dataset Dataset_48:\n",
      "  Train Accuracy = 0.6056\n",
      "  Validation Accuracy = 0.6737\n",
      "  Validation AUC = 1.0000\n",
      "[LightGBM] [Info] Number of positive: 216, number of negative: 129\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3907\n",
      "[LightGBM] [Info] Number of data points in the train set: 345, number of used features: 41\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.626087 -> initscore=0.515466\n",
      "[LightGBM] [Info] Start training from score 0.515466\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.998062\tvalid_0's binary_logloss: 0.119098\tvalid_1's auc: 0.989626\tvalid_1's binary_logloss: 0.163866\n",
      "Dataset Dataset_49:\n",
      "  Train Accuracy = 0.9768\n",
      "  Validation Accuracy = 0.9348\n",
      "  Validation AUC = 0.9896\n",
      "[LightGBM] [Info] Number of positive: 13, number of negative: 181\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1188\n",
      "[LightGBM] [Info] Number of data points in the train set: 194, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.067010 -> initscore=-2.633548\n",
      "[LightGBM] [Info] Start training from score -2.633548\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.179347\tvalid_1's auc: 0.914959\tvalid_1's binary_logloss: 0.201929\n",
      "Dataset Dataset_5:\n",
      "  Train Accuracy = 0.9330\n",
      "  Validation Accuracy = 0.9385\n",
      "  Validation AUC = 0.9150\n",
      "[LightGBM] [Info] Number of positive: 84, number of negative: 103\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 63\n",
      "[LightGBM] [Info] Number of data points in the train set: 187, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.449198 -> initscore=-0.203912\n",
      "[LightGBM] [Info] Start training from score -0.203912\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.999769\tvalid_0's binary_logloss: 0.102388\tvalid_1's auc: 0.992941\tvalid_1's binary_logloss: 0.154209\n",
      "Dataset Dataset_6:\n",
      "  Train Accuracy = 0.9679\n",
      "  Validation Accuracy = 0.9600\n",
      "  Validation AUC = 0.9929\n",
      "[LightGBM] [Info] Number of positive: 31, number of negative: 190\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 682\n",
      "[LightGBM] [Info] Number of data points in the train set: 221, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.140271 -> initscore=-1.813037\n",
      "[LightGBM] [Info] Start training from score -1.813037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.0509359\tvalid_1's auc: 0.983386\tvalid_1's binary_logloss: 0.126925\n",
      "Dataset Dataset_7:\n",
      "  Train Accuracy = 0.9910\n",
      "  Validation Accuracy = 0.9595\n",
      "  Validation AUC = 0.9834\n",
      "[LightGBM] [Info] Number of positive: 39, number of negative: 68\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 175\n",
      "[LightGBM] [Info] Number of data points in the train set: 107, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.364486 -> initscore=-0.555946\n",
      "[LightGBM] [Info] Start training from score -0.555946\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.968514\tvalid_0's binary_logloss: 0.310443\tvalid_1's auc: 0.795929\tvalid_1's binary_logloss: 0.470629\n",
      "Dataset Dataset_8:\n",
      "  Train Accuracy = 0.9159\n",
      "  Validation Accuracy = 0.8056\n",
      "  Validation AUC = 0.7959\n",
      "[LightGBM] [Info] Number of positive: 43, number of negative: 43\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1337\n",
      "[LightGBM] [Info] Number of data points in the train set: 86, number of used features: 46\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.985398\tvalid_0's binary_logloss: 0.252659\tvalid_1's auc: 0.927121\tvalid_1's binary_logloss: 0.401966\n",
      "Dataset Dataset_9:\n",
      "  Train Accuracy = 0.9302\n",
      "  Validation Accuracy = 0.8276\n",
      "  Validation AUC = 0.9271\n",
      "Average AUC = 0.8639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "average_auc = 0\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # 定义模型\n",
    "    model = lgb.LGBMClassifier(\n",
    "        boosting_type='gbdt',\n",
    "        num_leaves=31,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=500,\n",
    "        objective='binary',\n",
    "        random_state=42,\n",
    "        is_unbalance=True\n",
    "    )\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trains[i], y_trains[i], train_size=0.6, random_state=123)\n",
    "    eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train.values.ravel(),\n",
    "        eval_set=eval_set,\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "\n",
    "    # 預測\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    \n",
    "    # 計算 AUC\n",
    "    auc = roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])\n",
    "    average_auc += auc\n",
    "    \n",
    "    # 計算準確率\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"Dataset {dataset_names[i]}:\")\n",
    "    print(f\"  Train Accuracy = {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Accuracy = {val_accuracy:.4f}\")\n",
    "    print(f\"  Validation AUC = {auc:.4f}\")\n",
    "\n",
    "average_auc /= len(dataset_names)\n",
    "print(f\"Average AUC = {average_auc:.4f}\")\n",
    "\n",
    "AUC_set.append(average_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> AUC plotting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.8092416125176792), np.float64(0.7441867678247674), np.float64(0.7507947885909418), np.float64(0.7746742743162263), np.float64(0.7712243778417804), np.float64(0.7622466588825504), np.float64(0.7926386955651706), np.float64(0.7322830807888722), np.float64(0.7452340180432082), np.float64(0.8124538657927755), np.float64(0.8099217838684903), np.float64(0.8798364778900909), np.float64(0.9043), np.float64(0.8638565637660981)]\n"
     ]
    }
   ],
   "source": [
    "AUC_set.append(np.float64(0.9043)) ## CatBoost AUC\n",
    "print(AUC_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Classifier names\n",
    "classifiers = [\n",
    "    \"RandomForestClassifier\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"SVC\",\n",
    "    \"GaussianNB\",\n",
    "    \"MLPClassifier\",\n",
    "    \"RidgeClassifier\",\n",
    "    \"Perceptron\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"CatBoostClassifier\",\n",
    "    \"LGBMClassifier\"\n",
    "]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(classifiers, AUC_set, marker='o', linestyle='-', label='Average ROC AUC Score')\n",
    "\n",
    "# Annotate each data point with its value\n",
    "for i, value in enumerate(AUC_set):\n",
    "    plt.text(i, value + 0.005, f\"{value:.3f}\", ha='center', fontsize=9)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average ROC AUC Score for Classifiers', fontsize=14)\n",
    "plt.xlabel('Classifier', fontsize=12)\n",
    "plt.ylabel('Average ROC AUC Score', fontsize=12)\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Classifier names\n",
    "classifiers = [\n",
    "    \"RandomForestClassifier\",\n",
    "    \"KNeighborsClassifier\",\n",
    "    \"LogisticRegression\",\n",
    "    \"DecisionTreeClassifier\",\n",
    "    \"SVC\",\n",
    "    \"GaussianNB\",\n",
    "    \"MLPClassifier\",\n",
    "    \"RidgeClassifier\",\n",
    "    \"Perceptron\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"CatBoostClassifier\",\n",
    "    \"LGBMClassifier\"\n",
    "]\n",
    "\n",
    "# Plotting the bar graph\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(classifiers, AUC_set, color='skyblue', alpha=0.8, label='Average ROC AUC Score')\n",
    "\n",
    "# Annotate each bar with its value\n",
    "for bar, value in zip(bars, AUC_set):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, value + 0.005, f\"{value:.3f}\", \n",
    "             ha='center', fontsize=9)  # Display AUC values above the bars\n",
    "\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Average ROC AUC Score for Classifiers', fontsize=14)\n",
    "plt.xlabel('Classifier', fontsize=12)\n",
    "plt.ylabel('Average ROC AUC Score', fontsize=12)\n",
    "plt.ylim(0.7, 1.00)  \n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  \n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Comparison of AUC Scores Before and After Threshold Modification (Plotting Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Model names\n",
    "models = [\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"AdaBoostClassifier\",\n",
    "    \"RandomForestClassifier\",\n",
    "    \"XGBClassifier\",\n",
    "    \"LightGBM Classifier\",\n",
    "    \"CatBoostClassifier\"\n",
    "]\n",
    "\n",
    "# AUC values\n",
    "auc_before_threshold = [0.9380, 0.9128, 0.9343, 0.9359, 0.9307, 0.9451]\n",
    "auc_after_threshold = [0.9416, 0.9141, 0.9343, 0.9325, 0.9307, 0.9455]\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.4\n",
    "x = np.arange(len(models))\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars1 = plt.bar(x - bar_width / 2, auc_before_threshold, bar_width, label='Before modifying the threshold', color='skyblue')\n",
    "bars2 = plt.bar(x + bar_width / 2, auc_after_threshold, bar_width, label='After modifying the threshold', color='orange')\n",
    "\n",
    "# Adjust x-ticks to be centered between the bars\n",
    "plt.xticks(x, models, rotation=15, ha='center', fontsize=10)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.ylabel('Average ROC AUC Score', fontsize=12)\n",
    "plt.title('Comparison of AUC Scores Before and After Threshold Modification', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Annotate each bar with its value\n",
    "for bar, value in zip(bars1, auc_before_threshold):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.002, f\"{value:.4f}\", ha='center', fontsize=9)\n",
    "\n",
    "for bar, value in zip(bars2, auc_after_threshold):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.002, f\"{value:.4f}\", ha='center', fontsize=9)\n",
    "\n",
    "# Add grid lines and set y-axis limit\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.ylim(0.70, 1.00)  # Set y-axis range\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
